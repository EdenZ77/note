# OPS运维管理平台

项目描述： GatorCloud 项目旨在将天空卫视的核心产品 DLP（数据防泄漏） 能力从传统的物理设备销售模式
转变为基于云的服务模式。 在过去，天空卫士主要通过物理设备以容器化部署的方式向大型企业提供 DLP服务。 随着互联网的发展， 数据变得与来越重要，许多中小型企业也开始需要保护敏感数据的能力。GatorCloud 的目标就是利用公有云灵活性、 可扩展性、 按需付费等优势， 将天空卫士的 DLP能力提供给各种规模的企业。 无论是规模仅有十几人的小公司， 还是拥有数十万员工的大型企业， 都可以通过 GatorCloud 轻松获取 DLP 保护服务。  



多集群管理、多租户管理、安全服务管理

具体功能：集群基本信息管理、资源监控、**跨集群认证**、日志收集配置、Web 终端；租户的实时资源使用收集、各服务运行监控；安全产品服务**资源定义**、版本控制、接口测试；租户独立升级、降级安全产品服务；K8s 资源可视化展示、修改。

集成 Grafana，对产品服务进行监控可视化。上报业务监控指标到 Prometheus，结合 Grafana 实现服务异常告警。

集群问题排查，解决容器资源占用异常、容器性能差等问题。

> 资源限制不合理，没有考虑 pagecache，memory cgroup。request 太小
>
> ApiSix，不同集群，内存，oom，节点资源丰富。大量nginx进程，limit cpu，top，/proc/state。深入学习 cgroup，k8s cadvisor，lxcfs。

涉及技术：Client-go，Operator，Kubebuilder，K8s，Prometheus，Grafana，ApiSix，Kratos，Gorm，Wire，Grpc，Postgresql 等。

# Operator模块

 项目描述： 通过 Operator 封装租户产品业务逻辑， 实现租户不同 DLP 产品的订购、 修改、 取消订购等逻辑。
 技 术 栈： kubernetes + kubebuilder + operator + controller -runtime + apisix + etcd
 技术要点：
o 租户 DLP 产品订购、 修改、 取消订购以及产品到期问题
o 不同 DLP 产品容器依赖问题
o 不同 DLP 产品容器共享问题
o 后续不同 DLP 产品资源清单维护问题
o 后续不同 DLP 服务灰度升级、 回滚问题
o 不同 DLP 产品 apisix 路由维护问题  

# 私有化部署

响应一汽集团数字化转型战略，将传统硬件部署的UCWI-11000安全产品改造为Kubernetes云原生架构。实现从物理设备到容器化K8S部署的转型，满足客户对弹性伸缩、高可用和统一管理的核心需求。



原来采用docker-compose的方式部署，了解原来如何实现容器启动顺序、网络访问等原理



## 相关改造

appliance容器化改造

- 之前的设备注册流程需要人工操作，该流程需要自动化，依赖的信息可通过环境变量或者configmap的方式获取；注册成功后获取的证书等信息通过存入指定的存储让其他组件可以感知到并应用

各组件间调用方式修改（Cloud Team）

- 设备版是docker-compose方式部署，服务通过固定IP来调用。
- 各组件以单独的Pod来部署，通过暴露的service name来访问。
- 目前组件的依赖服务地址基本支持配置文件，并将依赖服务地址修改为对应服务的service name。

UCWI与UCSS的交互（Cloud Team）

- UCWI的apache会暴露到集群外，供外部服务访问。在设备注册时，将apache的访问地址上传到UCSS。
- 整个交互和当前设备版类似，改动较小。

容器依赖关系（Cloud Team）

- 组件之间存在依赖关系，在docker-compose中是可以控制启动顺序的，在pod中不行。
- 解决方案：可通过init container检查依赖pod的探针，就绪后才启动。

该方案可支持同一个K8S集群部署多套UCWI来支持扩容和负载均衡

- 使用 namespace 隔离，类似多个UCWI设备，保持原有逻辑。
- 目前方案为了简化部署，选择通过HostPort暴露，并选择一个work节点的IP作为对外访问的入口。具体选择集群中的哪一个节点，在安装部署时需要指定。
- 没有使用 NodePort 暴露，因为 NodePort 默认端口范围是 30000 以上，而 UCSS 固定了对 UCWI 的访问端口为 9443 和 5443，因此采用 HostPort 暴露。
- 每个 UCWI 实例需要绑定一个 work 节点，用于暴露 UCWI 服务网关，集群外通过此节点的 IP 访问 UCWI。

交付方式（Cloud Team）

- 通过导出镜像+部署文件+相关脚本
- 升级和bug修复：导出新的镜像+部署文件+相关脚本
- 镜像通过公网镜像仓库发布（后续镜像的更新由成都团队负责）
- 部署程序会通过公网镜像仓库拉取需要的镜像

## 具体实现

容器调度

1、appliance & ucwi 容器部署到同一个 Pod

appliance 访问 ucwi 时，由于 ucwi 授信 IP 功能，需要固定 appliance 访问时的客户端 IP，才能授信。因此将这两个容器放到同一个 Pod 里，appliance 通过 127.0.0.1 的方式去访问 ucwi，ucwi 只需要授信 127.0.0.1 即可。

2、appliance Pod（包含 ucwi 容器）需要调度到固定某个节点

通过 hostPort 的形式暴露 appliance 9443 端口，用于集群外的 ucss 访问。通过 hostPort 的形式暴露 ucwi 5443 端口，用于集群外的客户端访问。

3、dcrp 和 rde 容器部署到同一个 Pod

因为这两个容器内部通过 127.0.0.1 的形式相互访问，所以需要在同一个 network namespace。

4、spe & kvserver 容器部署到同一个 Pod

spe 和 kvserver 挂载了同一个PV，spe 运行时，会挂载 tmpfs 文件系统到该PV。因此 spe 和 kvserver 必须在同一个 Pod，并配置挂载传播特性，才能保证 spe 挂载的文件系统对 kvserver 可见。

5、appliance 部署后和 ucss 通信需要默认证书，此证书由成都团队以挂载文件的形式提供。后续 appliance 会申请新的证书进行覆盖。

## 代码实现

应用构建三剑客：wire、pflag、viper、cobra的使用。

version：给应用添加版本号打印功能：通过编译时指定 -ldflags -X importpath.name=value 参数，来为程序自动注入版本信息。

status：查看所有部署产品实例的相关信息，注意要读取产品命名空间下的config这个configmap，config中的data为config: |- xxxx，以此获得 网关对外地址：bs.Appliance.ServerOutIp。是否所有产品都是此种方式呢？

config：查看选择的产品实例的配置信息，也就是读取产品命名空间下的config这个configmap，config中的data为config: |- xxxx。

deploy：部署实例（创建、更新、删除、回滚），

- 创建：校验命名空间是否已经存在、校验node节点状态（污点、已被部署实例）







# ZTNA 网关模块

 项目描述： 零信任网络访问（ZTNA, 全称为 Zero Trust Network Access） 安全服务是零信任的理念实践。 旨
在解决传统 VPN 的痛点， 用于通过集成安全性和网络服务， 将安全策略应用于边缘网络， 从而实现更加动
态和灵活的访问控制。 这种方法不仅限制在企业内部的网络访问， 还扩展到云服务和分布式工作环境， 以确
保远程用户和设备能够安全地连接到公司资源， 同时保护数据的机密性和完整性。
 技 术 栈： traefik + kubernetes + socks5 + oauth2 + pkce + 七层/四层流量代理
 目标： 实现内网穿透， 让企业员工可以在任何时间任何地方无感的访问企业内网应用
 技术要点：
o 接收七层流量， 实现以 OAuth + PKCE 方式的租户认证， 不同租户流量转发、 策略执行
o 接收四层流量， 实现不同租户流量转发、 策略执行  





# CA认证中心



