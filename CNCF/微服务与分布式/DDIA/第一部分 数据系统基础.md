# 第1章 可靠、可扩展与可维护的应用系统

当今许多新型应用都属于数据密集型（data-intensive），而不是计算密集型（compute-intensive）。对于这些类型应用， CPU 的处理能力往往不是第一限制性因素，关键在于数据量、数据的复杂度及数据的快速多变性。

数据密集型应用通常也是基于标准模块构建而成，每个模块负责单一的常用功能。例如，许多应用系统都包含以下模块 ：  



## 认识数据系统

我们通常将数据库、队列、 高速缓存等视为不同类型的系统。虽然数据库和消息队列存在某些相似性，例如两者都会保存数据（至少一段时间），但他们却有着截然不同的访问模式，这就意味着不同的性能特征和设计实现。  

那么为什么本书将它们归为一大类即“数据系统” (data system ）呢？

首先，近年来出现了许多用于数据存储和处理的新工具 。 它们针对各种不同的应用场景进行优化，不适合再归为传统类型。 例如， Redis既可以用于数据存储也适用于消息队列， Apache Kafka作为消息队列也具备了持久化存储保证。系统之间的界限正在变得模糊。

其次 ，越来越多的应用系统需求广泛，单个组件往往无能满足所有数据处理与存储需求。因而需要将任务分解，每个组件负责高效完成其中一部分，多个组件依靠应用层代码驱动有机衔接起来。

举个例子，假定某个应用包含缓存层（例如Memcached ）与全文索引服务器（如Elasticsearch或 Solr ）， 二者与主数据库保持关联 ，通常由应用代码负责缓存 、 索引与主数据库之间的同步。

设计数据系统或数据服务时， 一定会碰到很多棘手的问题。例如，当系统内出现了局部失效时，如何确保数据的正确性与完整性？当发生系统降级（ degrade ）时，该如何为客户提供一致的良好表现？负载增加时，系统如何扩展？友好的服务API该如何设计？

影响数据系统设计的因素有很多，其中包括相关人员技能和经验水平、遗留系统依赖性、交付周期、对不同风险因素的容忍度、监管合规等。这些因素往往因时因地而异。本书将专注于对大多数软件系统都极为重要的三个问题：

- 可靠性 （Reliability）

当出现意外情况如硬件、软件故障、人为失误等，系统应可以继续正常运转：虽然性能可能有所降低，但确保功能正确。具体请参阅本章后面的“可靠性” 一节 。

- 可扩展性（Scalability）

随着规模的增长 ，例如数据量 、流量或复杂性，系统应以合理的方式来匹配这种增长，具体请参阅本章后面的 “可扩展性 ” 一节。

- 可维护性 （Maintainability）

随着时间的推移，许多新的人员参与到系统开发和运维， 以维护现有功能或适配新场景等，系统都应高效运转。具体请参阅本章后面的“可维护性”一节。

### **可靠性**

每个人脑子里都有一个直观的认识 ， 即什么意味着可靠或者不可靠。对于软件，典型的期望包括：

- 应用程序执行用户所期望的功能。
- 可以容忍用户出现错误或者不正确的软件使用方怯 。
- 性能可以应对典型场景 、 合理负载压力和数据量。
- 系统可防止任何未经授权的访问和滥用。

如果所有上述目标都要支持才算 “正常工作”，那么我们可以认为可靠性大致意味着 ：即使发生了某些错误，系统仍可以继续正常工作。

可能出错的事情称为错误（ faults ）或故障，系统可应对错误则称为容错（ fault-­tolerant ）或者弹性（ resilient ）。 前一个词略显误导 ：似乎暗示着系统可以容忍各种可能的故障类型，显然实际中这是不可能的。举一个夸张一些的例子，如果整个地球（及其上的所有服务器）都被黑洞吞噬，那么要在这个级别容错就意味着必须在宇宙范围内进行系统冗余。试想，这将是天价的预算。因此，容错总是指特定类型的故障 ，这样的系统才更有实际意义。

注意， 故障与失效（ failure ） 不完全一 致 。故障通常被定义为组件偏离其正常规格，而失效意味系统作为一个整体停止，无法向用户提供所需的服务。我们不太可能将故障概率降低到零，因此通常设计容错机制来避免从故障引发系统失效。本书将介绍在不可靠组件基础上构建可靠性系统的相关技术。

在这种容错系统中，用于测试目的，可以故意提高故障发生概率，例如通过随机杀死某个进程，来确保系统仍保持健壮。很多关键的bug实际上正是由于错误处理不当而造成的。通过这种故意引发故障的方式，来持续检验、测试系统的容错机制，增加对真实发生故障时应对的信心。 Netflix的 Chaos Monkey系统就是这种测试的典型例子。

虽然我们通常倾向于容忍故障而不是预防故障，但是也存在“预防胜于治疗”的情况，安全问题就是一例，例如 ： 如果攻击者破坏了系统并窃取了敏感数据，则该事件造成的影响显然无法被撤销。然而，本书主要针对那些影响可以被消除的故障类型，接下来详细介绍。

#### **硬件故障**

当我们考虑系统故障时，对于硬件故障总是很容易想到 ： 硬盘崩溃，内存故障，电网停电，甚至有人误拔掉了网线。任何与大型数据中心合作过的人都可以告诉你，当有很多机器时，这类事情迟早会发生。

有研究证明硬盘的平均无故障时间（ MTTF ）约为 10 ～ 50年。因此，在一个包括10 000个磁盘的存储集群中，我们应该预期平均每天有一个磁盘发生故障。

我们的第一个反应通常是为硬件添加冗余来减少系统故障率。 例如对磁盘配置RAID ，服务器配备双电源，甚至热插拔CPU， 数据中心添加备用电源、发电机等。当一个组件发生故障，元余组件可以快速接管，之后再更换失效的组件。这种方法可能并不能完全防止硬件故障所引发的失效，但还是被普遍采用，且在实际中也确实可以让系统不间断运行长达数年。

#### **软件错误**

我们通常认为硬件故障之间多是相互独立的： 一台机器的磁盘出现故障并不意味着另一台机器的磁盘也要失效。除非存在某种弱相关（例如一些共性原因，如服务器机架中的温度过高），否则通常不太可能出现大量硬件组件同时失效的情况。

另一类故障则是系统内的软件问题。这些故障事先更加难以预料，而且因为节点之间是由软件关联的，因而往往会导致更多的系统故障 。 例如：

- 由于软件错误，导致当输入特定值时应用服务器总是崩溃。 例如， 2012年6月30日发生闰秒，由于Linux 内核中的一个bug ，导致了很多应用程序在该时刻发生挂起。
- 一个应用进程使用了某些共享如CPU、内存、磁盘或网络带宽 ，但却不幸失控跑飞了。
- 系统依赖于某些服务，但该服务突然变慢，甚至无响应或者开始返回异常的响应。
- 级联故障，其中某个组件的小故障触发另一个组件故障，进而引发更多的系统问题。

导致软件故障的bug通常会长时间处于引而不发的状态，直到碰到特定的触发条件。这也意味着系统软件其实对使用环境存在某种假设，而这种假设多数情况都可以满足，但是在特定情况下，假设条件变得不再成立 。

软件系统问题有时没有快速解决办法，而只能仔细考虑很多细节，包括认真检查依赖的假设条件与系统之间交互 ，进行全面的测试，进程隔离，允许进程崩愤并自动重启，反复评估，监控并分析生产环节的行为表现等。如果系统提供某些保证，例如，在消息队列中，输出消息的数量应等于输入消息的数量， 则可以不断地检查确认 ，如发现差异则立即告警。

#### **人为失误**

设计和构建软件系统总是由人类完成， 也是由人来运维这些系统。即使有时意图是好的，但人却无法做到万无一失。例如，一项针对大型互联网服务的调查发现，运维者的配置错误居然是系统下线的首要原因，而硬件问题（服务器或网络）仅在10%～25% 的故障中有所影响。

#### **可靠性的重要性**

可靠性绝不仅仅针对的是核电站和空中交管软件之类的系统，很多应用都需要可靠工作。商业软件中的错误会导致效率下降（如数据报告错误，甚至带来法律风险），电子商务网站的暂停会对营收和声誉带来巨大损失。

即使在所谓“非关键”应用中，我们也应秉持对用户负责的态度。例如一对父母，将其所有的照片以及他们孩子的视频存放在你的照片应用中。 如果不幸发生了数据库损坏，他们的感受可想而知，他们是否知道该如何从备份数据来执行恢复？

当然， 也会存在其他一些情况，例如面对不太确定的市场开发原型系统，或者服务的利润微薄，有时也会牺牲一些可靠性来降低开发成本或者运营开销，对此， 我们总是建议务必三思后行。

### **可扩展性**

即使系统现在工作可靠 ， 并不意味着它将来一定能够可靠运转。发生退化的一个常见原因是负载增加：例如也许并发用户从最初的 10 000个增长到 100 000个，或从 100万到 1000万；又或者系统目前要处理的数据量超出之前很多倍。

可扩展性是用来描述系统应对负载增加能力的术语。但是请注意，它并不是衡量一个系统的一维指标， 谈论“ X是可扩展 ”或“ Y不扩展”没有太大意义。相反，讨论可扩展性通常要考虑这类问题 ： “如果系统以某种方式增长，我们应对增长的措施有哪些”， “我们该如何添加计算资源来处理额外的负载” 。

#### **描述负载**

首先，我们需要简洁地描述系统当前的负载 ， 只有这样才能更好地讨论后续增长问题（例如负载加倍会意味着什么）。负载可以用称为负载参数的若干数字来描述。参数的最佳选择取决于系统的体系结构，它可能是Web服务器的每秒请求处理次数，数据库中写入的比例 ，聊天室的同时活动用户数量， 缓存命中率等。 有时平均值很重要 ，有时系统瓶颈来自于少数峰值 。

#### **描述性能**

描述系统负载之后，接下来设想如果负载增加将会发生什么。有两种考虑方式：

- 负载增加，但系统资源（如CPU、内存、网络带宽等）保持不变，系统性能会发生什么变化？
- 负载增加，如果要保持性能不变，需要增加多少资源？

这两个问题都会关注性能指标，所以我们先简要介绍一下如何描述系统性能。

在批处理系统如Hadoop 中 ，我们通常关心吞吐量 （ throughput ），即每秒可处理的记录条数 ，或者在某指定数据集上运行作业所需的总时间的 ；而在线系统通常更看重服务的响应时间（ response time），即客户端从发送请求到接收响应之间的间隔 。

即使是反复发送、处理相同的请求，每次可能都会产生略微不同的响应时间。实际情况往往更复杂，由于系统要处理各种不同的请求，晌应时间可能变化很大。因此，最好不要将响应时间视为一个固定的数字，而是可度量的一种数值分布。

我们经常考察的是服务请求的平均响应时间（严格来说，术语“平均值”并没有明确采用何种具体公式，但通常被理解为算术平均值：给定n个值，将所有值相加，并除以n ） 。然而，如果想知道更典型的响应时间，平均值并不是合适的指标 ，因为它掩盖了一些信息，无法告诉有多少用户实际经历了多少延迟。

因此最好使用百分位数（ percentiles ）。如果已经搜集到了响应时间信息，将其从最快到最慢排序，中位数（ median ）就是列表中间的响应时间。例如，如果中位数响应时间为200 ms ，那意味着有一半的请求响应不到 200 ms ，而另一半请求则需要更长的时间。

中位数指标非常适合描述多少用户需要等待多长时间： 一半的用户请求的服务时间少于中位数响应时间，另一半则多于中位数的时间。因此中位数也称为50百分位数，有时缩写为p50 。请注意，中位数对应单个请求 ：这也意味着如果某用户发了多个请求，那么它们中至少一个比中位数慢的概率远远大于50% 。

......

#### **应对负载增加的方法**

我们已经讨论了描述负载的参数以及衡量性能的相关指标，接下来讨论可扩展性：即当负载参数增加时， 应如何保持良好性能？

首先， 针对特定级别负载而设计的架构不太可能应付超出预设目标10倍的实际负载 。如果目标服务处于快速增长阶段，那么需要认真考虑每增加一个数量级的负载，架构应如何设计。

现在谈论更多的是如何在垂直扩展（即升级到更强大的机器）和水平扩展（即将负载分布到多个更小的机器）之间做取舍。在多台机器上分配负载也被称为无共享体系结构。在单台机器上运行的系统通常更简单，然而高端机器可能非常昂贵，且扩展水平有限，最终往往还是无法避免需要水平扩展。实际上，好的架构通常要做些实际取舍，例如，使用几个强悍的服务器仍可以比大量的小型虚拟机来得更简单、便宜。

某些系统具有弹性特征，它可以自动检测负载增加，然后自动添加更多计算资源，而其他系统则是手动扩展（人工分析性能表现，之后决定添加更多计算）。如果负载高度不可预测，则自动弹性系统会更加高效 ，但或许手动方式可以减少执行期间的意外情况（参阅第6章的“分区再平衡”）。

把无状态服务分布然后扩展至多台机器相对比较容易，而有状态服务从单个节点扩展到分布式多机环境的复杂性会大大增加。出于这个原因，直到最近通常的做法一直是，将数据库运行在一个节点上（采用垂直扩展策略）， 直到高扩展性或高可用性的要求迫使不得不做水平扩展。

然而，随着相关分布式系统专门组件和编程接口越来越好 ， 至少对于某些应用类型来讲，上述通常做法或许会发生改变。可以乐观设想 ，即使应用可能并不会处理大量数据或流量，但未来分布式数据系统将成为标配。在本书后续部分，我们将介绍多种分布式数据系统，不仅可以帮助提高可扩展性， 也会提高易用性与可维护性。

超大规模的系统往往针对特定应用而高度定制，很难有一种通用的架构。背后取舍因素包括数据读取量、写入量、待存储的数据量、数据的复杂程度、 响应时间要求、访问模式等，或者更多的是上述所有因素的叠加，再加上其他更复杂的问题。

例如，即使两个系统的数据吞吐量折算下来是一样的，但是为每秒处理 100000次请求（每个大小为 1KB ）而设计的系统，与为每分钟3个请求（每个大小为 2GB ）设计的系统会大不相同。

对于特定应用来说，扩展能力好的架构通常会做出某些假设，然后有针对性地优化设计，如哪些操作是最频繁的，哪些负载是少数情况。如果这些假设最终发现是错误的，那么可扩展性的努力就白费了，甚至会出现与设计预期完全相反的情况。对于早期的初创公司或者尚未定型的产品，快速迭代推出产品功能往往比投入精力来应对不可知的扩展性更为重要。

可扩展架构通常都是从通用模块逐步构建而来，背后往往有规律可循，所以本书将会讨论这些通用模块和常见模式，希望对读者有所借鉴。

### **可维护性**

众所周知，软件的大部分成本并不在最初的开发阶段，而是在于整个生命周期内持续的投入，这包括维护与缺陷修复，监控系统来保持正常运行、故障排查、适配新平台、搭配新场景、技术缺陷的完善以及增加新功能等。

不幸的是，许多从业人根本不喜欢维护这些所谓的遗留系统，例如修复他人埋下的错误，或者使用过时的开发平台，或者被迫做不喜欢的工作。坦白说，每一个遗留系统总有其过期的理由，所以很难给出一个通用的建议该如何处理它们。

但是，换个角度，我们可以从软件设计时开始考虑，尽可能较少维护期间的麻烦，甚至避免造出容易过期的系统。为此，我们将特别关注软件系统的三个设计原则 ：

- 可运维性

方便运营团队来保持系统平稳运行。

- 简单性

简化系统复杂性，使新工程师能够轻松理解系统。注意这与用户界面的简单性并不一样。

- 可演化性

后续工程师能够轻松地对系统进行改进，并根据需求变化将其适配到非典型场景，也称为可延伸性、易修改性或可塑性。

与可靠性和可扩展性类似，实现上述这些目标也没有简单的解决方案。接下来，我们首先建立对这三个特性的理解。

#### **可运维性：运维更轻松**

有人认为， “良好的操作性经常可以化解软件的局限性，而不规范的操作则可以轻松击垮软件”。虽然某些操作可以而且应该是自动化的 ，但最终还是需要人来执行配置并确保正常工作。

运营团队对于保持软件系统顺利运行至关重要。 一个优秀的运营团队通常至少负责以下内容:

- 监视系统的健康状况，并在服务出现异常状态时快速恢复服务。
- 追踪问题的原因，例如系统故障或性能下降。
- 保持软件和平台至最新状态， 例如安全补丁方面。
- 了解不同系统如何相互影响，避免执行带有破坏性的操作 。
- 预测未来可能的问题，并在问题发生之前及时解决（例如容量规划）。
- 建立用于部署、配置管理等良好的实践规范和工具包 。
- 执行复杂的维护任务， 例如将应用程序从一个平台迁移到另一个平台。
- 当配置更改时，维护系统的安全稳健。
- 制定流程来规范操作行为，并保持生产环境稳定 。
- 保持相关知识的传承（如对系统理解），例如发生团队人员离职或者新员工加入等。

良好的可操作性意味着使日常工作变得简单，使运营团队能够专注于高附加值的任务。数据系统设计可以在这方面贡献很多， 包括 ：

- 提供对系统运行时行为和内部的可观测性，方便监控。
- 支持自动化， 与标准工具集成 。
- 避免绑定特定的机器，这样在整个系统不间断运行的同时，允许机器停机维护。
- 提供良好的文档和易于理解的操作模式，诸如“如果我做了X ，会发生Y”。
- 提供良好的默认配置，且允许管理员在需要时方便地修改默认值。
- 尝试自我修复，在需要时让管理员手动控制系统状态 。
- 行为可预测，减少意外发生。

#### **简单性：简化复杂度**

小型软件项目通常可以写出简单而漂亮的代码 ，但随着项目越来越大，就会越来越复杂和难以理解。这种复杂性拖慢了开发效率，增加了维护成本。一个过于复杂的软件项目有时被称为一个“大泥潭”。

复杂性有各种各样的表现方式 ： 状态空间的膨胀，模块紧搞合，令人纠结的相互依赖关系， 不一致的命名和术语，为了性能而采取的特殊处理，为解决某特定问题而引人的特殊框架等。在参考文献中有很多这方面的讨论。

复杂性使得维护变得越来越困难， 最终会导致预算超支和开发进度滞后。对于复杂的软件系统，变更而引人潜在错误的风险会显著加大，最终开发人员更加难以准确理解、评估或者更加容易忽略相关系统行为，包括背后的假设，潜在的后果，设计之外的模块交互等。相反 ，降低复杂性可以大大提高软件的可维护性，因此简单性应该是我们构建系统的关键目标之一 。

简化系统设计并不意味着减少系统功能，而主要意味着消除意外方面的复杂性，正如Moseley和Marks把复杂性定义为一种“意外”，即它并非软件固有、被用户所见或感知，而是实现本身所衍生出来的问题。

消除意外复杂性最好手段之一是抽象。 一个好的设计抽象可以隐藏大量的实现细节，并对外提供干净、易懂的接口。 一个好的设计抽象可用于各种不同的应用程序。这样，复用远比多次重复实现更有效率；另一方面，也带来更高质量的软件，而质量过硬的抽象组件所带来的好处，可以使运行其上的所有应用轻松获益。

然而，设计好的抽象还是很有挑战性。在分布式系统领域中，虽然已有许多好的算法可供参考，但很多时候我们并不太清楚究竟该如何利用他们，封装到抽象接口之中，最终帮助将系统的复杂性降低到可靠控的级别。本书我们将广泛考察如何设计好的抽象，这样至少能够将大型系统的一部分抽象为定义明确、可重用的组件。

#### **可演化性：易于改变**

一成不变的系统需求几乎没有，想法和目标经常在不断变化：适配新的外部环境，新的用例，业务优先级的变化，用户要求的新功能，新平台取代旧平台，法律或监管要求的变化，业务增长促使架构的演变等。

在组织、流程方面 ，敏捷开发模式为适应变化提供了很好的参考。敏捷社区还发布了很多技术工具和模式，以帮助在频繁变化的环境中开发软件，例如测试驱动开发(TDD)和重构。

这些敏捷开发技术目前多数还只是针对小规模、本地模式（例如同一应用程序中的几个源代码文件）环境。本书将探索在更大的数据系统层面上提高敏捷性，系统由多个不同特性的应用或者服务协作而成 。 

我们的目标是可以轻松地修改数据系统，使其适应不断变化的需求，这和简单性与抽象性密切相关 ： 简单易懂的系统往往比复杂的系统更容易修改。这是一个非常重要的理念，我们将采用另一个不同的词来指代数据系统级的敏捷性 ， 即可演化性。

### **小结**

这一章我们探讨了一些关于数据密集型应用的基本原则，这些原则将指导如何阅读本书的其余部分。

一个应用必须完成预期的多种需求，主要包括功能性需求（即应该做什么，比如各种存储、检索、搜索和处理数据）和一些非功能性需求（ 即常规特性、例如安全性 、可靠性、合规性、可伸缩性、兼容性和可维护性） 。本章我们着重梳理讨论了可靠性、可扩展性和可维护性。

可靠性意味着即使发生故障，系统也可以正常工作。故障包括硬件（通常是随机的，不相关的）、软件（缺陷通常是系统的，更加难以处理）以及人为（总是很难避免时不时会出错）方面。容错技术可以很好地隐藏某种类型故障，避免影响最终用户。

可扩展性是指负载增加时， 有效保持系统性能的相关技术策略。为了讨论可扩展性，我们首先探讨了如何定量描述负载和性能。对于可扩展的系统，增加处理能力的同时，还可以在高负载情况下持续保持系统的高可靠性。

可维护性则意味着许多方面，但究其本质是为了让工程和运营团队更为轻松。良好的抽象可以帮助降低复杂性， 并使系统更易于修改和适配新场景。良好的可操作性意味着对系统健康状况有良好的可观测性和有效的管理方法。

然而知易行难，使应用程序可靠、可扩展或可维护并不容易。考虑到一些重要的模式和技术在很多不同应用中普遍适用，在接下来的几章中，我们就一些数据密集系统例子，分析它们如何实现上述这些目标。

# 第2章 数据模型与查询语言





# 第3章 数据存储与检索

从最基本的层面看，数据库只需做两件事情 ： 向它插入数据时，它就保存数据：之后查询时，它应该返回那些数据。

在第2章中，我们讨论了数据模型和查询语言，即关于应用开发人员向数据库指明数据格式并在之后如何查询的机制。本章我们主要从数据库的角度再来探讨同样的问题，即如何存储输入的数据，并在收到查询请求时，怎样重新找到数据。

作为一名应用系统开发人员，为什么要关注数据库内部的存储和检索呢？首先，你不太可能从头开始实现一套自己的存储引擎，往往只需要从众多现有的存储引擎中选择一个适合自己应用的存储引擎。 因此，为了针对你特定的工作负载而对数据库调优时，最好对存储引擎的底层机制有一个大概的了解。

特别地，针对事务型工作负载和针对分析型负载的存储引擎优化存在很大的差异。本章“事务处理与分析处理”和“面向列的存储”部分，将讨论一系列针对分析型进行优化的存储引擎。

我们首先讨论存储引擎 ，这些存储引擎用于大家比较熟悉的两种数据库，即传统的关系数据库和大多数所谓的NoSQL数据库。我们将研究两个存储引擎家族 ，即日志结构的存储引擎和面向页的存储引擎，比如B-tree 。

### **数据库核心：数据结构**

我们来看一个世界上最简单的数据库， 它由两个Bash 函数实现：

\#!/bin/bash db_set () {  echo "$1,$2" >> database } db_get () {  grep "^$1," database | sed -e "s/^$1,//" | tail -n 1 }

这两个函数实现了键值存储的功能。执行 db_set key value 会将 键（key） 和 值（value） 存储在数据库中。键和值（几乎）可以是你喜欢的任何东西，例如，值可以是 JSON 文档。然后调用 db_get key 会查找与该键关联的最新值并将其返回。

麻雀虽小，五脏俱全：

$ db_set 123456 '{"name":"London","attractions":["Big Ben","London Eye"]}' $ db_set 42 '{"name":"San Francisco","attractions":["Golden Gate Bridge"]}' $ db_get 42 {"name":"San Francisco","attractions":["Golden Gate Bridge"]}

底层的存储格式非常简单：一个文本文件，每行包含一条逗号分隔的键值对。每次对 db_set 的调用都会向文件末尾追加记录，所以每次更新键的时候旧版本的值不会被覆盖 —— 因而查找最新值的时候，需要找到文件中键最后一次出现的位置（因此 db_get 中使用了 tail -n 1 )。

$ db_set 42 '{"name":"San Francisco","attractions":["Exploratorium"]}' $ db_get 42 {"name":"San Francisco","attractions":["Exploratorium"]} $ cat database 123456,{"name":"London","attractions":["Big Ben","London Eye"]} 42,{"name":"San Francisco","attractions":["Golden Gate Bridge"]} 42,{"name":"San Francisco","attractions":["Exploratorium"]}

db_set 函数对于极其简单的场景其实有非常好的性能，因为在文件尾部追加写入通常是非常高效的。与 db_set 相似，许多数据库内部都使用日志（log），日志是一个仅支持追加（append-only）式更新的数据文件。虽然真正的数据库有更多更为复杂的问题需要考虑（例如并发控制、回收硬盘空间以控制日志文件大小、处理错误与部分完成写记录等），但基本原理是相同的。日志机制极其有用，我们还将在本书的其它部分多次提到它。

日志这个词通常指的是应用程序的运行输出日志，来记录发生了什么事情。在本书中，日志则是一个更为通用的含义，表示一个仅能追加的记录序列集合。它可能是人类不可读的，可能是二进制格式而只能被其他程序来读取。

另一方面，如果日志文件保存了大量的记录，那么 db_get 函数的性能会非常差。每次想查找一个键，db_get 必须从头到尾扫描整个数据库文件来查找键的出现位置。在算法术语中，查找的开销是 O(n） ，即如果数据库的记录条数加倍，则查找需要两倍的时间。这一点并不好。

为了高效地查找数据库中特定键的值 ， 需要新的数据结构： 索引。在本章中，我们将介绍一些索引结构并对它们进行比较 ；它们背后的基本想法都是保留一些额外的元数据，这些元数据作为路标，帮助定位想要的数据。如果希望用几种不同的方式搜索相同的数据，在数据的不同部分，我们可能定义多种不同的索引。

索引是基于原始数据派生而来的额外数据结构。很多数据库允许单独添加和删除索引，而不影响数据库的内容，它只会影响查询性能。维护额外的结构势必会引入开销，特别是在新数据写入时。对于写入，它很难超过简单地追加文件方式的性能，因为那已经是最简单的写操作了。由于每次写数据时，需要更新索引，因此任何类型的索引通常都会降低写的速度。

这里涉及存储系统中重要的权衡设计 ： 适当的索引可以加速读取查询，但每个索引都会减慢写速度。为此，默认情况下，数据库通常不会对所有内容进行索引 ，它需要应用开发人员或数据库管理员，基于对应用程序典型查询模式的了解，来手动选择索引。目的是为应用程序提供最有利加速的同时，避免引入过多不必要的开销 。

#### **哈希索引**

让我们从 键值数据（key-value Data） 索引开始。这不是你可以构建索引的唯一数据类型，但键值数据是很常见的。而且是其他更复杂索引的基础构造模块。

键值存储与大多数编程语言所内置的字典结构非常相似，通常采用hash map (或者hash table，哈希表)来实现。许多算法资料中都介绍过hash map，所以这里不再详细介绍它们工作的细节。既然我们已经可以用散列映射来表示内存中的数据结构，为什么不使用它来索引硬盘上的数据呢？

假设数据存储全部采用追加式文件组成，如之前的例子所示。那么最简单的索引策略就是:保存内存中的hash map，把每个键一一映射到数据文件中特定的字节偏移量这样就可以找到每个值的位置，如图3-1所示。每当在文件中追加新的key-value对时，还要更新hash map来反映刚刚写入数据的偏移量 （包括插入新的键和更新已有的键）。 当查找某个值时，使用 hash map来找到文件中的偏移量 ，即存储位置，然后读取其内容 。

​    ![0](https://note.youdao.com/yws/res/18447/WEBRESOURCE4d9f42910732ea7c44be44c4cf1fa0f0)

这听起来可能过于简单，但它的确是一个可行的方法 。事实上，这就是Bitcask (Riak中的默认存储引擎) 所采用的核心做法。 Bitcask可以提供高性能的读和写，只要所有的key可以放入内存（因为hash map需要保存在内存中） 。 而value数据量则可以超过内存大小，只需一次磁盘寻址，就可以将value从磁盘加载到内存。如果那部分数据文件已经在文件系统的缓存中，则读取根本不需要任何的磁盘I/O 。

像Bitcask这样的存储引擎非常适合每个键的值频繁更新的场景。例如， key可能是某个关于猫的视频URL, value是它播放的次数（每次有人单击播放按钮时就增加）。对于这种工作负载，有很多写操作，但是没有太多不同的key ，即每个key都有大量的写操作，但将所有key保存在内存中是可行的。

如上所述，只追加到一个文件，那么如何避免最终用尽磁盘空间？ 一个好的解决方案是将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。然后可以在这些段上执行压缩，如图 3-2所示 。 压缩意味着在日志中丢弃重复的键，并且只保留每个键最近的更新。

​    ![0](https://note.youdao.com/yws/res/18467/WEBRESOURCE13d33711c6089b7e79e538a6d7d48506)

此外，由于压缩往往使得段更小（假设键在段内被覆盖多次），也可以在执行压缩的同时将多个段合并在一起，如图 3-3 所示。由于段在写入后不会再进行修改，所以合并的段会被写入另一个新的文件。对于这些冻结段的合并和压缩过程可以在后台线程中完成，而且运行时，仍然可以用旧的段文件继续正常读取和写请求。当合并过程完成后，将读取请求切换到新的合并段上，而旧的段文件可以安全删除 。

​    ![0](https://note.youdao.com/yws/res/18472/WEBRESOURCEce07911844053f34fed532a2bdc9af54)

每个段现在都有自己的内存哈希表 ，将键映射到文件的偏移量。 为了找到键的值，首先检查最新的段的 hash map ；如果键不存在，检查第二最新的段，以此类推。由于合并过程可以维持较少的段数量 ，因此查找通常不需要检查很多 hash map 。还有很多细节方面的考虑才能使得这个简单的想法在实际中行之有效。简而言之，在真正地实现中有以下重要问题 ：

- 文件格式

csv不是日志的最佳格式 。 更快更简单的方法是使用二进制格式，首先以字节为单位来记录字符串的长度，之后跟上原始字符串（不需要转义）。

- 删除记录

如果要删除键和它关联的值，则必须在数据文件中追加一个特殊的删除记录（有时候称为墓碑）。当合并日志段时， 一旦发现墓碑标记，则会丢弃这个己删除键的所有值 。

- 崩溃恢复

如果数据库重新启动，则内存中的hash map将丢失 。原则上，可以通过从头到尾读取整个段文件，然后记录每个键的最新值的偏移量，来恢复每个段的 hash map 。 但是， 如果分段文件很大，可能扫描需要很长时间，这将使服务器重启变得缓慢。 Bitcask通过将每个段的 hash map的快照存储在磁盘上，可以更快地加载到内存中，以此加快恢复速度。

- 部分写入的记录

数据库随时可能崩溃，包括将记录追加到日志的过程中。 Bitcask文件包括校验值，这样可以发现损坏部分并丢弃。

- 并发控制

由于写入以严格的先后顺序追加到日志中，通常的实现选择是只有一个写线程。数据文件段是追加的， 并且是不可变的， 所以他们可以被多个线程同时读取。

一个追加的日志乍看起来似乎很浪费空间 ： 为什么不原地更新文件，用新值覆盖旧值？但是，结果证明追加式的设计非常不错，主要原因有以下几个 ：

- 追加和分段合并主要是顺序写，它通常比随机写入快得多，特别是在旋转式磁性硬盘上。在某种程度上，顺序写入在基于闪存的固态硬盘（ solid state drives,SSD ）上也是适合的。 我们将在本章后面的“比较B-tree和LSM-Trees”部分进一步讨论此问题 。
- 如果段文件是追加的或不可变的，则并发和崩溃恢复要简单得多。例如，不必担心在重写值时发生崩溃的情况，留下一个包含部分旧值和部分新值混杂在一起的文件。
- 合并旧段可以避免随着时间的推移数据文件出现碎片化的问题 。

但是，哈希表索引也有其局限性 ：

- 哈希表必须全部放入内存，所以如果有大量的键，就没那么幸运了。原则上，可以在磁盘上维护 hash map ，但不幸的是，很难使磁盘上的 hash map表现良好。它需要大量的随机访问 I/O ，当哈希变满时，继续增长代价昂贵，井且哈希冲突时需要复杂的处理逻辑。
- 区间查询效率不高。例如，不能简单地支持扫描kitty0000和 kitty9999 区间内的所有键，只能采用逐个查找的方式查询每一个键 。

在下一节中，我们将看到摆脱这些限制的其他索引结构。

#### **SSTables和LSM-Tree**

在图3-3中，每个日志结构的存储段都是一组key-value对的序列。这些 key-value对按照它们的写入顺序排列，并且对于出现在 日志中的同一个键，后出现的值优于之前的值。除此之外，文件中 key-value对的顺序并不重要。

现在简单地改变段文件的格式：要求key-value对的顺序按键排序。乍一看，这个要求似乎打破了顺序写规则，我们稍后会解释。

这种格式称为排序字符串表，或简称为SSTable。它要求每个键在每个合并的段文件中只能出现一次（压缩过程已经确保了）。 SSTable相比哈希索引的日志段，具有以下优点：

1、合并段更加简单高效，即使文件大于可用内存。方法类似于合并排序算法中使用的方法，如图3-4所示。并发读取多个输入段文件，比较每个文件的第一个键，把最小的键（根据排序顺序）拷贝到输出文件，并重复这个过程。这会产生一个新的按键排序的合并段文件。如果相同的键出现在多个输入段怎么办？请记住，每个段包含在某段时间内写入数据库的所有值。这意味着一个输入段中的所有值肯定比其他段中的所有值更新（假设总是合并相邻的段）。当多个段包含相同的键时，可以保留最新段的值，并丢弃旧段中的值。

2、在文件中查找特定的键时，不再需要在内存中保存所有键的索引。 以图3-5为例，假设正在查找键handiwork ，且不知道该键在段文件中的确切偏移。但是，如果知道键handbag和键handsome的偏移量 ，考虑到根据键排序，则键handiwork一定位于它们两者之间。这意味着可以跳到handbag的偏移，从那里开始扫描，直到找到handiwork。

所以，仍然需要一个内存索引来记录某些键的偏移，但它可以是稀疏的，由于可以很快扫描几千字节，对于段文件中每几千字节，只需要一个键就足够了。

​    ![0](https://note.youdao.com/yws/res/18550/WEBRESOURCE805a1f0827161220eee9e7bca03c9a4e)

​    ![0](https://note.youdao.com/yws/res/18552/WEBRESOURCEf9c86d4b026102e6b0759bd4dd4e63df)

3、由于读请求往往需要扫描请求范围内的多个key value对，可以考虑将这些记录保存到一个块中并在写磁盘之前将其压缩（如图 3-5 中阴影区域所示）。然后稀疏内存索引的每个条目指向压缩块的开头。除了节省磁盘空间，压缩还减少了I/O带宽的占用。

**构建和维护 SSTables**

到目前为止，似乎一切还算顺利，但是，考虑到写入可能以任意顺序出现，首先该如何让数据按键排序呢？在磁盘上维护排序结构是可行的（参阅本章后面的“ B-trees”），不过，将其保存在内存中更容易。内存排序有很多广为人知的树状数据结构，例如红黑树或AVL树。使用这些数据结构，可以按任意顺序插入键并以排序后的顺序，读取它们 。

存储引擎的基本工作流程如下 ：

- 当写入时，将其添加到内存中的平衡树数据结构中（例如红黑树）。这个内存中的树有时被称为内存表。
- 当内存表大于某个阈值（通常为几兆字节）时，将其作为 SSTable 文件写入磁盘。由于树已经维护了按键排序的 key - value对， 写磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。当 SSTable写磁盘的同时 ，写入可以继续添加到一个新的内存表实例 。
- 为了处理读请求，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件，以此类推，直到找到目标（或为空）。
- 后台进程周期性地执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值 。

上述方案可以很好地工作。但它还存在一个问题 ： 如果数据库崩溃，最近的写入（在内存表中但尚未写入磁盘）将会丢失。为了避免该问题，可以在磁盘上保留单独的日志，每个写入都会立即追加到该日志，就像上一节所述。那个日志文件不需要按键排序，这并不重要，因为它的唯一目的是在崩溃后恢复内存表。每当将内存表写入SSTable时，相应的日志可以被丢弃。

**从SSTables到LSM-Tree**

这里描述的算法本质上是LevelDB 和RocksDB 所使用的，主要用于嵌入到其他应用程序的 key-value 存储引擎库。除此之外，LevelDB可以在Riak中用作Bitcask的替代品。在Cassandra和HBase中使用了类似的存储引擎，这两种引擎都受到了Google的Bigtable论文（它引入了 SSTable和内存表这两个术语）的启发。	

最初这个索引结构 由Patrick O'Neil等人以日志结构的合井树（ Log-Structured MergeTree ，或LSM-Tree) [IOJ命名，它建立在更早期的日志结构文件系统之上 l 门 l 。因此，基于合井和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎。

#### **B-trees**

#### **对比B-tree和LSM-tree**

#### **其他索引结构**

### **事务处理与分析处理**

#### **数据仓库**

#### **星型与雪花型分析模式**

### **列式存储**

### **小结**

# 第4章 数据编码与演化



# **第二部分 分布式数据系统**

本书第一部分主要讨论了单台机器存储系统设计的主要技术。在第二部分，我们将继续向前迈进，当需要多台机器提供数据存储和检索服务时，又会有哪些挑战和方案呢？

主要出于以下目的，我们需要在多台机器上分布数据 ：

- 扩展性

当数据量或者读写负载巨大，严重超出了单台机器的处理上限，需要将负载分散到多台机器上。

- 容错与高可用性

当单台机器（或者多台，以及网络甚至整个数据中心）出现故障，还希望应用系统可以继续工作，这时需要采用多台机器提供冗余。这样某些组件失效之后，冗余组件可以迅速接管。

- 延迟考虑

如果客户遍布世界各地，通常需要考虑在全球范围内部署服务，以方便用户就近访问最近数据中心所提供的服务，从而避免数据请求跨越了半个地球才能到达目标。

**系统扩展能力**

当负载增加需要更强的处理能力时，最简单的办法就是购买更强大的机器（有时称为垂直扩展）。由一个操作系统管理更多的CPU ，内存和磁盘，通过高速内部总线使每个CPU都可以访问所有的存储器或磁盘。在这样一个共享内存架构中，所有这些组件的集合可看作一台大机器 。

共享内存架构的问题在于，成本增长过快甚至超过了线性 ：即如果把一台机器内的CPU数量增加一倍，内存扩容一倍，磁盘容量加大一倍，则最终总成本增加不止一倍。并且由于性能瓶颈因素，这样一台机器尽管拥有了两倍的硬件指标但却不一定能处理两倍的负载。

共享内存架构能够提供有限的容错能力，例如高端的服务器可以热插拔很多组件（在不关闭机器的情况下更换磁盘，内存模块，甚至是CPU ）。但很显然，它仍局限于某个特定的地理位置，无法提供异地容错能力。

另一种方法是共享磁盘架构，它拥有多台服务器，每个服务器各自拥有独立的CPU和内存，然后将数据存储在可共享访问的磁盘阵列上，服务器与磁盘阵列之间往往通过高速网络连接。这种架构多适用于数据仓库等负载，然而通常由于资源竞争以及锁的开销等限制了其进一步的扩展能力。

**无共享结构**

相比之下，无共享架构（也称为水平扩展）则获得了很大的关注度。当采用这种架构时，运行数据库软件的机器或者虚拟机称为节点。每个节点独立使用本地的CPU、内存和磁盘。节点之间的所有协调通信等任务全部运行在传统网络（以太网）之上且核心逻辑主要依靠软件来实现。

无共享系统不需要专门的硬件，具有较高的性价比。它可以跨多个地理区域分发数据，从而减少用户的访问延迟，甚至当整个数据中心发生灾难时仍能继续工作。通过云计算虚拟机的部署方式，即便是没有Google级别规模的小公司，也可以轻松拥有跨区域的分布式架构和服务能力。

本部分内容将重点放在无共享体系架构上，并不是因为它一定是所有应用的最佳选择，而是因为它需要应用开发者更多的关注和深入理解。例如把数据分布在多节点上，就需要了解在这样一个分布式系统下，背后的权衡设计和隐含限制，数据库并不能魔法般地把所有复杂性都屏蔽起来。

虽然分布式无共享体系架构具有很多优点，但也会给应用程序带来更多的复杂性，有时甚至会限制实际可用的数据模型。例如在某些极端情况下， 一个简单的单线程程序可能比一个拥有 100 多个CPU核的集群性能更好。 而另一方面，无共享系统也可以做到性能非常强大 。接下来的几章里我们将详细讨论数据分布时所面临的主要问题 。

**复制与分区**

将数据分布在多节点时有两种常见的方式：

- 复制

在多个节点上保存相同数据的副本，每个副本具体的存储位置可能不尽相同。复制方法可以提供冗余 ：如果某些节点发生不可用，则可以通过其他节点继续提供数据访问服务。复制也可以帮助提高系统性能。我们在第5章将主要讨论复制技术。

- 分区

将一个大块头的数据库拆分成多个较小的子集即分区，不同的分区分配给不同的节点（也称为分片）。我们在第6章主要介绍分区技术。

这些是不同的数据分布机制，然而它们经常被放在一起组合使用。参见图 II -1 的示例。

在了解以上概念之后，我们会讨论分布式环境中错综复杂的权衡之道 ，很可能你会在实际设计系统时不得不面对这些艰难选择 。我们将在第7章介绍事务，帮助理解数据系统中各种可能出错的情况以及处理方法，而第8章和第9章将深入分析分布式系统内在的局限性，之后结束本部分。

​    ![0](https://note.youdao.com/yws/res/18612/WEBRESOURCEf0f1c232a7ff7f08dd1b54164ce815fd)

在之后本书的第三部分， 我们将讨论如何把多个（可能每一个都是分布式）数据存储组件集成到一个更大的系统中，以满足更复杂的应用需求。 但在那之前，我们首先来谈谈分布式数据系统 。

## **第5章 数据复制**

复制主要指通过互联网络在多台机器上保存相同数据的副本。正如第二部分开头所介绍的，通过数据复制方案，人们通常希望达到以下目的：

- 使数据在地理位置上更接近用户，从而降低访问延迟 。
- 当部分组件出现位障，系统依然可以继续工作，从而提高可用性。
- 扩展至多台机器以同时提供数据访问服务，从而提高读吞吐量。

本章我们将假设数据规模比较小，集群的每一台机器都可以保存数据集的完整副本。在接下来的第6章中，我们放宽这一假设，讨论单台机器无法容纳整个数据集的情况（即必须分区）。在后面的章节中，我们还将讨论复制过程中可能出现的各种故障，以及该如何处理这些故障。

如果复制的数据一成不变，那么复制就非常容易：只需将数据复制到每个节点，一次即可搞定。然而所有的技术挑战都在于处理那些持续更改的数据，而这正是本章讨论的核心。我们将讨论三种流行的复制数据变化的方法：主从复制 、 多主节点复制和无主节点复制。几乎所有的分布式数据库都使用上述方法中的某一种， 而三种方法各有优缺点，我们稍后会详细解读。

复制技术存在许多需要折中考虑的地方，例如采用同步复制还是异步复制，以及如何处理失败的副本等。数据库通常采用可配置选项来调整这些处理策略，虽然在处理细节方面因数据库实现而异，但存在一些通用的一般性原则。本章我们还将再讨论不同选项可能出现的后果。

数据库复制其实是个很古老的话题。因为网络的基本约束条件没有发生本质的改变，可以说自1970年所研究的基本复制原则，时至今日也没有发生太大的变化。然而，除了学术研究，实践中很多开发人员仍然假定数据库只运行在单节点上，分布式数据库成为主流也只是最近发生的事情。由于许多应用开发人员在这方面经验还略显不足，对诸如“最终一致性”等问题存在一些误解。因此，在“复制滞后问题”中，我们会详细讨论最终一致性，包括读自己的写和单调读等。

### **主节点与从节点**

每个保存数据库完整数据集的节点称之为副本。当有了多副本，不可避免地会引人一个问题： 如何确保所有副本之间的数据是一致的？

对于每一笔数据写入，所有副本都需要随之更新：否则， 某些副本将出现不一致。最常见的解决方案是基于主节点的复制（也称为主动／被动，或主从复制），如图 5-1 所示。主从复制的工作原理如下 ：

1. 指定某一个副本为主副本 （或称为主节点） 。当客户写数据库时，必须将写请求首先发送给主副本，主副本首先将新数据写入本地存储。
2. 其他副本则全部称为从副本（或称为从节点）。主副本把新数据写入本地存储后，然后将数据更改作为复制的日志或更改流发送给所有从副本。每个从副本获得更改日志之后将其应用到本地，且严格保持与主副本相同的写入顺序。
3. 客户端从数据库中读数据时 ，可以在主副本或者从副本上执行查询。再次强调，只有主副本才可以接受写请求 ：从客户端的角度来看，从副本都是只读的。

​    ![0](https://note.youdao.com/yws/res/18688/WEBRESOURCE674f54936466e4280349b97e5e84bf2c)

#### **同步复制与异步复制**

复制非常重要的一个设计选项是同步复制还是异步复制。对于关系数据库系统，同步或异步通常是一个可配置的选项：而其他系统则可能是硬性指定或者只能二选一。

结合图 5-1 的例子，网站用户需要更新首页的头像图片。其基本流程是，客户将更新请求发送给主节点，主节点接收到请求，接下来将数据更新转发给从节点。最后，由主节点来通知客户更新完成。

图 5-2 则进一步描述了系统各个模块间的通信情况，包括客户端，主节点和两个从节点。 时间从左到右。请求或响应标记为粗箭头。

​    ![0](https://note.youdao.com/yws/res/18691/WEBRESOURCEbeba2d8b44bc30f3bf2b8a8025bed419)

图 5-2 中，从节点 1 的复制是同步的，即主节点需等待直到从节点 1 确认完成了写入，然后才会向用户报告完成，并且将最新的写入对其他客户端可见。而从节点 2 的复制是异步的： 主节点发送完消息之后立即返回，不用等待从节点2的完成确认。

图 5-2 中，从节点2在接收复制日志之前有一段很长的延迟。通常情况下， 复制速度会非常快，例如多数数据库系统可以在一秒之内完成所有从节点的更新。但是，系统其实并没有保证一定会在多长时间内完成复制。有些情况下，从节点可能落后主节点几分钟甚至更长时间，例如，由于从节点刚从故障中恢复，或者系统已经接近最大设计上限，或者节点之间的网络出现问题 。

同步复制的优点是， 一旦向用户确认，从节点可以明确保证完成了与主节点的更新同步，数据已经处于最新版本 。万一主节点发生故障，总是可以在从节点继续访问最新数据。缺点则是，如果同步的从节点无法完成确认（例如由于从节点发生崩溃，或者网络故障，或任何其他原因）， 写入就不能视为成功。 主节点会阻塞其后所有的写操作，直到同步副本确认完成 。

因此，把所有从节点都配置为同步复制有些不切实际。因为这样的话，任何一个同步节点的中断都会导致整个系统更新停滞不前 。实践中，如果数据库启用了同步复制，通常意味着其中某一个从节点是同步的，而其他节点则是异步模式。万一同步的从节点变得不可用或性能下降， 则将另一个异步的从节点提升为同步模式。这样可以保证至少有两个节点（即主节点和一个同步从节点）拥有最新的数据副本。这种配置有时也称为半同步。

主从复制还经常会被配置为全异步模式。 此时如果主节点发生失败且不可恢复 ，则所有尚未复制到从节点的写请求都会丢失。这意味着即使向客户端确认了写操作， 却无法保证数据的持久化。但全异步配置的优点则是，不管从节点上数据多么滞后， 主节点总是可以继续响应写请求，系统的吞吐性能更好 。异步模式这种弱化的持久性听起来是一个非常不靠谱的折中设计，但是异步复制还是被广泛使用，特别是那些从节点数量巨大或者分布于广域地理环境。我们将在本章后面的“复制滞后问题”继续这个话题。

#### **配置新的从节点**

当如果出现以下情况时，如需要增加副本数以提高容错能力，或者替换失败的副本，就需要考虑增加新的从节点。但如何确保新的从节点和主节点保持数据一致呢？

简单地将数据文件从一个节点复制到另一个节点通常是不够的。主要是因为客户端仍在不断向数据库写入新数据，数据始终处于不断变化之中，因此常规的文件拷贝方式将会导致不同节点上呈现出不同时间点的数据，这不是我们所期待的。

或许应该考虑锁定数据库（使其不可写）来使磁盘上的文件保持一致，但这会违反高可用的设计目标。好在我们可以做到在不停机、数据服务不中断的前提下完成从节点的设置。逻辑上的主要操作步骤如下：

1. 在某个时间点对主节点的数据副本产生一个一致性快照，这样避免长时间锁定整个数据库。目前大多数数据库都支持此功能，快照也是系统备份所必需的。而在某些情况下，可能需要第三方工具。
2. 将此快照拷贝到新的从节点 。
3. 从节点连接到主节点并请求快照点之后所发生的数据更改日志。因为在第一步创建快照时，快照与系统复制日志的某个确定位置相关联，这个位置信息在不同的系统有不同的称呼，如PostgreSQL将其称为“ log sequence number” （日志序列号），而MySQL将其称为“ binlog coordinates ” 。
4. 获得日志之后，从节点来应用这些快照点之后所有数据变更，这个过程称之为追赶。接下来，它可以继续处理主节点上新的数据变化。并重复步骤1～步骤4 。

建立新的从副本具体操作步骤可能因数据库系统而异。某些系统中 ，这个过程是全自动化的，而其他系统中所涉及的步骤、流程可能会比较复杂，甚至需要管理员手动介入。

#### **处理节点失效**

系统中的任何节点都可能因故障或者计划内的维护（例如重启节点以安装内核安全补丁）而导致中断甚至停机。如果能够在不停机的情况下重启某个节点，这会对运维带来巨大的便利。我们的目标是，尽管个别节点会出现中断，但要保持系统总体的持续运行，并尽可能减小节点中断带来的影响 。

那么如何通过主从复制技术来实现系统高可用呢？

##### **从节点失效：追赶式恢复**

从节点的本地磁盘上都保存了副本收到的数据变更日志。如果从节点发生崩溃，然后顺利重启，或者主从节点之间的网络发生暂时中断（闪断），则恢复比较容易，根据副本的复制日志，从节点可以知道在发生故障之前所处理的最后一笔事务，然后连接到主节点，并请求自那笔事务之后中断期间内所有的数据变更。在收到这些数据变更日志之后，将其应用到本地来追赶主节点。之后就和正常情况一样持续接收来自主节点数据流的变化。

##### **主节点失效：节点切换**

处理主节点故障的情况则比较棘手：选择某个从节点将其提升为主节点；客户端也需要更新，这样之后的写请求会发送给新的主节点，然后其他从节点要接受来自新的主节点上的变更数据，这一过程称之为切换。

故障切换可以手动进行，例如通知管理员主节点发生失效，采取必要的步骤来创建新的主节点；或者以自动方式进行。自动切换的步骤通常如下：

1. 确认主节点失效。有很多种出错可能性，例如由于系统崩溃，停电，网络问题等。没有万无一失的方法能够确切地检测到究竟问题出在哪里，所以大多数系统都采用了基于超时的机制：节点间频繁地互相发生发送心跳存活消息，如果发现某一个节点在一段比较长时间内（例如30s ）没有响应，即认为该节点发生失效（如果主节点在计划内出于维护目的而故意下线，则不在此讨论范围）。
2. 选举新的主节点。可以通过选举的方式（超过多数的节点达成共识）来选举新的主节点，或者由之前选定的某控制节点来指定新的主节点。候选节点最好与原主节点的数据差异最小，这样可以最小化数据丢失的风险。让所有节点同意新的主节点是个典型的共识问题，会在第9章详细讨论。
3. 重新配置系统使新主节点生效。客户端现在需要将写请求发送给新的主节点（细节将在第6章的“请求路由”中讨论）。如果原主节点之后重新上线，可能仍然自认为是主节点，而没有意识到其他节点已经达成共识迫使其下台。这时系统要确保原主节点降级为从节点，并认可新的主节点。

然而，上述切换过程依然充满了很多变数：

- 如果使用了异步复制，且失效之前，新的主节点并未收到原主节点的所有数据；在选举之后，原主节点很快又重新上线并加入到集群，接下来的写操作会发生什么？新的主节点很可能会收到冲突的写请求，这是因为原主节点未意识的角色变化，还会尝试同步其他从节点，但其中的一个现在已经接管成为现任主节点 。常见的解决方案是，原主节点上未完成复制的写请求就此丢弃，但这可能会违背数据更新持久化的承诺。
- 如果在数据库之外有其他系统依赖于数据库的内容并在一起协同使用，丢弃数据的方案就特别危险。例如，在GitHub的一个事故中，某个数据并非完全同步的MySQL从节点被提升为主副本，数据库使用了自增计数器将主键分配给新创建的行，但是因为新的主节点计数器落后于原主节点（ 即二者并非完全同步），它重新使用了已被原主节点分配出去的某些主键，而恰好这些主键已被外部Redis所引用，结果出现MySQL和Redis之间的不一致，最后导致了某些私有数据被错误地泄露给了其他用户。
- 在某些故障情况下（参见第8章），可能会发生两个节点同时都自认为是主节点。这种情况被称为脑裂，它非常危险：两个主节点都可能接受写请求，并且没有很好解决冲突的办法（参阅本章后面的“多主节点复制技术”），最后数据可能会丢失或者破坏 。作为一种安全应急方案，有些系统会采取措施来强制关闭其中一个节点。然而，如果设计或者实现考虑不周，可能会出现两个节点都被关闭的情况。
- 如何设置合适的超时来检测主节点失效呢？ 主节点失效后，超时时间设置得越长也意味着总体恢复时间就越长。但如果超时设置太短，可能会导致很多不必要的切换。例如，突发的负载峰值会导致节点的响应时间变长甚至超时，或者由于网络故障导致延迟增加。如果系统此时已经处于高负载压力或网络已经出现严重拥塞 ，不必要的切换操作只会使总体情况变得更糟。

坦白讲，对于这些问题没有简单的解决方案。因此，即使系统可能支持自动故障切换，有些运维团队仍然更愿意以手动方式来控制整个切换过程 。

上述这些问题，包括节点失效、网络不可靠、副本一致性、持久性、可用性与延迟之间各种细微的权衡，实际上正是分布式系统核心的基本问题。在第8章和第9章中，我们还会进一步讨论。

#### **复制日志的实现**

主从复制技术到底是如何工作呢？实践中有多种不同的实现方法， 此处我们逐一做些介绍 。

##### **基于语句的复制**

最简单的情况，主节点记录所执行的每个写请求（操作语句）并将该操作语句作为日志发送给从节点。对于关系数据库，这意味着每个 INSERT 、 UPDATE或DELETE语句都会转发给从节点，并且每个从节点都会分析并执行这些SQL语句，如同它们是来自客户端那样。

听起来很合理也不复杂，但这种复制方式有一些不适用的场景 ：

- 任何调用非确定性函数的语句，如NOW() 获取当前时间，或RAND()获取一个随机数等，可能会在不同的副本上产生不同的值。
- 如果语句中使用了自增列，或者依赖于数据库的现有数据（例如， UPDATE...WHERE ＜某些条件＞），则所有副本必须按照完全相同的顺序执行，否则可能会带来不同的结果。进而，如果有多个同时并发执行的事务时， 会有很大的限制 。
- 有副作用的语句（例如，触发器、存储过程、用户定义的函数等），可能会在每个副本上产生不同的副作用 。

有可能采取一些特殊措施来解决这些问题，例如，主节点可以在记录操作语句时将非确定性函数替换为执行之后的确定的结果，这样所有节点直接使用相同的结果值。但是，这里面存在太多边界条件需要考虑，因此目前通常首选的是其他复制实现方案。

##### **基于预写日志（ WAL) 传输**

在第3章中，我们讨论了存储引擎的磁盘数据结构，通常每个写操作都是以追加写的方式写入到日志中：

- 对于日志结构存储引擎（参阅第3章的“ SSTables和LSM-trees”），日志是主要的存储方式。日志段在后台压缩并支持垃圾回收。
- 对于采用覆盖写磁盘的Btree（参阅第3章的“B-tree”）结构，每次修改会预先写入日志，如系统发生崩溃，通过索引更新的方式迅速恢复到此前一致状态。

不管哪种情况，所有对数据库写入的字节序列都被记入日志。因此可以使用完全相同的日志在另一个节点上构建副本：除了将日志写入磁盘之外， 主节点还可以通过网络将其发送给从节点。

从节点收到日志进行处理，建立和主节点内容完全相同的数据副本。

PostgreSQL 、 Oracle以及其他系统等支持这种复制方式 。其主要缺点是日志描述的数据结果非常底层 ： 一个WAL包含了哪些磁盘块的哪些字节发生改变，诸如此类的细节。这使得复制方案和存储引擎紧密耦合。如果数据库的存储格式从一个版本改为另一个版本，那么系统通常无能支持主从节点上运行不同版本的软件。

看起来这似乎只是个有关实现方面的小细节，但可能对运营产生巨大的影响 。如果复制协议允许从节点的软件版本比主节点更新，则可以实现数据库软件的不停机升级：首先升级从节点，然后执行主节点切换，使升级后的从节点成为新的主节点。相反，复制协议如果要求版本必须严格一致（例如WAL传输），那么就势必以停机为代价。

##### **基于行的逻辑日志复制**

另一种方法是复制和存储引擎采用不同的日志格式，这样复制与存储逻辑剥离。这种复制日志称为逻辑日志，以区分物理存储引擎的数据表示。

关系数据库的逻辑日志通常是指一系列记录来描述数据表行级别的写请求：

- 对于行插入，日志包含所有相关列的新值。
- 对于行删除，日志里有足够的信息来唯一标识已删除的行，通常是靠主键，但如果表上没有定义主键，就需要记录所有列的旧值。
- 对于行更新，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少包含所有已更新列的新值）。

如果一条事务涉及多行的修改，则会产生多个这样的日志记录，并在后面跟着一条记录 ，指出该事务已经提交。 MySQL的二进制日志binlog （当配置为基于行的复制时）使用该方式。

由于逻辑日志与存储引擎逻辑解耦，因此可以更容易地保持向后兼容，从而使主从节点能够运行不同版本的软件甚至是不同的存储引擎。

对于外部应用程序来说，逻辑日志格式也更容易解析。如果要将数据库的内容发送到外部系统（如用于离线分析的数据仓库），或构建自定义索引和缓存等，基于逻辑日志的复制更有优势。该技术也被称为变更数据捕获，我们将在第11章中继续讨论 。

##### **基于触发器的复制**

### **复制滞后问题**

容忍节点故障只是使用复制其中的一个原因。正如第二部分开头所介绍的，其他原因包括可扩展性（采用多节点来处理更多的请求）和低延迟（将副本部署在地理上距离用户更近的地方）。

主从复制要求所有写请求都经由主节点，而任何副本只能接受只读查询。对于读操作密集的负载（如Web），这是一个不错的选择：创建多个从副本，将读请求分发给这些从副本，从而减轻主节点负载并允许读取请求就近满足。

在这种扩展体系下，只需添加更多的从副本，就可以提高读请求的服务吞吐量。但是，这种方法实际上只能用于异步复制，如果试图同步复制所有的从副本，则单个节点故障或网络中断将使整个系统无写入。而且节点越多，发生故障的概率越高，所以完全同步的配置现实中反而非常不可靠。

不幸的是，如果一个应用正好从一个异步的从节点读取数据，而该副本落后于主节点， 则应用可能会读到过期的信息。这会导致数据库中出现明显的不一致：由于并非所有的写入都反映在从副本上，如果同时对主节点和从节点发起相同的查询，可能会得到不同的结果。这种不一致只是一个暂时的状态，如果停止写数据库，经过一段时间之后，从节点最终会赶上并与主节点保持一致。这种效应也破称为最终一致性。

“最终”一词有些含糊不清， 总的来说，副本落后的程度理论上并没有上限 。 正常情况下，主节点和从节点上完成写操作之间的时间延迟（复制滞后）可能不足 1 秒，这样的滞后，在实践中通常不会导致太大影响。但是，如果系统已接近设计上限，或者网络存在问题， 则滞后可能轻松增加到几秒甚至几分钟不等。

当滞后后时间太长时 ，导致的不一致性不仅仅是一个理论存在的问题，而是个实实在在的现实问题。在本节中 ， 我们将重点介绍三个复制滞后可能出现的问题，并给出相应的解决思路。

#### **读自己的写**

许多应用让用户提交一些数据，接下来查看他们自己所提交的内容。例如客户数据库中的记录，亦或者是讨论主题的评论等。提交新数据须发送到主节点，但是当用户读取数据时 ，数据可能来自从节点 。 这对于读密集和偶尔写入的负载是个非常合适的方案。然而对于异步复制存在这样一个问题，如图 5-3 所示，用户在写入不久即查看数据 ，则新数据可能尚未到达从节点。对用户来讲， 看起来似乎是刚刚提交的数据丢失了，显然用户不会高兴。

​    ![0](https://note.youdao.com/yws/res/18840/WEBRESOURCE9e072664c227bc7818809aa80378c253)

对于这种情况，我们需要“写后读一致性”，也称为读写一致性。 该机制保证如果用户重新加载页面， 他们总能看到自己最近提交的更新。但对其他用户则没有任何保证，这些用户的更新可能会在稍后才能刷新看到。基于主从复制的系统该如何实现写后读一致性呢？有多种可行的方案，以下例举一二：

- 如果用户访问可能会被修改的内容，从主节点读取 ； 否则 ，在从节点读取。这背后就要求有一些方法在实际执行查询之前，就已经知道内容是否可能会被修改。例如，社交网络上的用户首页信息通常只能由所有者编辑，而其他人无法编辑。因此，这就形成一个简单的规则： 总是从主节点读取用户自己的首页配置文件，而在从节点读取其他用户的配置文件 。
- 如果应用的大部分内容都可能被所有用户修改，那么上述方法将不太有效，它会导致大部分内容都必须经由主节点，这就丧失了读操作的扩展性 。 此时需要其他方案来判断是否从主节点读取。例如，跟踪最近更新的时间 ，如果更新后一分钟之内，则总是在主节点读取；并监控从节点的复制滞后程度 ，避免从那些滞后时间超过一分钟的从节点读取 。
- 客户端还可以记住最近更新时的时间戳 ，并附带在读请求中，据此信息，系统可以确保对该用户提供读服务时都应该至少包含了该时间戳的更新 。 如果不够新，要么交由另一个副本来处理，要么等待直到副本接收到了最近的更新。 时间戳可以是逻辑时间戳（例如用来指示写入顺序的日志序列号）或实际系统时钟（在这种情况下，时钟同步又称为一个关键点 ， 请参阅第8章“不可靠的时钟”）。
- 如果副本分布在多数据中心（例如考虑与用户的地理接近，以及高可用性），情况会更复杂些。必须先把请求路由到主节点所在的数据中心（该数据中心可能离用户很远）。

如果同一用户可能会从多个设备访问数据，例如一个桌面Web浏览器和一个移动端的应用，情况会变得更加复杂 。 此时 ，要提供跨设备的写后读一致性， 即如果用户在某个设备上输入了一些信息然后在另一台设备上查看，也应该看到刚刚所输入的内容 。

在这种情况下，还有一些需要考虑的问题 ：

- 记住用户上次更新时间戳的方法实现起来会比较困难，因为在一台设备上运行的代码完全无法知道在其他设备上发生了什么。此时，元数据必须做到全局共享。
- 如果副本分布在多数据中心， 无法保证来自不同设备的连接经过路由之后都到达同一个数据中心。 例如，用户的台式计算机使用了家庭宽带连接，而移动设备则使用蜂窝数据网络，不同设备的网络连接线路可能完全不同。如果方案要求必须从主节点读取，则首先需要想办法确保将来自不同设备的请求路由到同一个数据中心。

#### **单调读**

在前面异步复制读异常的第二个例子里，出现了用户数据向后回滚的奇怪情况 。

假定用户从不同副本进行了多次读取，如图 5-4 所示，用户刷新一个网页，读请求可能被随机路由到某个从节点。用户 2345先后在两个从节点上执行了两次完全相同的查询（先是少量滞后的节点，然后是滞后很大的从节点），则很有可能出现以下情况。第一个查询返回了最近用户1234所添加的评论，但第二个查询因为滞后的原因，还没有收到更新因而返回结果是空。实际上，第二个查询结果代表了更早时间点的状态 。如果第一个查询没有返回任何内容，用户2345并不知道用户 1234最近的评论，情况还不算太糟糕，但当用户 2345看到了用户 1234的评论之后，紧接着评论又消失了，他就会感觉很困惑。

​    ![0](https://note.youdao.com/yws/res/18886/WEBRESOURCE6534bca6aaef44bfca296bfc7c359683)

单调读一致性可以确保不会发生这种异常。这是一个比强一致性弱 ，但比最终一致性强的保证 。当读取数据时，单调读保证，如果某个用户依次进行多次读取，则他绝不会看到回滚现象，即在读取较新值之后又发生读旧值的情况。

实现单调读的一种方式是，确保每个用户总是从固定的同一副本执行读取（而不同的用户可以从不同的副本读取）。例如，基于用户 ID 的哈希的方法而不是随机选择副本。但如果该副本发生失效，则用户的查询必须重新路由到另一个副本。

#### **前缀一致读**

第三个由于复制滞后导致因果反常的例子。例如Poons先生与Cake夫人之间的以下对话：

Poons先生

Cake夫人，您能看到多远的未来？

Cake夫人

通常约 10s, Poons先生。

这两句话之间存在因果关系： Cake夫人首先是听到了 Poons先生的问题，然后再去回答该问题。

现在，想象第三个人正在通过从节点收听上述对话。 Cake夫人所说的话经历了短暂的滞后到达该从节点，但Poons先生所说的经历了更长的滞后才到达（见图5-5 ）。观察者听到的对话变成这样：

Cake夫人

通常约 10s, Poons先生。

Poons先生

Cake夫人，您能看到多远的未来？

对于观察者来说，似乎在Poon先生提出问题之前， Cake夫人就开始了回答问题。首先，这种超自然的力量确认令人印象深刻，但逻辑上却是混乱的。

防止这种异常需要引人另一种保证：前缀一致读。该保证是说，对于一系列按照某个顺序发生的写请求，那么读取这些内容时也会按照当时写入的顺序。

这是分区（分片）数据库中出现的一个特殊问题，细节将在第6章中讨论。如果数据库总是以相同的顺序写入，则读取总是看到一致的序列，不会发生这种反常。然而，在许多分布式数据库中，不同的分区独立运行，因此不存在全局写入顺序。这就导致当用户从数据库中读数据时，可能会看到数据库的某部分旧值和另一部分新值。

​    ![0](https://note.youdao.com/yws/res/18918/WEBRESOURCE2cd4615e1cda4ec6b6897068a921584f)

一个解决方案是确保任何具有因果顺序关系的写入都交给一个分区来完成，但该方案真实实现效率会大打折扣 。现在有一些新的算法来显式地追踪事件因果关系，在本章稍后的“Happened-before关系与并发”会继续该问题的探讨。

#### **复制滞后的解决方案**

使用最终一致性系统时，最好事先就思考这样的问题：如果复制延迟增加到几分钟甚至几小时，那么应用层的行为会是什么样子？如果答案是“没问题”， 那没得说。但是，如果带来糟糕的用户体验，那么在设计系统肘，就要考虑提供一个更强的一致性保证，比如写后读 ； 如果系统设计时假定是同步复制，但最终它事实上成为了异步复制，就可能会导致灾难性后果。

正如前面所讨论的， 在应用层可以提供比底层数据库更强有力的保证。例如只在主节点上进行特定类型的读取，而代价则是，应用层代码中处理这些问题通常会非常复杂，且容易出错。

如果应用程序开发人员不必担心这么多底层的复制问题，而是假定数据库在“做正确的事情”，情况就变得很简单。而这也是事务存在的原因，事务是数据库提供更强保证的一种方式。

单节点上支持事务已经非常成熟。然而，在转向分布式数据库（即支持复制和分区）的过程中，有许多系统却选择放弃支持事务，并声称事务在性能与可用性方面代价过高，然后断言在可扩展的分布式系统中最终的一致性是无法避免的终极选择 。 关于这样的表述，首先它有一定道理，但情况远不是所说的那么简单，我们将在本书其余部分展开讨论，尝试形成一个更为深入的观点。例如在第7章和第9章将理解事务，然后在第三部分再介绍其他一些替代机制。

#### **GPT解释**

Q：解释复制滞后问题

------

数据复制是分布式系统中保持数据一致性和可用性的常见技术。它涉及将数据从一个节点复制到其他节点。然而，由于网络延迟、系统负载、复制算法的效率等因素，复制过程可能会遇到滞后，即复制延迟。这种滞后在分布式数据库和文件系统中较为常见，可能导致一系列问题。

复制滞后（Replication Lag）的原因:

1. 网络延迟：数据在节点之间传输时会受到网络速度和稳定性的影响，可能导致复制操作滞后。
2. 资源竞争：当目标节点正在处理高负载或资源竞争（如CPU、内存、磁盘I/O）时，它可能无法及时处理接收到的复制数据。
3. 复制机制：不同的复制策略可能会导致不同程度的滞后。例如，同步复制要求每次写操作都必须在所有副本上确认，这可能导致显著的延迟；而异步复制，尽管响应更快，但可能引入数据不一致的风险。
4. 单点瓶颈：在主从复制模式下，如果主节点处理大量的写操作，可能会形成复制瓶颈，因为所有的数据更改都必须被复制到从节点。
5. 事务大小和复杂性：大型事务或复杂的数据修改需要更多的处理时间和网络带宽来复制，可能导致复制滞后。

复制滞后可能导致的问题:

1. 数据一致性问题：读取操作可能会在复制滞后的节点上进行，导致读到旧的数据。
2. 备份数据不一致：如果备份操作在复制滞后的副本上执行，可能会导致备份的数据不一致。
3. 故障切换问题：在主节点发生故障时进行故障切换，如果从节点数据滞后，可能会导致数据丢失。
4. 用户体验不一致：在需要实时数据的应用中，用户可能会因为复制滞后而体验到数据不一致。

解决复制滞后的策略:

1. 优化复制通道：通过增加网络带宽、优化网络路由等方式减少网络延迟。
2. 负载均衡：避免单点瓶颈，通过负载均衡将写操作分散到多个节点。
3. 优化复制策略：使用更加高效的复制算法，如增量复制或压缩数据以减少网络传输量。
4. 监控和警报：实施复制监控，一旦检测到复制滞后就发出警报，快速响应和解决问题。
5. 读取优先级：在读取操作时优先选择最新数据的副本，以减少因复制滞后导致的数据不一致问题。

通过这些策略，系统管理员可以减少复制滞后的影响，确保分布式系统的高可用性和数据一致性。

### **多主节点复制**

到目前为止，我们只考虑了单个主节点的主从复制架构。 主从复制方法较为常见，但也存在其他一些有趣的方案。

首先，主从复制存在一个明显的缺点：系统只有一个主节点，而所有写人都必须经由主节点。如果由于某种原因，例如与主节点之间的网络中断而导致主节点无法连接，主从复制方案就会影响所有的写入操作。

对主从复制模型进行自然的扩展，则可以配置多个主节点，每个主节点都可以接受写操作，后面复制的流程类似 ： 处理写的每个主节点都必须将该数据更改转发到所有其他节点 。这就是多主节点（也称为主-主，或主动／主动）复制。 此时，每个主节点还同时扮演其他主节点的从节点。

#### **适用场景**

在一个数据中心内部使用多主节点基本没有太大意义，其复杂性已经超过所能带来的好处。但是，在以下场景这种配置则是合理的。

##### **多数据中心**

为了容忍整个数据中心级别故障或者更接近用户，可以把数据库的副本横跨多个数据中心。而如果使用常规的基于主从的复制模型，主节点势必只能放在其中的某一个数据中心，而所有写请求都必须经过该数据中心。有了多主节点复制模型，则可以在每个数据中心都配置主节点，如图 5-6 所示的基本架构。在每个数据中心内，采用常规的主从复制方案；而在数据中心之间，由各个数据中心的主节点来负责同其他数据中心的主节点进行数据的交换、更新。

​    ![0](https://note.youdao.com/yws/res/18948/WEBRESOURCEf68a2d01afd404cefd8239084d06be01)

可以对比一下在多数据中心环境下，部署单主节点的主从复制方案与多主复制方案之间的差异：

性能

对于主从复制，每个写请求都必须经由广域网传送至主节点所在的数据中心。这会大大增加写入延迟，井基本偏离 	了采用多数据中心的初衷 （即就近访问）。而在多主节点模型中，每个写操作都可以在本地数据中心快速响应，然后采用异步复制方式将变化同步到其他数据中心。因此 ，对上层应用有效屏蔽了数据中心之间的网络延迟，使得终端用户所体验到的性能更好。

容忍数据中心失效

对于主从复制，如果主节点所在的数据中心发生故障，必须切换至另一个数据中心，将其中的一个从节点被提升为主节点。在多主节点模型中，每个数据中心则可以独立于其他数据中心继续运行，发生故障的数据中心在恢复之后更新到最新状态。

容忍网络问题

数据中心之间的通信通常经由广域网，它往往不如数据中心内的本地网络可靠。对于主从复制模型，由于写请求是同步操作，对数据中心之间的网络性能和稳定性等更加依赖。多主节点模型则通常采用异步复制，可以更好地容忍此类问题，例如临时网络闪断不会妨碍写请求最终成功。

尽管多主复制具有上述优势，但也存在一个很大的缺点：不同的数据中心可能会同时修改相同的数据，因而必须解决潜在的写冲突（如图 5-6 中的“冲突解决”）。我们会在本章稍后的“处理写入冲突”详细介绍。

由于多主复制在许多数据库中还只是新增的高级功能，所以可能存在配置方面的细小缺陷；在与其他数据库功能（例如自增主键 ，触发器和完整性约束等）交互时有时会出现意想不到的副作用。出于这个原因， 一些人认为多主复制比较危险，应该谨慎使用或者避免使用。

##### **离线客户端操作**

另一种多主复制比较适合的场景是，应用在与网络断开后还需要继续工作。

比如手机，笔记本电脑和其他设备上的日历应用程序。无论设备当前是否联网，都需要能够随时查看当前的会议安排（对应于读请求）或者添加新的会议（对应于写请求）。在离线状态下进行的任何更改，会在下次设备上线时，与服务器以及其他设备同步。

这种情况下，每个设备都有一个充当主节点的本地数据库（用来接受写请求），然后在所有设备之间采用异步方式同步这些多主节点上的副本，同步滞后可能是几小时或者数天，具体时间取决于设备何时可以再次联网。

从架构层面来看，上述设置基本上等同于数据中心之间的多主复制，只不过是个极端情况，即一个设备就是数据中心，而且它们之间的网络连接非常不可靠。多个设备同步日历的例子表明，多主节点可以得到想要的结果，但中间过程依然有很多的未知数。

有一些工具可以使多主配置更为容易，如 CouchDB 就是为这种操作模式而设计的。

##### **协作编辑**

实时协作编辑应用程序允许多个用户同时编辑文档。例如， Etherpad和Google Docs 允许多人同时编辑文本文档或电子表格（算法简要会在本章后面的“自动冲突解决”中讨论）。

我们通常不会将协作编辑完全等价于数据库复制问题，但二者确实有很多相似之处。当一个用户编辑文档时，所做的更改会立即应用到本地副本（ Web浏览器或客户端应用程序），然后异步复制到服务器以及编辑同一文档的其他用户。

如果要确保不会发生编辑冲突，则应用程序必须先将文档锁定，然后才能对其进行编辑。如果另一个用户想要编辑同一个文档 ， 首先必须等到第一个用户提交修改并释放锁。这种协作模式相当于主从复制模型下在主节点上执行事务操作 。

为了加快协作编辑的效率， 可编辑的粒度需要非常小。例如，单个按键甚至是全程无锁。然而另一方面， 也会面临所有多主复制都存在的挑战 ， 即如何解决冲突。

#### **处理写冲突**

多主复制的最大问题是可能发生写冲突， 这意味着必须有方案来解决冲突。

例如，两个用户同时编辑Wiki页面，如图 5-7 所示。用户1将页面的标题从A更改为B ， 与此同时用户2却将标题从A改为 C 。每个用户的更改者都顺利地提交到本地主节点。 但是，当更改被异步复制到对方时，却发现存在冲突。 注意，正常情况下的主从复制则不会出现这种情况。

​    ![0](https://note.youdao.com/yws/res/18993/WEBRESOURCE0536eda4980262e8042d32f789f3d112)

##### **同步与异步冲突检测**

如果是主从复制数据库，第二个写请求要么会被阻塞直到第一个写完成， 要么被中止（用户必须重试） 。然而在多主节点的复制模型下，这两个写请求都是成功的，并且只能在稍后的时间点上才能异步检测到冲突，那时再要求用户层来解决冲突为时已晚 。

理论上， 也可以做到同步冲突检测，即等待写请求完成对所有副本的同步，然后再通知用户写入成功 。 但是，这样做将会失去多主节点的主要优势 ：允许每个主节点独立接受写请求。如果确实想要同步方式冲突检测 ，或许应该考虑采用单主节点的主从复制模型 。

##### **避免冲突**

处理冲突最理想的策略是避免发生冲突 ，即如果应用层可以保证对特定记录的写请求总是通过同一个主节点，这样就不会发生写冲突。现实中，由于不少多主节点复制模型所实现的冲突解决方案存在瑕疵，因此，避免冲突反而成为大家普遍推荐的首选方案。

例如， 一个应用系统中，用户需要更新自己的数据，那么我们确保特定用户的更新请求总是路由到特定的数据中心，并在该数据中心的主节点上进行读／写。不同的用户则可能对应不同的主数据中心（例如根据用户的地理位置来选择）。从用户的角度来看，这基本等价于主从复制模型。

但是，有时可能需要改变事先指定的主节点，例如由于该数据中心发生故障，不得不将流量重新路由到其他数据中心，或者是因为用户已经漫游到另一个位置，因而更靠近新数据中心。此时，冲突避免方式不再有效，必须有措施来处理同时写入冲突的可能性 。

##### **收敛于一致状态**

对于主从复制模型，数据更新符合顺序性原则，即如果同一个字段有多个更新，则最后一个写操作将决定该字段的最终值。

对于多主节点复制模型，由于不存在这样的写入顺序，所以最终值也会变得不确定。在图 5-7 中，主节点 1 接受到请求把标题更新为B ，然后更新为C ；而在主节点2 ，则是相反的更新顺序。两者都无法辩驳谁更正确。

如果每个副本都只是按照它所看到写入的顺序执行，那么数据库最终将处于不一致状态。例如主节点 1 看到最终值C ，而主节点2看到的是B ，这绝对是不可接受的， 所有的复制模型至少应该确保数据在所有副本中最终状态一定是一致的。因此，数据库必须以一种收敛趋同的方式来解决冲突，这也意味着当所有更改最终被复制、同步之后，所有副本的最终值是相同的。

实现收敛的冲突解决有以下可能的方式 ：

- 给每个写入分配唯一 的 ID ，例如， 一个时间戳， 一个足够长的随机数， 一个UUID或者一个基于键－值的哈希，挑选最高 ID的写入作为胜利者，并将其他写入丢弃。如果基于时间戳，这种技术被称为最后写入者获胜。 虽然这种方法很流行 ，但是很容易造成数据丢失。 我们将在本章最后部分来详细解释。
- 为每个副本分配一个唯一的 ID ，并制定规则，例如序号高的副本写入始终优先于序号低的副本。这种方法也可能会导致数据丢失。
- 以某种方式将这些值合并在一起。 例如，按字母顺序排序，然后拼接在一起（ 图5-7 中，合并的标题可能类似于“B/C”）。
- 利用预定义好的格式来记录和保留冲突相关的所有信息，然后依靠应用层的逻辑，事后解决冲突 （可能会提示用户） 。

##### **自定义冲突解决逻辑**

解决冲突最合适的方式可能还是依靠应用层，所以大多数多主节点复制模型都有工具来让用户编写应用代码来解决冲突。可以在写入时或在读取时执行这些代码逻辑：

在写入时执行

只要数据库系统在复制变更日志时检测到冲突，就会调用应用层的冲突处理程序。 例如， Bucardo支持编写一段Perl代码 。这个处理程序通常不能在线提示用户，而只能在后台运行，这样速度更快。

在读取时执行

当检测到冲突时 ，所有冲突写入值都会暂时保存下来。下一次读取数据时，会将数据的多个版本读返回给应用层。应用层可能会提示用户或自动解决冲突， 并将最后的结果返回到数据库。 CouchDB采用了这样的处理方式。

注意， 冲突解决通常用于单个行或文档， 而不是整个事务。因此，如果有一个原子事务包含多个不同写请求（如第7章） ，每个写请求仍然是分开考虑来解决冲突。

##### **什么是冲突？**

有些冲突是显而易见的 。在图 5-7 的例子中，两个写操作同时修改同一个记录中的同一个字段，并将其设置为不同的值。毫无疑问，这就是一个冲突。而其他类型的冲突可能会非常微妙，更难以发现。例如一个会议室预订系统，它主要记录哪个房间由哪个人在哪个时间段所预订。这个应用程序需要确保每个房间只能有一组人同时预定（即不得有相同房间的重复预订）。如果为同一个房间创建两个不同的预订，可能会发生冲突。尽管应用在预订时会检查房间是否可用，但如果两个预订是在两个不同的主节点上进行，则还是存在冲突的可能 。

很遗憾，这里没有现成的答案。通过接下来的几章，我们将对这个问题进行深入的剖析和讲解。我们将在第7章看到更多的冲突示例，在第12章中讨论检测和解决冲突的可扩展方法。

#### **拓扑结构**

复制的拓扑结构描述了写请求从一个节点的传播到其他节点的通信路径 。 如果有两个主节点，如图 5-7所示，则只存在一个合理的拓扑结构：主节点1必须把所有的写同步到主节点2 ，反之亦然。但如果存在两个以上的主节点， 则会有多个可能的同步拓扑结构，如图 5-8 所示。

​    ![0](https://note.youdao.com/yws/res/19142/WEBRESOURCE2c4cfd0fe0b067a174e3d3ca077678aa)

最常见的拓扑结构是全部－至－全部 ，见图 5 - 8 (c），每个主节点将其写入同步到其他所有主节点。 而其他一些拓扑结构也有普遍使用，例如，默认情况下MySQL只支持环形拓扑结构，其中的每个节点接收来自前序节点的写入，并将这些写入（加上自己的写入 ）转发给后序节点。另一种流行的拓扑是星形结构的：一个指定的根节点将写入转发给所有其他节点。星形拓扑还可以推广到树状结构。

在环形和星形拓扑中，写请求需要通过多个节点才能到达所有的副本，即中间节点需要转发从其他节点收到的数据变更。为防止无限循环，每个节点需要赋予一个唯一的标识符，在复制日志中的每个写请求都标记了已通过的节点标识符。如果某个节点收到了包含自身标识符的数据更改，表明该请求已经被处理过，因此会忽略此变更请求，避免重复转发。

环形和星形拓扑的问题是，如果某一个节点发生了故障，在修复之前，会影响其他节点之间复制日志的转发。可以采用重新配置拓扑结构的方法暂时排除掉故障节点。在大多数部署中，这种重新配置必须手动完成。而对于链接更密集的拓扑（如全部到全部），消息可以沿着不同的路径传播，避免了单点故障，因而有更好的容错性 。

但另一方面，全链接拓扑也存在一些自身的问题。主要是存在某些网络链路比其他链路更快的情况（例如由于不同网络拥塞），从而导致复制日志之间的覆盖，如图 5-9 所示。

在图 5-9 中，客户端A向主节点 1 的表中首先插入一行，然后客户端B在主节点3上对该行记录进行更新。而在主节点2上，由于网络原因可能出现意外的写日志复制顺序，例如它先接收到了主节点3的更新日志（从主节点2的角度来看，这是对数据库中不存在行的更新操作），之后才接收到主节点1的插入日志（按道理应该在更新日志之前到达）。

​    ![0](https://note.youdao.com/yws/res/19146/WEBRESOURCE627736ffb5ce50e1007ad395913cac10)

这里涉及到一个因果关系问题，类似于在本章前面“前缀一致读”所看到的：更新操作一定是依赖于先前完成的插入，因此我们要确保所有节点上一定先接收插入日志，然后再处理更新。在每笔写日志里简单地添加时间戳还不够，主要因为无法确保时钟完全同步，因而无法在主节点2上正确地排序所收到日志（参见第8章）。

为了使得日志消息正确有序，可以使用一种称为版本向量的技术，本章稍后将讨论这种技术（参见本章后面的“检测并发写入”）。需要指出，冲突检测技术在许多多主节点复制系统中的实现还不够完善，例如在撰写本书时， PostgreSQL BDR尚不支持写操作的因果排序，而MySQL的Tungsten Replicator 甚至还没有基本的冲突检测功能。

如果正在使用支持多主节点复制的系统，这些问题都值得注意，仔细查阅相关文档，详细测试这些数据库，以确保它确实提供所期望的功能。

### **无主节点复制**

到目前为止本章所讨论的复制方法，包括单主节点和多主节点复制，都是基于这样一种核心思路，即客户端先向某个节点（主节点）发送写请求，然后数据库系统负责将写请求复制到其他副本。由主节点决定写操作的顺序， 从节点按照相同的顺序来应用主节点所发送的写日志。

一些数据存储系统则采用了不同的设计思路：选择放弃主节点，允许任何副本直接接受来自客户端的写请求。其实最早的数据复制系统就是无主节点的（或称为去中心复制，无中心复制），但后来到了关系数据库主导的时代，这个想法被大家选择性遗忘了。当亚马逊内部采用了 Dynamo 系统之后，无主复制又再次成为一种时髦的数据库架构。 Riak、 Cassandra和Voldemort都是受Dynamo启发而设计的无主节点、开源数据库系统，这类数据库也被称为Dynamo风格数据库。

对于某些无主节点系统实现，客户端直接将其写请求发送到多副本，而在其他一些实现中，由一个协调者节点代表客户端进行写入，但与主节点的数据库不同，协调者并不负责写入顺序的维护。我们很快就会看到，这种设计上的差异对数据库的使用方式有着深刻的影响 。

#### **节点失效时写入数据库**

假设一个三副本数据库，其中一个副本当前不可用（例如正在重启以安装系统更新）。在基于主节点复制模型下，如果要继续处理写操作，则需要执行切换操作（参阅本章前面的“处理节点失效”）。

对于无主节点配置，则不存在这样的切换操作。图 5-10 展示了所发生的情况：用户1234将写请求并行发送到三个副本，有两个可用副本接受写请求，而不可用的副本无法处理该写请求。如果假定三个副本中有两个成功确认写操作，用户1234收到两个确认的回复之后，即可认为写入成功。客户完全可以忽略其中一个副本无法写入的情况 。

现在设想一下，失效的节点之后重新上线，而客户端又开始从中读取内容。由于节点失效期间发生的任何写入在该节点上都尚未同步，因此读取可能会得到过期的数据。

为了解决这个问题， 当一个客户端从数据库中读取数据时，它不是向一个副本发送请求，而是并行地发送到多个副本。客户端可能会得到不同节点的不同响应，包括某些节点的新值和某些节点的旧值。可以采用版本号技术确定哪个值更新（参见本章后面的“检测并发写入”）。

##### **读修复与反熵**

复制模型应确保所有数据最终复制到所有的副本。当一个失效的节点重新上线之后，它如何赶上中间错过的那些写请求呢？

​    ![0](https://note.youdao.com/yws/res/19186/WEBRESOURCE96d5b6a4a9bd88338f2f4fd20ba00f0a)

Dynamo风格的数据存储系统经常使用以下两种机制：

读修复

当客户端并行读取多个副本时，可以检测到过期的返回值。例如，在图 5-10 中 ，用户2345从副本3获得的是版本6 ，而从副本1和2得到的是版本7。 客户端可以判断副本3一个过期值，然后将新值写入到该副本。这种方法主要适合那些被频繁读取的场景。

反熵过程

此外， 一些数据存储有后台进程不断查找副本之间数据的差异，将任何缺少的数据从一个副本复制到另一个副本。与基于主节点复制的复制日志不同，此反熵过程并不保证以特定的顺序复制写入，并且会引入明显的同步滞后。

并不是所有的系统都实现了上述两种方案。例如，Voldemort 目前没有反熵过程。请注意， 当缺少反熵过程的支持时，由于读时修复只在发生读取时才可能执行修复，那些很少访问的数据有可能在某些副本中已经丢失而无法检测到，从而降低了写的持久性。

##### **读写quorum**

图 5-10 的例子中， 三个副本中如果有两个以上完成处理，写入即可认为成功。如果三个副本中只有一个完成了写请求，会怎样呢？依次类推，究竟多少个副本完成才可以认为写成功？

我们知道，成功的写操作要求三个副本中至少两个完成，这意味着至多有一个副本可能包含旧值。因此，在读取时需要至少向两个副本发起读请求，通过版本号可以确定一定至少有一个包含新值 。 如果第三个副本出现停机或响应缓慢， 则读取仍可以继续并返回最新值。

把上述道理推广到一般情况，如果有n个副本，写入需要w个节点确认，读取必须至少查询r个节点， 则只要 w+r > n ，读取的节点中一定会包含最新值。例如在前面的例子中，n = 3, w = 2, r = 2。满足上述这些r 、 w值的读／写操作称之为法定票数读（或仲裁读）或提定票数写（或仲裁写）。 也可以认为r和w是用于判定读、写是否有效的最低票数。

在Dynamo风格的数据库中，参数n、w 和 r 通常是可配置的。一个常见的选择是设置n为某奇数 (通常为3或5) ，w = r = (n + 1) /2 (向上舍入) 。也可以根据自己的需求灵活调整这些配置。例如，对于读多写少的负载，设置 w = n 和 r = 1 比较合适，这样读取速度更快，但是一个失效的节点就会使得数据库所有写入因无法完成quorum而失败。

仲裁条件 w + r > n 定义了系统可容忍的失效节点数，如下所示:

- 当w < n，如果一个节点不可用，仍然可以处理写入
- 当r < n，如果一个节点不可用，仍然可以处理读取
- 假定n=3，w=2，r= 2，则可以容忍一个不可用的节点
- 假定n= 5，w=3，r=3，则可以容忍两个不可用的节点。如图5-11所示
- 通常，读取和写入操作总是并行发送到所有的n个副本。 参数w和参数r只是决定要等待的节点数。即有多少个节点需要返回结果，我们才能判断出结果的正确性。

如果可用节点数小于所需的 w 或 r ，则写入或读取就会返回错误。不可用的原因可能有很多种，包括节点崩溃或者断电而关机，执行操作时出错（例如磁盘已满而无法写入），客户端和节点之间的网络中断等。这里，我们只需关心节点是否有返回值，而不需区分出错的具体原因。

​    ![0](https://note.youdao.com/yws/res/19243/WEBRESOURCEd9b456d55e2b581c1d84125fc36d6a5d)

##### **GPT解释**

Q：当某个节点由于维护或失效而暂时脱离集群时，如何处理副本之间的一致性问题？

------

你描述的是一种分布式数据库中常见的副本控制问题。在这种情况下，系统必须处理副本之间的一致性问题，尤其是当某个节点由于维护或失效而暂时脱离集群时。

**写操作和副本故障**：

在无主节点（leaderless）的配置中，客户端通常会向多个副本发送写请求以确保数据的持久化和可靠性。这通常涉及到对写入操作的确认过程，需要满足一定数量的副本（通常称为Quorum）对写操作给出响应才能认为写入操作成功。如果三个副本中至少有两个确认了写操作，则客户端可以认为写入成功，即使第三个副本暂时不可用。

**副本重新上线和一致性问题**：

当失效的副本重新上线时，它可能包含过时的数据，因为在它不可用期间，它错过了一些写操作。如果客户端直接从这个副本读取数据，可能会得到陈旧的信息。

为了解决这个问题，可以采取以下策略：

1. 读取修复（Read Repair）：当客户端从多个副本读取时，它可以比较不同副本返回的数据版本。如果检测到不一致（旧值与新值），客户端或数据库系统可以自动将最新的值写回那些包含旧数据的副本，这个过程称为读取修复。
2. 副本同步和修复(也叫反熵)：当一个失效的副本重新上线时，它需要与其他副本进行同步，以获取它在不可用期间错过的所有写操作。同步操作通常是由数据库系统自动执行的。
3. 向多个副本读取：为了减少读取到过时数据的风险，客户端可以从多个副本并行读取，并使用某种形式的版本控制（例如，时间戳或逻辑时钟）来确定哪个是最新的值。
4. 使用版本控制：在数据项中嵌入版本信息（如时间戳或逻辑时钟）可以帮助识别和处理不同副本间的数据不一致性。这样，客户端可以请求特定版本的数据，或者数据库系统可以确保只有最新版本的数据被返回给客户端。
5. Quorum读取：类似于写操作，读取操作也可以从多数副本中进行，这确保了至少一个副本包含了最新的写入。只有当超过半数的副本（Quorum）返回相同的结果时，客户端才接受该结果作为有效读取。

通过这些策略，分布式数据库系统可以确保即使在副本失效和重新上线的情况下，也能够维护数据的一致性（读取修复、反熵）和正确性（向多副本读取、Quorum读取）。这些策略的选择和设计通常取决于系统的特定需求，如一致性、可用性和延迟等。

#### **Quorum一致性的局限性**

如果有n个副本，并且配置w和r，使得 w + r > n，可以预期可以读取到一个最新值。之所以这样，是因为成功写入的节点集合和读取的节点集合必然有重合，这样读取的节点中至少有一个具有最新值 (见图5-11)。

通常，设定r和w为简单多数(多于n /2) 节点，即可确保w + r > n，且同时容忍多达n / 2个节点故障。但是，quorum不一定非得是多数，读和写的节点集中有一个重叠的节点才是最关键的。设定其他的quorum分配数也是可行的。

也可以将w和r设置为较小的数字，从而w + r <= n (即不满足仲裁条件)。此时，读取和写入操作仍会被发送到n个节点，但只需等待更少的节点回应即可返回。

由于w和r配置的节点数较小 ，读取请求当中可能恰好没有包含新值的节点，因此最终可能会返回一个过期的旧值。好的一方面是，这种配置可以获得更低的延迟和更高的可用性，例如网络中断， 许多副本变得无法访问，相比而言有更高的概率继续处理读取和写入。只有当可用的副本数已经低于w或r时， 数据库才会变得无法读／写， 即处于不可用状态。即使在w + r > n的情况下，也可能存在返回旧值的边界条件 。这主要取决于具体实现，可能的情况包括 ：

- 如果采用了sloppy quorum (参阅本章后面的“宽松的quorum与数据回传”)，写操作的w节点和读取的r节点可能完全不同，因此无法保证读写请求一定存在重叠的节点。
- 如果两个写操作同时发生，则无法明确先后顺序。这种情况下，唯一安全的解决方案是合并并发写入（参见本章前面的“处理写冲突”）。如果根据时间戳（最后写入获胜）挑选胜者，则由于时钟偏差问题，某些写入可能会被错误地抛弃。
- 如果写操作与读操作同时发生 ， 写操作可能仅在一部分副本上完成。此时，读取时返回旧值还是新值存在不确定性。
- 如果某些副本上已经写入成功，而其他一些副本发生写入失败（例如磁盘已满），且总的成功副本数少于w，那些已成功的副本上不会做回滚。这意味着尽管这样的写操作被视为失败，后续的读操作仍可能返回新值。
- 如果具有新值的节点后来发生失效，但恢复数据来自某个旧值， 则总的新值副本数会低于w，这就打破了之前的判定条件。
- 即使一切工作正常 ，也会出现一些边界情况，如第9章所介绍的“可线性化与quorum 。

因此，虽然quorum设计上似乎可以保证读取最新值， 但现实情况却往往更加复杂。Dynamo风格的数据库通常是针对最终一致性场景而优化的 。我们建议最好不要把参数w和r视为绝对的保证，而是一种灵活可调的读取新值的概率。

例如，这里通常无法得到本章前面的“复制滞后问题”中所罗列的一致性保证，包括写后读、单调读、前缀一致读等，因此前面讨论种种异常同样会发生在这里。如果确实需要更强的保证， 需要考虑事务与共识问题，接下来的第7章和第9章将对此展开讨论。

##### **监控旧值**

从运维角度来看，监视数据库是否返回最新结果非常重要。 即使应用程序可以容忍读取旧值，也需要仔细了解复制的当前运行状态。如果已经出现了明显的滞后，它就是个重要的信号提醒我们需要采取必要措施来排查原因（例如网络问题或节点超负荷）。

对于主从复制的系统，数据库通常会导出复制滞后的相关指标，可以将其集成到统一监控模块。原理大概是这样，由于主节点和从节点上写入都遵从相同的顺序，而每个节点都维护了复制日志执行的当前偏移量。 通过对比主节点和从节点当前偏移量的差值， 即可衡量该从节点落后于主节点的程度。

然而，对于无主节点复制的系统，并没有固定的写入顺序，因而监控就变得更加困难。而且，如果数据库只支持读时修复（不支持反熵），那么旧值的落后就没有一个上限。例如如果一个值很少被访问，那么所返回的旧值可能非常之古老。

目前针对无主节点复制系统已经有一些研究，根据参数 n, w 和 r 来预测读到旧值的期望百分比。不过，总体讲还不是很普及。即使如此 ，将旧值监控纳入到数据库标准指标集中还是很有必要。要知道，最终一致性其实是个非常模糊的保证，从可操作性上讲， 量化究竟何为“最终”很有实际价值。

##### **宽松的quorum与数据回传**

配置适当quorum的数据库系统可以容忍某些节点故障，也不需要执行故障切换。它们还可以容忍某些节点变慢，这是因为请求并不需要等待所有n个节点的响应，只需w或r节点响应即可。对于需要高可用和低延迟的场景来说，还可以容忍偶尔读取旧值，所有这些特性使之具有很高的吸引力。

但是， quorum并不总如期待的那样提供高容错能力。 一个网络中断可以很容易切断一个客户端到多数数据库节点的链接。尽管这些集群节点是活着的 ，而且其他客户端也确实可以正常链接，但是对于断掉链接的客户端来讲 ，情况无疑等价于集群整体失效。这种情况下，很可能无法满足最低的 w 和 r 所要求的节点数，因此导致客户端无能满足quorum要求。

在一个大规模集群中（节点数远大于n个），客户可能在网络中断期间还能连接到某些数据库节点，但这些节点又不是能够满足数据仲裁的那些节点。此时，数据库设计者就面临着一个选择：

- 如果无法达到w或r所要求quorum ，将错误明确地返回给客户端？
- 或者，我们是否应该接受该写请求，只是将它们暂时写入一些可访问的节点中？注意，这些节点并不在n节点集合中。

后一种方案称之为放松的仲裁 ：写入和读取仍然需要 w 和 r 个成功的响应，但包含了那些并不在先前指定的n个节点。 打个比方 ，如果你把不小心把自己锁在房子外面，可能会敲开邻居家的门，请求否可以坐在沙发上暂时休息一下。

一旦网络问题得到解决，临时节点需要把接收到的写入全部发送到原始主节点上。这就是所谓的数据回传（或暗示移交）。即一旦你找到了房子的钥匙，你的邻居会礼貌地请你离开沙发回到自己的家中 。

可以看出， sloppy quorum对于提高写入可用性特别有用：只要有任何w个节点可用，数据库就可以接受新的写入。然而这意味着，即使满足 w + r > n ，也不能保证在读取某个键时，一定能读到最新值，因为新值可能被临时写入n之外的某些节点且尚未回传过来。

因此，sloppy quorum并非传统意义上quorum。而更像是为了数据持久性而设计的一个保证措施，除非回传结束，否则它无法保证客户端一定能从r个节点读到新值。

目前，所有Dynamo风格的系统都已经支持sloppy quorum。在Riak中，默认启用，而在Cassandra和Voldemort中则默认关闭。

##### **多数据中心操作**

我们之前以多数据中心为例介绍了多主节点复制（参见本章前面的“多主节点复制”）。而无主节点复制由于旨在更好地容忍并发写入冲突，网络中断和延迟尖峰等，因此也可适用于多数据中心操作 。

Cassandra 和 Voldemort 在其默认配置的无主节点模型中都支持跨数据中心操作： 副本的数量n是包含所有数据中心的节点总数。配置时，可以指定每个数据中心各有多少副本。每个客户端的写入都会发送到所有副本，但客户端通常只会等待来自本地数据中心内的quorum节点数的确认，这样避免了高延迟和跨数据中心可能的网络异常。尽管可以灵活配置，但对远程数据中心的写入由于延迟很高，通常都被配置为异步方式。

Riak则将客户端与数据库节点之间的通信限制在一个数据中心内，因此n描述的是一个数据中心内的副本数量。 集群之间跨数据中心的复制则在后台异步运行，类似于多主节点复制风格。

#### **检测并发写**

Dynamo风格的数据库允许多个客户端对相同的主键同时发起写操作， 即使采用严格的quorum机制也可能会发生写冲突。这与多主节复制类似（参见本章前面的“处理写冲突”），此外，由于读时修复或者数据回传也会导致并发写冲突。

一个核心问题是，由于网络延迟不稳定或者局部失效，请求在不同的节点上可能会呈现不同的顺序。如图 5-12 所示，对于包含三个节点的数据系统，客户端A和B同时向主键X发起写请求 ：

- 节点1收到来自客户端A的写请求，但由于节点失效，没有收到客户端B的写请求。
- 节点2首先收到A的写请求，然后是B的写请求。
- 与节点2相反，节点3首先收到B的写请求，然后是A的写请求。

​    ![0](https://note.youdao.com/yws/res/19321/WEBRESOURCE634acaaf03e902e2ec89b9f068660641)

如果节点每当收到新的写请求时就简单地覆盖原有的主键，那么这些节点将永久无法达成一致，如图 5-12中的所示，节点2认为X的最终值是B ，而其他节点认为值是A 。

我们知道副本应该收敛于相同的内容，这样才能达成最终一致。但如何才能做到呢？有人可能希望数据副本之间能自动处理，然而非常不幸，目前大多数的系统实现都无法令人满意， 如果你不想丢失数据，应用开发者必须了解很多关于数据库内部冲突处理的机制。

我们已经在本章前面的“处理写冲突”简要介绍了一些解决冲突的技巧。在总结本章之前，我们来更详细地探讨这个问题。

##### **最后写入者获胜(丢弃并发写入)**

一种实现最终收敛的方法是，每个副本总是保存最新值，允许覆盖并丢弃旧值。 那么，假定每个写请求都最终同步到所有副本，只要我们有一个明确的方法来确定哪一个写入是最新的， 则副本可以最终收敛到相同的值。

这个想法其实有些争议，关键点在于前面所提到关于如何定义“最新”。在图 5-12 的例子中，当客户端向数据库节点发送写请求时， 一个客户端无法意识到另一个客户端，也不清楚哪一个先发生。其实 ，争辩哪个先发生没有太大意义， 当我们说支持写入并发，也就意味着它们的顺序是不确定的。

即使无法确定写请求的“自然顺序“，我们可以强制对其排序。例如，为每个写请求附加一个时间戳，然后选择最新即最大的时间戳，丢弃较早时间戳的写人。这个冲突解决算法被称为最后写入者获胜（ last write wins, LWW ），它是Cassandra仅有的冲突解决方法，而在Riak中，它是可选方案之一 。

LWW可以实现最终收敛的目标，但是以牺牲数据持久性为代价。如果同一个主键有多个并发写，即使这些并发写都向客户端报告成功（因为完成了写入w个副本），但最后只有一个写入值会存活下来，其他的将被系统默默丢弃 。 此外， LWW甚至可能会删除那些非并发写，我们将在第8章“时间戳与事件顺序”中举例说明（就是下面GPT回答的两个主要缺点）。在一些场景如缓存系统，覆盖写是可以接受的。如果覆盖、丢失数据不可接受，则LWW并不是解决冲突很好的选择。要确保LWW安全无副作用的唯一方法是，只写入一次然后写入值视为不可变，这样就避免了对同一个主键的并发（覆盖）写。 例如， Cassandra的一个推荐使用方法就是采用 UUID作为主键，这样每个写操作都针对的不同的、系统唯一的主键。

Q：LWW (Last-Write-Wins)的主要缺点？

------

LWW (Last-Write-Wins) 是一种冲突解决策略，通常用在分布式系统中的数据复制过程中。根据这个策略，如果有多个写操作同时发生，系统将接受具有最新时间戳的写操作。虽然这个策略简单直观，但它有一个主要的缺点，那就是不能区分“快速连续写操作”和“真正的并发写操作”。

1. 快速连续写操作：这种情况下，一个节点先后执行了多个写操作，每个后续的写操作都可能依赖于前一个写操作的结果。LWW策略可能无法正确体现这种操作序列中的因果关系，因为如果一个后续操作的时间戳由于某种原因（例如时钟偏差）比前一个操作的时间戳还早，那么这个后续的写操作可能会被错误地丢弃。
2. 真正的并发写操作：在这种场景中，多个客户端同时对同一个数据项进行写操作，而这些写操作之间不存在直接的因果关系。在这种情况下，LWW策略将简单地选择具有最新时间戳的写操作，而不考虑其他可能影响数据一致性的因素。

为了解决这些问题，分布式系统可能需要引入额外的机制来跟踪数据变更之间的因果关系。其中一种流行的方法是使用版本向量（Version Vectors）。

**版本向量**：

- 版本向量是一种跟踪分布式系统中不同副本状态的技术。
- 每个副本都维护自己的版本号，每次写操作都会更新这个版本号。
- 当副本间进行数据同步时，它们会比较彼此的版本向量来确定数据的新旧和因果关系。
- 如果一个写操作在因果关系上依赖于另一个写操作，版本向量会反映这种关系，从而允许系统保持数据的因果一致性。

使用版本向量可以帮助系统区分并解决因果关系下的写操作冲突，但它也带来了更高的复杂性和可能的性能开销。设计分布式系统时，需要权衡这些因素，并选择最适合特定应用场景的策略。

Q：LWW策略在真正的并发写操作时会出现哪些潜在问题呢？

------

在真正的并发写操作场景中，使用 LWW（Last-Write-Wins）策略可能会导致以下几个潜在问题：

1. 数据丢失：如果并发写操作修改了数据项的不同部分，使用 LWW 策略可能导致某些写操作所做的修改丢失，因为具有最新时间戳的写操作会覆盖其他所有写操作。
2. 时钟偏差导致的不一致：LWW 策略依赖于时间戳来解决写操作冲突。如果系统中各节点的时钟没有完美同步，可能导致实际上先发生的写操作拥有较晚的时间戳，而实际上后发生的写操作拥有较早的时间戳，进而导致错误的冲突解决。
3. 写操作顺序的歧义性（和时钟偏差相关）：并发写操作可能在用户的不同设备上几乎同时发生，时间戳可能无法精确反映这些操作的实际顺序，导致最终保留的写操作不一定是最合理或用户期望的结果。
4. 并发操作的语义冲突：LWW 不考虑操作的语义，因此无法处理涉及到不同写操作“意图”的情况。比如，两个并发操作分别试图将同一个计数器分别增加和减少一个单位，LWW 无法合理地解决这种语义上的冲突。
5. 用户体验问题：在用户协作的应用中（例如文档编辑器），如果多个用户同时编辑同一文档，LWW 策略可能导致用户的编辑被无意地覆盖，这会造成不良的用户体验。

为了解决这些问题，分布式系统设计者可能会采用其他策略或复合策略，例如：

- 多版本并发控制（MVCC）
- 操作转换（OT）或冲突自由复制数据类型（CRDTs）
- 手动冲突解决

选用哪种策略取决于具体的应用场景和一致性需求。在设计系统时，开发者需要仔细考虑这些因素，以确保系统能以一种可靠和用户友好的方式处理并发操作。

Q：能举例说明一下：写操作顺序的歧义性 这一点吗？

------

当然可以。让我们通过一个具体的例子来说明“写操作顺序的歧义性”：

假设有一个在线文档编辑平台，允许多个用户同时编辑同一篇文档。Alice 和 Bob 同时对文档的同一段落进行编辑：

1. 在 Alice 的设备上，她删除了段落中的一个句子，并添加了一些新的文本。她的设备记录了这次编辑的本地时间戳 

T1。

1. 在 Bob 的设备上，几乎与此同时，他修改了同一段落中的几个单词并更改了格式。他的设备记录了这次编辑的本地时间戳 T2。

由于网络延迟或时钟偏差，即使 Bob 的编辑在实际发生时早于 Alice 的编辑，Bob 的设备记录的时间戳 T2 可能比 Alice 的 T1 更晚。

如果在线文档平台使用 LWW 策略来解决冲突，那么平台只会保留具有最新时间戳的编辑——在这个例子中，假设是 Bob 的编辑。这意味着 Alice 所做的删除和添加操作将被完全覆盖，即使她的编辑在逻辑上可能是需要被保留的。

在这种情况下，两位作者的编辑可能都有价值，而且他们的操作并不一定冲突，因为他们编辑了段落的不同部分。但是由于 LWW 只考虑时间戳来确定哪个写操作“胜出”，这就导致了写操作顺序的歧义性问题。Alice 和 Bob 的编辑都希望被正确处理和反映在最终文档中，但 LWW 策略未能实现这一点。

这个例子展示了在并发编辑场景中，LWW 策略可能导致重要内容的丢失和用户期望的顺序与实际处理的顺序不一致的问题。为了避免这种情况，可能需要更复杂的冲突解决策略，如操作转换（OT）或冲突自由复制数据类型（CRDTs），它们可以更智能地合并并发编辑，而不是简单地基于时间戳选择一个写操作。

##### **Happens-before关系和并发**

如何判断两个操作是否是并发呢？首先为了建立起一个快速的直觉判断，我们先来看一些例子：

- 图5-9中，两个写入不是并发的:  A的插入操作发生在B的增量修改之前， B的递增是基于A插入的行。换句话说，B后发生，其操作建立在A基础之上。A和B属于因果依赖关系。
- 另一个例子，图5-12中的两个写入则是并发的:  每个客户端启动写操作时，并不知道另一个客户端是否也在同一个主键上执行操作。因此，操作之间不存在因果关系。

如果B知道A ，或者依赖于A ，或者以某种方式在A基础上构建，则称操作A在操作B之前发生 。 这是定义何为并发的关键。事实上，我们也可以简单地说，如果两个操作都不在另一个之前发生，那么操作是并发的（或者两者都不知道对方）。因此，对于两个操作A和B ， 一共存在三种可能性： A在B之前发生，或者B在A之前发生，或者A和B并发 。 我们需要的是一个算法来判定两个操作是否并发。如果一个操作发生在另一个操作之前，则后面的操作可以覆盖较早的操作。如果属于并发，就需要解决潜在的冲突问题。

##### **确定前后关系**

我们来看一个确定操作并发性的算法，即两个操作究竟属于并发还是一个发生在另一个之前（依赖关系）。简单起见，我们先从只有一个副本的数据库开始，在阐明其原理之后 ，将其推广到有多个副本的无主节点数据库。

图 5-13 的例子是两个客户端同时向购物篮车加商品（如果觉得这个例子太微不足道，可以类比为，两个空中交管员同时把飞机添加到他们所管理的追踪目标里）。初始时购物车为空。然后两个客户端向数据库共发出五次写入操作 ：

1、客户端1首先将牛奶加入购物车。这是第一次写入该主键的值，服务器保存成功然后分配版本1，服务器将值与版本号一起返回给该客户端1。

2、客户端2将鸡蛋加入购物车， 此时它并不知道客户端1已添加了牛奶，而是认为鸡蛋是购物车中的唯一物品。服务器为此写入并分配版本2 ，然后将鸡蛋和牛奶存储为两个单独的值，最好将这两个值与版本号2返回给客户端2 。

3、同理，客户端1也并不意识上述步骤2 ，想要将面粉加入购物车，且以为购物车的内容应该是［牛奶，面粉］，将此值与版本号1一起发送到服务器 。服务器可以从版本号中知道 ［牛奶，面粉］的新值要取代先前值 ［牛奶］ ，但值［鸡蛋］则是新的并发操作。因此，服务器将版本3分配给［牛奶，面粉］并覆盖版本1的 ［牛奶］，同时保留版本2的值［鸡蛋］，将二者同时返回给客户端 1 。

​    ![0](https://note.youdao.com/yws/res/19384/WEBRESOURCE7ecf9e623a5d2cd176b9df3b8dfce4f6)

4、同时 ， 客户端2想要加入火腿，也不知道客户端 1 刚刚加了面粉。其在最后一个响应中从服务器收到的两个值是［牛奶］和［蛋 ］ ，现在合并这些值，并添加火腿形成一个新的值 ［鸡蛋，牛奶，火腿]。它将该值与前一个版本号2一起发送到服务器。服务器检测到版本2会覆盖 ［鸡蛋］ ，但与 ［牛奶，面粉］是同时发生，所以设置为版本4并将所有这些值发送给客户端2 。

5、最后，客户端 1 想要加培根。它以前在版本 3 中从服务器接收 ［牛奶 ，面粉］和 ［鸡蛋 ］，所以合并这些值，添加培根， 并将最终值 ［牛奶，面粉，鸡蛋，培根］连同版本号3来覆盖［牛奶，面粉］，但与［鸡蛋，牛奶，火腿］并发，所以服务器会保留这些并发值。

图 5-13 操作之间的数据流可以通过图 5-14 形象展示。 箭头表示某个操作发生在另一个操作之前，即后面的操作“知道”或是“依赖”于前面的操作。在这个例子中，因为总有另一个操作同时进行，所以每个客户端都没有时时刻刻和服务器上的数据保持同步。但是，新版本值最终会覆盖旧值，且不会发生已写入值的丢失。

​    ![0](https://note.youdao.com/yws/res/19407/WEBRESOURCEad0143f24f25d9b93186ca71d4e1cccd)

需要注意的是，服务器判断操作是否并发的依据主要依靠对比版本号 ，而并不需要解释新旧值本身（值可以是任何数据结构）。算法的工作流程如下：

- 服务器为每个主键维护一个版本号，每当主键新值写入时递增版本号，并将新版本号与写入的值一起保存 。
- 当客户端读取主键时，服务器将返回所有（未被覆盖的）当前值以及最新的版本号。且要求写之前， 客户必须先发送读请求 。
- 客户端写主键，写请求必须包含之前读到的版本号、读到的值和新值合并后的集合。写请求的响应可以像读操作一样 ， 会返回所有当前值，这样就可以像购物车例子那样一步步链接起多个写入的值。
- 当服务器收到带有特定版本号的写入时， 覆盖该版本号或更低版本的所有值（因为知道这些值已经被合并到新传入的值集合中），但必须保存更高版本号的所有值（因为这些值与当前的写操作属于并发）。

当写请求包含了前一次读取的版本号时，意味着修改的是基于以前的状态。如果一个写请求没有包含版本号，它将与所有其他写入同时进行，不会覆盖任何已有值，其传入的值将包含在后续读请求的返回值列表当中。

###### **GPT解释**

个人对于这个部分还是很懵逼，在经过GPT的解释后大致明白了一些，我们看看GPT怎么解释的吧

------

这段文字描述了一种分布式系统中处理写入操作的方法，它使用版本号来确定数据项之间的因果关系（即操作的前后关系）。这种方法可以用于无主节点复制（master-less replication）系统，其中没有单一的权威来源来决定操作的顺序。下面是对这个过程的详细解释：

1. 版本号:  每个数据项（主键）都有一个与之相关联的版本号。每次更新数据项时，服务器都会递增这个版本号。新的版本号和写入的值一起保存，这样每个版本的数据项都有唯一的标识。
2. 读取操作:  当客户端想要更新一个数据项时，它必须先执行一个读取操作。服务器不仅返回数据项的当前值，还返回最新的版本号。客户端使用这个版本号来指明它想要基于哪个版本进行更新。
3. 写入操作:  在客户端进行写入操作时，它必须把之前读取到的版本号、读到的值以及新值合并后的结果一起发送给服务器。这样做可以确保服务器理解客户端的更新是基于数据的哪个状态，从而判断并发情况。
4. 处理写入:  服务器接收到写入请求后，会覆盖所有版本号小于或等于请求中版本号的值，因为这表示客户端在提出更新时已经知晓这些版本。然而，服务器必须保留所有版本号更高的值，因为这些值是在客户端读取之后新写入的，所以属于并发写入。
5. 并发写入:  如果写入请求不包含版本号，服务器会将其视为并发写入，这些写入不覆盖现有值。新值会被添加到数据项的版本集合中，并在后续的读取中返回，允许客户端看到所有并发的更新。

通过以上步骤，这种方法可以有效解决并发写入带来的冲突问题，使系统能够在无主节点复制的环境下正确处理并发更新。它允许客户端基于最新读取的状态执行更新，并确保客户端知晓并发更新的存在。这种方法特别适合于需要最终一致性的分布式数据库，如Amazon的DynamoDB或Apache Cassandra，这些数据库允许数据在没有单一主节点协调的情况下在多个副本之间复制和同步。

**Q：上述的方法可以来确定数据项之间的因果关系（即操作的前后关系）吗？**

------

是的，上述方法可以用来确定数据项之间的因果关系。这是如何操作的：

每次数据项更新时，服务器递增关联的版本号。版本号的递增性确保了每个更新都可以根据先后顺序进行追踪。当客户端进行写入操作时，它会基于之前读取的版本号进行更新，这意味着客户端知晓的数据状态和它想要基于该状态进行的更改。如果服务端收到了带有特定版本号的写入请求，它会根据这个版本号来覆盖或保留数据项的值。

这种依赖于版本号的方法确保了：

1. 因果关系的确定：

- - 每个写入操作都在客户端知晓的最新数据状态基础上进行，这样可以明确哪些写入是顺序发生的。

1. 并发操作的识别：

- - 当服务器收到的写入请求没有包含版本号，或者版本号高于当前版本，这意味着存在并发写入，服务器将保留这些值而不覆盖。

因此，通过版本号和这种读-改-写循环，分布式系统中的数据更新可以被准确地跟踪，并可以确定操作之间的因果关系。这种方法在多副本环境中尤其重要，因为它允许合理地处理并发更新，且避免了数据丢失的风险。

**Q: 举例说明？**

------

当然可以。假设我们有一个简单的在线购物车系统，这个系统是分布式的，没有主节点控制数据。现在想象两个用户（A 和 B）同时尝试更新同一个购物车，该购物车由一个键（例如购物车ID）标识，每个购物车都有一个与之关联的版本号。

以下是一个具体的操作序列示例，展示了用户如何使用版本号来读取和写入购物车内容：

1. 初始状态:

购物车的当前内容是：{apple, banana}，版本号是 1。

1. 用户 A 的操作:

用户 A 读取购物车，得到内容 {apple, banana} 和版本号 1。

用户 A 决定添加 cherry 到购物车，准备发送写入请求。

1. 用户 B 的操作:

用户 B 也读取购物车，得到相同的内容 {apple, banana} 和版本号 1。

用户 B 决定添加 orange 到购物车，准备发送写入请求。

1. 并发写入:

用户 A 发送写入请求，包括他读到的版本号 1 和新的购物车内容 {apple, banana, cherry}。

几乎同时，用户 B 发送写入请求，包括同样的版本号 1 和另一个新的购物车内容 {apple, banana, orange}。

1. 服务器处理写入请求:

服务器首先收到用户 A 的写入请求，更新购物车内容为 {apple, banana, cherry}，并将版本号递增到 2。

紧接着，服务器收到用户 B 的写入请求。因为用户 B 的写入是基于版本号 1，服务器不能简单地用 {apple, banana, orange} 覆盖购物车，因为这样会丢失用户 A 添加的 cherry。所以，服务器需要合并这两个更新，保留版本号更高的内容，并将用户 B 的更新应用在此基础上，形成 {apple, banana, cherry, orange}，版本号更新为 3。

1. 后续读取和写入:

如果用户 A 或 B 再次读取购物车，他们将看到合并后的内容 {apple, banana, cherry, orange} 和新的版本号 3。

如果用户 A 或 B 想要进行进一步的更新，他们需要基于版本号 3 的状态来进行，这样服务器就能正确跟踪哪些更新是基于最新的购物车状态。

在这个例子中，通过要求每个写入操作都携带客户端最后读取到的版本号，我们能够跟踪数据的修改序列，并且在发生并发修改时能够正确合并它们，从而避免数据丢失。这个过程是实现最终一致性和解决写入冲突的关键。

**Q: 能解释一下之前 "第5点 并发写入" 那段话吗？**

------

当然可以。这个“并发写入”的概念假设系统允许多个客户端在没有先前读取数据的情况下直接写入数据。因为没有先前的版本号信息，系统无法确定这些写入操作相对于其他操作的顺序。这种情况下，系统采取的策略是保留所有并发写入的值，而不是选择其中一个值覆盖其他值。这样可以防止数据丢失，并允许系统在以后处理这些并发写入。

举个例子，假设有一个分布式键值存储系统，其中有一个键 key1 关联着数据项。现在有两个客户端（客户端 C 和 客户端 D）同时写入不同的值到 key1，但没有提供先前读取到的版本号。

1. 并发写入:

客户端 C 写入 {key1: "Value from C"} 到系统。同时，客户端 D 也写入 {key1: "Value from D"} 到系统。

1. 服务器处理:

由于客户端 C 和 D 的写入请求都没有包含版本号，服务器认为这两个写入是并发发生的。服务器决定不覆盖任何值，而是将这两个并发写入的值都保存下来。

1. 版本集合:

服务器将 key1 的版本集合更新为包含两个值：["Value from C", "Value from D"]。这意味着 key1 现在有两个值，表示两个客户端的并发写入。

1. 读取操作:

当之后有客户端尝试读取 key1 的值时，服务器返回两个值的集合：["Value from C", "Value from D"]，以及与每个值相关联的版本号（如果有的话）。

这样客户端就可以知道 key1 有两个并发写入的值，并可以根据应用逻辑解决冲突（例如，合并这两个值，或者提示用户手动解决）。

在这个例子中，服务器避免了因选择一个写入而丢失另一个写入的风险。相反，它保留了所有并发写入的值，并将解决冲突的责任交给了客户端或应用逻辑。这种方法允许在没有丢失任何可能重要的信息的情况下处理并发写入，但它也要求客户端在处理这些并发值时能进行合适的合并或解决策略。

**通过GPT的解释就清晰很多了！！！**

##### **合并同时写入的值**

上述算法可以保证不会发生数据丢弃，但不幸的是，客户端需要做一些额外的工作: 即如果多个操作并发发生，则客户端必须通过合并并发写入的值来继承旧值。Riak称这些并发值为兄弟关系。

合并本质上与先前讨论的多节点复制冲突解决类似（参阅本章前面的“处理写冲突”）。 一个简单的方法是基于版本号或时间戳（即最后写入获胜）来选择其中的一个值，但这意味着会丢失部分数据。 所以，需要在应用程序代码中额外做些工作 。

以购物车为例，合并并发值的合理方式是包含新值和旧值（union操作）。 图 5-14 中，两个客户端最后的值分别是［牛奶，面粉，鸡蛋，熏肉 ］和［鸡蛋，牛奶，火腿 ］ 。注意，虽然牛奶和鸡蛋只是写入了一次，但它在两个客户端中均有出现。合并的最终值应该是 ［牛奶，面粉，鸡蛋，墙根，火腿]，其中去掉了重复值。

然而，设想一下人们也可以在购物车中删除商品， 此时把并发值都合并起来可能会导致错误的结果：如果合并了两个客户端的值，且其中有一个商品被某客户端删除掉，则被删除的项目会再次出现在合并的终值中。为了防止该问题，项目在删除时不能简单地从数据库中删除 ，系统必须保留一个对应的版本号以恰当的标记该项目需要在合并时被剔除。这种删除标记被称为墓碑 (之前我们在第3章“哈希索引”日志压缩时提到过)。

考虑到在应用代码中合并非常复杂且容易出错，因此可以设计一些专门的数据结构来自动执行合并，例如，Riak支持称为CRDT一系列数据结构，(具体参见本章前面的“自动冲突解决”)，以合理的方式高效自动合并，包括支持删除标记。

##### **版本矢量**

图 5-13 中的示例只有一个副本。如果存在多个副本但没有主节点，算法又该如何呢？

图 5-13 使用单个版本号来捕获操作之间的依赖关系，当多个副本同时接受写入时，这是不够的。因此我们需要为每个副本和每个主键均定义一个版本号。每个副本在处理写入时增加自己的版本号，并且跟踪从其他副本看到的版本号。通过这些信息来指示要覆盖哪些值、该保留哪些并发值。

所有副本的版本号集合称为版本矢量。这种思路还有一些变体，但最有趣的可能是在Riak 2.0 中使用的虚线版本矢量。我们无法在此深入其细节，但是它的工作方式与购物车例子所展示的非常相似。

与图 5-13 中版本号类似，当读取数据时，数据库副本会返回版本矢量给客户端，而在随后写入时需要将将版本信息包含在请求当中一起发送到数据库。 Riak将版本矢量编码为一个称之为因果上下文的字符串。版本矢量技术使数据库可以区分究竟应该覆盖写还是保留并发值。

另外，就像单副本的例子一样，应用程序仍然需要执行合并操作。版本矢量可以保证从某一个副本读取值然后写入到另一个副本，而这些值可能会导致在其他副本上衍生出来新的“兄弟”值，但至少不会发生数据丢失且可以正确合并所有并发值。

###### **GPT解释**

Q：详细说说版本向量工作流程和原理

------

版本向量是一种在分布式系统中用于跟踪和管理不同副本之间数据项状态的一致性和因果关系的技术。它们能够确定不同副本上的操作是否具有因果关系或是否并发。以下是版本向量的工作流程和原理：

**初始化**：

- 在系统初始化时，每个副本都会创建一个版本向量，其中包含所有副本的计数器，并初始化为0。

**写入操作**：

- 当一个副本上执行写入操作时，该副本的计数器在版本向量中递增。
- 新的数据状态会与更新的版本向量一起存储，这样就可以知道每个数据项的最新状态是如何确定的。

**更新传播**：

- 当一个副本更新了数据项后，它需要向系统中的其他副本传播这个更新，包括新的数据状态和关联的版本向量。
- 收到更新的副本会比较自己的版本向量和接收到的版本向量。

**因果关系的检测**：

- 如果接收到的版本向量在对应发送副本的计数器上比接收副本大1，而在其他副本上小于等于接收副本的计数器，这表明接收到的更新是因果序列中的下一步，可以安全地应用更新。
- 如果接收到的版本向量在其中任何一个计数器上都不大于接收副本的计数器，这意味着这个更新是基于该副本已知的信息的，因此没有新信息，可以忽略。

**并发更新的处理**：

- 如果接收到的版本向量在一个或多个计数器上大于本地计数器（除了对应发送副本的计数器之外），则表示发生了并发更新。
- 在这种情况下，副本需要合并并发更新，解决可能的冲突。这可以通过各种方法完成，如最终用户介入、合并策略或者其他冲突解决算法。

**更新本地版本向量**：

- 一旦更新被应用，接收副本会更新自己的版本向量。对于应用了更新的副本，其计数器将设置为接收到的版本向量中相应计数器的值。
- 对于其他的计数器，接收副本会设置为本地和接收到的版本向量中较大的那个值。

版本向量允许分布式系统达成事件发生的偏序关系，也就是确定哪些事件是先发生的，哪些事件是并发的。这种偏序关系对于协调副本之间的状态和解决数据冲突非常重要。

版本向量的主要优点是简单和高效，但同时也存在局限性。例如，当新副本加入或者旧副本永久离开系统时，版本向量需要进行调整。此外，如果副本数量很多，版本向量可能会变得很大，从而增加存储和传输的开销。

Q：能举例说一下你上面讲述的每一步吗，举一个综合的例子说明一下

------

当然可以。让我们假设有一个简单的分布式系统，该系统用于维护一个共享的字符串列表，此系统有三个副本：A、B和C。我们将通过一系列操作来说明版本向量的工作流程和原理。

**初始状态**：

- 所有副本的版本向量初始化为 [A:0, B:0, C:0]
- 列表在所有副本上都是空的

**步骤1：副本A添加一个元素**：

- 副本A向列表中添加字符串 "apple"，并将其版本向量更新为 [A:1, B:0, C:0]
- 副本A现在持有的数据是 ["apple"] 并且有一个关联的版本向量 [A:1, B:0, C:0]

**步骤2：副本A的更新传播到B和C**：

- 副本A将其更新 ("apple", [A:1, B:0, C:0]) 发送给副本B和C。
- 副本B和C比较接收到的版本向量与自己的版本向量，发现更新是顺序下一步（因为A计数器增加了1），因此它们都应用这个更新。
- 所有副本的列表现在都是 ["apple"]，副本B和C的版本向量分别更新为 [A:1, B:0, C:0]

**步骤3：副本B和C并发添加元素**：

- 副本B添加字符串 "banana"，版本向量更新为 [A:1, B:1, C:0]
- 与此同时，副本C添加字符串 "cherry"，版本向量更新为 [A:1, B:0, C:1]

**步骤4：副本B和C尝试传播它们的更新**：

- 副本B将其更新 ("banana", [A:1, B:1, C:0]) 发送给副本A和C。
- 副本C将其更新 ("cherry", [A:1, B:0, C:1]) 发送给副本A和B。

**步骤5：副本C和B处理并发更新**：

- 副本C接收到来自副本B的更新。它比较版本向量 [A:1, B:1, C:0]和[A:1, B:0, C:1]，发现它们在B和C上的计数器是不一致的，这意味着这是一个并发更新。
- 同时，副本B也检测到并发更新，因为它从副本C接收到了版本向量 [A:1, B:0, C:1]
- 两个副本都进行冲突解决，假设它们选择合并列表，副本B的列表更新为 ["apple", "banana", "cherry"]，版本向量变为 [A:1, B:1, C:1]。副本C同样更新为这个状态。

**步骤6：副本A接收并发更新**：

- 现在，副本A接收到副本B和C的更新，并执行同样的冲突解决策略，因此三个副本的最终状态都是：

- - 数据：["apple", "banana", "cherry"]
  - 版本向量：[A:1, B:1, C:1]

通过这个过程，我们可以看到版本向量如何帮助系统确定操作的因果关系和处理并发更新，确保分布式系统中的数据一致性。

### **小结**

本章，我们详细探讨了复制相关的话题。复制或者多副本技术主要服务于以下目的：

- 高可用性：即使某台机器（或多台机器，或整个数据中心）出现故障，系统也能保持正常运行。
- 连接断开与容错：允许应用程序在出现网络中断时继续工作。
- 低延迟：将数据放置在距离用户较近的地方，从而实现更快地交互。
- 可扩展性：采用多副本读取，大幅提高系统读操作的吞吐量 。

在多台机器上保存多份相同的数据副本，看似只是个很简单的目标，但事实上复制技术是一个非常烧脑的问题。需要仔细考虑并发以及所有可能出错的环节，并小心处理故障之后的各种情形。最最基本的，要处理好节点不可用与网络中断问题，这里甚至还没考虑一些更隐蔽的失效场景，例如由于软件bug而导致的无提示的数据损坏。

我们主要讨论了三种多副本方案：

主从复制

所有的客户端写入操作都发送到某一个节点（主节点），由该节点负责将数据更改事件发送到其他副本（从节点）。每个副本都可以接收读请求，但内容可能是过期值。

多主节点复制

系统存在多个主节点，每个都可以接收写请求，客户端将写请求发送到其中的一个主节点上，由该主节点负责将数据更改事件同步到其他主节点和自己的从节点。

无主节点复制

客户端将写请求发送到多个节点上，读取时从多个节点上并行读取，以此检测和纠正某些过期数据。

每种方也都有其优点和缺点。主从复制非常流行，主要是因为它很容易理解，也不需要担心冲突问题。而万一出现节点失效、网络中断或者延迟抖动等情况，多主节点和无主节点复制方案会更加可靠，不过背后的代价则是系统的复杂性和弱一致性保证。

复制可以是同步的，也可以是异步的，而一旦发生故障， 二者的表现差异会对系统行为产生深远的影响。在系统稳定状态下异步复制性能优秀，但仍须认真考虑一旦出现复制滞后和节点失效两种场景会导致何种影响。万一某个主节点发生故障，而一个异步更新的从节点被提升为新的主节点，要意识到最新确认的数据可能有丢失的风险。

我们还分析了由于复制滞后所引起的一些奇怪效应，并讨论了以下一致性模型，来帮助应用程序处理复制滞后：

写后读一致性

保证用户总能看到自己所提交的最新数据。

单调读

用户在某个时间点读到数据之后，保证此后不会出现比该时间点更早的数据 。

前缀一致读

保证数据之间的因果关系，例如，总是以正确的顺序先读取问题，然后看到回答。

最后，我们讨论了多主节点和无主节点复制方案所引人的并发问题。即由于多个写可能同时发生，继而可能产生冲突。为此，我们研究了一个算法使得数据库系统可以判定某操作是否发生在另一个操作之前，或者是同时发生。接下来，探讨采用合并并发更新值的方法来解决冲突。

下一章我们继续研究多节点上数据的分布问题，与本章不同的是，它是针对一个大型数据集而采用分区技术。

## **第6章 数据分区**

第5章讨论了复制技术，即在不同节点上保存相同数据的多个副本。然而，面对一些海量数据集或非常高的查询压力，复制技术还不够，我们还需要将数据拆分成为分区 ，也称为分片。

分区通常是这样定义的 ，即每一条数据（或者每条记录，每行或每个文档）只属于某个特定分区。实现的方法有多种，稍后将逐一介绍。实际上，每个分区都可以视为一个完整的小型数据库 ，虽然数据库可能存在一些跨分区的操作。

采用数据分区的主要目的是提高可扩展性。不同的分区可以放在一个无共享集群（参阅第二部分关于无共享架构的定义）的不同节点上。这样一个大数据集可以分散在更多的磁盘上，查询负载也随之分布到更多的处理器上 。

对单个分区进行查询时，每个节点对自己所在分区可以独立执行查询操作，因此添加更多的节点可以提高查询吞吐量。 超大而复杂的查询尽管比较困难，但也可能做到跨节点的并行处理。

分区数据库最初在20世纪80年代由 Teradata和Tandem NonStop SQL等率先推出， 最近又被一些No SQL数据库和基于Hadoop的数据仓库重视起来。这些系统有些是为事务型负载设计的，有些是分析型（参阅第3章的“事务处理与分析处理”）。 二者的差异会显著影响系统的优化策略 ，然而分区技术的基本原理则可以普遍适用。

本章我们将首先介绍切分大型数据集的若干方法，讨论数据索引如何影响分区。接下来讨论分区的再平衡 ，这对动态添加或删除节点非常重要。最后，我们将介绍数据库如何将请求路由到正确的分区并执行查询。

### **数据分区与数据复制**

分区通常与复制结合使用，即每个分区在多个节点都存有副本。这意味着某条记录属于特定的分区 ，而同样的内容会保存在不同的节点上以提高系统的容错性。

一个节点上可能存储了多个分区。图 6-1 展示了主从复制模型与分区组合使用时数据的分布情况。由图可知，每个分区都有自己的主副本，例如被分配给某节点，而从副本则分配在其他一些节点。 一个节点可能即是某些分区的主副本，同时又是其他分区的从副本。

第5章所讨论的所有复制相关的原理同样适用于对分区数据的复制 。考虑到分区方案的选择通常独立于复制，因此本章将力求简洁，而省略与复制相关的内容。

### **键-值数据的分区**

假设面临海量数据，现在需要切分它们 ，那么该如何决定哪些记录放在哪些节点上呢？

分区的主要目标是将数据和查询负载均匀分布在所有节点上 。 如果节点平均分担负载 ，那么理论上10个节点应该能够处理10倍的数据量和10倍于单个节点的读写吞吐量（忽略复制） 。

​    ![0](https://note.youdao.com/yws/res/19540/WEBRESOURCE12342c9d04470be4568cd3deb8c06eb1)

而如果分区不均匀，则会出现某些分区节点比其他分区承担更多的数据量或查询负载，称之为倾斜。倾斜会导致分区效率严重下降，在极端情况下，所有的负载可能会集中在一个分区节点上，这就意味着10个节点9个空闲，系统的瓶颈在最繁忙的那个节点上。这种负载严重不成比例的分区即成为系统热点。

避免热点最简单的方法是将记录随机分配给所有节点上。这种方也可以比较均匀地分布数据，但是有一个很大的缺点 ： 当试图读取特定的数据时，没有办法知道数据保存在哪个节点上，所以不得不并行查询所有节点。

可以改进上述方法 。现在我们假设数据是简单的键－值数据模型 ，这意味着总是可以通过关键字来访问记录 。 例如，像一个纸质百科全书，可以通过标题来查找某一个条目；而所有的条目按字母序排序，因此可以做到快速查找条目。

#### **基于关键字区间分区**

一种分区方式是为每个分区分配一段连续的关键字或者关键字区间范围（以最小值和最大值来指示），如图 6-2 所示的纸质百科全书的卷目录。如果知道关键字区间的上下限，就可以轻松确定哪个分区包含这些关键字。 如果还知道哪个分区分配在哪个节点，就可以直接向该节点发出请求（对于百科全书的例子，就是从书架上直接取到所要的书籍）。

​    ![0](https://note.youdao.com/yws/res/19595/WEBRESOURCE1aa81492934529ab09b0f5cefe5bd0c6)

关键字的区间段不一定非要均匀分布，这主要是因为数据本身可能就不均匀。例如，在图 6-2中，卷 1 只包含以A和B开头的单词，但是卷12则包含了T 、 U 、 V 、 X 、 Y和Z开始的单词。如果只是简单地规定每个分区包含两个字母，则可能会导致一些卷比其他卷要大很多。为了更均匀地分布数据，分区边界理应适配数据本身的分布特征。

分区边界可以由管理员手动确定，或者由数据库自动选择（我们将在本章后面的“分区再平衡”中更详细地讨论）。采用这种分区策略的系统包括Bigtable, Bigtable的开源版本HBase, RethinkDB和2.4版本之前MongoDB。

每个分区内可以按照关键字排序保存（参阅第3章的“ SSTables和LSM Trees”）。这样可以轻松支持区间查询。例如，对于一个保存网络传感器数据的应用系统，选择测量的时间戳（年月日时分秒）作为关键字，此时区间查询会非常有用，它可以快速获得某个月份内的所有数据。

然而，基于关键字的区间分区的缺点是某些访问模式会导致热点。如果关键字是时间戳，则分区对应于一个时间范围，例如每天一个分区。然而，当测量数据从传感器写入数据库时，所有的写入操作都集中在同一个分区（即当天的分区），这会导致该分区在写入时负载过高，而其他分区始终处于空闲状态。

为了避免上述问题，需要使用时间戳以外的其他内容作为关键字的第一项。例如，可以在时间戳前面加上传感器名称作为前缀，这样首先由传感器名称，然后按时间进行分区。假设同时有许多传感器处于活动状态，则写入负载最终会比较均匀地分布在多个节点上。接下来，当需要获取一个时间范围内、多个传感器的数据时，可以根据传感器名称，各自执行区间查询。

#### **基于关键字哈希值分区**

对于上述数据倾斜与热点问题，许多分布式系统采用了基于关键字哈希函数的方式来分区。

一个好的哈希函数可以处理数据倾斜并使其均匀分布 。 例如一个处理字符串的32位哈希函数，当输入某个字符串，它会返回一个0和 2^32～ 1 之间近似随机分布的数值。即使输入的字符串非常相似，返回的哈希值也会在上述数字范围内均匀分布。

用于数据分区目的的哈希函数不需要在加密方面很强: 例如，Cassandra和MongoDB使用MD5，Voldemort使用Fowler-Noll-Vo函数。许多编程语言也有内置的简单哈希函数 (主要用于哈希表)，但是要注意这些内置的哈希函数可能并不适合分区，例如，Java的obiect.hashCode和Ruby的obiect#hash，同一个键在不同的进程中可能返回不同的哈希值。

一旦找到合适的关键字哈希函数，就可以为每个分区分配一个哈希范围（而不是直接作用于关键字范围），关键字根据其哈希值的范围划分到不同的分区中。如图 6-3 所示。

​    ![0](https://note.youdao.com/yws/res/19612/WEBRESOURCEaeda849953110c612c8cb110db543e32)

这种方法可以很好地将关键字均匀地分配到多个分区中。分区边界可以是均匀间隔，也可以是伪随机选择（在这种情况下，该技术有时被称为一致性哈希 ） 。

然而，通过关键字哈希进行分区，我们丧失了良好的区间查询特性。即使关键字相邻，但经过哈希之后会分散在不同的分区中，区间查询就失去了原有的有序相邻的特性。 在MongoDB 中，如果启用了基于哈希的分片模式，则区间查询会发送到所有的分区上，而Riak、Couchbase和 Voldemort干脆就不支持关键字上的区间查询。

Cassandra则在两种分区策略之间做了一个折中。 Cassandra 中的表可以声明为由多个列组成的复合主键。复合主键只有第一部分可用于哈希分区，而其他列则用作组合索引来对Cassandra SSTable中的数据进行排序。因此，它不支持在第一列上进行区间查询，但如果为第一列指定好了固定值，可以对其他列执行高效的区间查询。

组合索引为一对多的关系提供了一个优雅的数据模型。例如，在社交网站上， 一个用户可能会发布很多消息更新。 如果更新的关键字设置为（ user_id, update_timestamp ）的组合，那么可以有效地检索由某用户在一段时间内所做的所有更新，且按时间戳排序。不同的用户可以存储在不同的分区上，但是对于某一用户，消息按时间戳顺序存储在一个分区上。

#### **负载倾斜与热点**

如前所述，基于哈希的分区方法可以减轻热点，但无法做到完全避免。 一个极端情况是，所有的读／写操作都是针对同一个关键字，则最终所有请求都将被路由到同一个分区。

这种负载或许并不普遍，但也并非不可能：例如，社交媒体网站上，一些名人用户有数百万的粉丝，当其发布一些热点事件时可能会引发一场访问风暴，出现大量的对相同关键字的写操作（其中关键字可能是名人的用户 ID ，或者人们正在评论的事件ID ） 。 此时，哈希起不到任何帮助作用，因为两个相同 ID 的哈希值仍然相同 。

大多数的系统今天仍然无法自动消除这种高度倾斜的负载，而只能通过应用层来减轻倾斜程度。例如，如果某个关键字被确认为热点， 一个简单的技术就是在关键字的开头或结尾处添加一个随机数。只需一个两位数的十进制随机数就可以将关键字的写操作分布到100个不同的关键字上，从而分配到不同的分区上。

但是，随之而来的问题是，之后的任何读取都需要些额外的工作，必须从所有 100个关键字中读取数据然后进行合井。因此通常只对少量的热点关键字附加随机数才有意义；而对于写入吞吐量低的绝大多数关键宇，这些都意味着不必要的开销。此外，还需要额外的元数据来标记哪些关键字进行了特殊处理 。

也许将来某一天，数据系统能够自动检测负载倾斜情况，然后自动处理这些倾斜的负载。但截至目前，仍然需要开发者自己结合应用来综合权衡。

### **分区与二级索引**

我们之前所讨论的分区方案都依赖于键－值数据模型。键－值模型相对简单，即都是通过关键字来访问记录，自然可以根据关键字来确定分区，并将读写请求路由到负责该关键字的分区上。

但是，如果涉及二级索引，情况会变得复杂（参阅第3章的“其他索引结构”）。 二级索引通常不能唯一标识一条记录，而是用来加速特定值的查询，例如查找用户123的所有操作，找到所有含有hogwash的文章，查找所有颜色为红色的汽车等。

二级索引是关系数据库的必备特性 ，在文档数据库中应用也非常普遍。但考虑到其复杂性，许多键－值存储（如HBase和Voldemort）并不支持二级索引；但其他一些如Riak则开始增加对二级索引的支持。 此外， 二级索引技术也是 Solr 和 Elasticsearch等全文索引服务器存在之根本。

二级索引带来的主要挑战是它们不能规整的地映射到分区中。有两种主要的方法来支持对二级索引进行分区：基于文档的分区和基于词条的分区。

#### **基于文档分区的二级索引**

假设一个销售二手车的网站（见图 6-4 ）。每个列表都有一个唯一的文档ID ，用此ID对数据库进行分区，例如， ID 0到499归分区0, ID 500到999划为分区 1 。现在用户需要搜索汽车，可以持按汽车颜色和厂商进行过滤，所以需要在颜色和制造商上设定二级索引（在文档数据库中这些都是字段；在关系数据库中则是列）。声明这些索引之后，数据库会自动创建索引。例如，每当一辆红色汽车添加到数据库中，数据库分区会自动将其添加到索引条目为“ color: red”的文档ID列表中 。

​    ![0](https://note.youdao.com/yws/res/19666/WEBRESOURCE1e4650ff188e25a29eace09573a7f843)

在这种索引方法中，每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中数据。每当需要写数据库时，包括添加，删除或更新文档等，只需要处理包含目标文档ID的那一个分区。因此文档分区索引也被称为本地索引，而不是全局索引，后者将在本章后面介绍。

但读取时需要注意： 除非对文档 ID做了特别的处理，否则不太可能所有特定颜色或特定品牌的汽车都放在一个分区中，例如图 6-4中，红色汽车就出现在分区0和分区1中 。因此，如果想要搜索红色汽车，就需要将查询发送到所有的分区，然后合并所有返回的结果。

这种查询分区数据库的方法有时也称为分散／聚集，显然这种二级索引的查询代价高昂。即使采用了并行查询，也容易导致读延迟显著放大。尽管如此，它还是广泛用于实践： MongoDB 、 Riak、 Cassandra 、Elasticsearch、 SolrCloud 和VoltDB 都支持基于文档分区二级索引。大多数数据库供应商都建议用户自己来构建合适的分区方案，尽量由单个分区满足二级索引查询，但现实往往难以如愿，尤其是当查询中可能引用多个二级索引时（例如同时指定颜色和制造商两个条件）。

#### **基于词条的二级索引分区**

另一种方法，我们可以对所有的数据构建全局索引，而不是每个分区维护自己的本地索引。而且，为避免成为瓶颈，不能将全局索引存储在一个节点上，否则就破坏了设计分区均衡的目标。所以，全局索引也必须进行分区，且可以与数据关键字采用不同的分区策略。

​    ![0](https://note.youdao.com/yws/res/19684/WEBRESOURCEec056323bf4cc9cd54ff7fb99f4200cb)

以图 6-5 为例：所有数据分区中的颜色为红色的汽车被收录到在索引 color : red 中，而索引本身也是分区的，例如从 a 到 r 开始的颜色放在分区0中，从 s 到 z 的颜色放在分区1中。类似的，汽车制造商的索引也被分区（两个分区的边界分别是字母 f 和字母 h ） 。

我们将这种索引方案称为词条分区，它以待查找的关键字本身作为索引。例如颜色color: red。名字词条源于全文索引（一种特定类型的二级索引) , term指的是文档中出现的所有单词的集合 。

和前面讨论的方法一样，可以直接通过关键词来全局划分索引，或者对其取哈希值。直接分区的好处是可以支持高效的区间查询（例如，查询汽车报价在某个值以上）而采用哈希的方式则可以更均匀的划分分区。

这种全局的词条分区相比于文档分区索引的主要优点是，它的读取更为高效，即它不需要采用 scatter/gather 对所有的分区都执行一遍查询，相反，客户端只需要向包含词条的那一个分区发出读请求。然而全局索引的不利之处在于， 写入速度较慢且非常复杂，主要因为单个文档的更新时，里面可能会涉及多个二级索引，而二级索引的分区又可能完全不同甚至在不同的节点上，由此势必引人显著的写放大。

理想情况下，索引应该时刻保持最新，即写入的数据要立即反映在最新的索引上。但是，对于词条分区来讲，这需要一个跨多个相关分区的分布式事务支持，写入速度会受到极大的影响，所以现有的数据库都不支持同步更新二级索引（参阅第7章和第9章）。

实践中，对全局二级索引的更新往往都是异步的（也就意味着 ，如果在写入之后马上去读索引 ，那 么刚刚发生的更新可能还没有反映在索引中）。例如， Amazon DynamoDB的二级索引通常可以在 1 秒之内完成更新，但当底层设施出现故障时，也有可能需要等待很长的时间 。其他使用全局索引的系统还包括Riak的搜索功能和Oracle数据仓库，后者允许用户来选择是使用本地还是全局索引。在第12章我们会重新讨论如何实现全局二级索引。

### **分区再平衡**

随着时间的推移，数据库可能总会出现某些变化：

- 查询压力增加，因此需要更多的CPU来处理负载 。
- 数据规模增加，因此需要更多的磁盘和内存来存储数据 。
- 节点可能出现故障，因此需要其他机器来接管失效的节点。

所有这些变化都要求数据和请求可以从一个节点转移到另一个节点。这样一个迁移负载的过程称为再平衡（或者动态平衡）。无论对于哪种分区方案 ， 分区再平衡通常至少要满足 ：

- 平衡之后，负载、数据存储、读写请求等应该在集群范围更均匀地分布。
- 再平衡执行过程中，数据库应该可以继续正常提供读写服务。
- 避免不必要的负载迁移，以加快动态再平衡，并尽量减少网络和磁盘 I/O 影响。

#### **动态再平衡的策略**

将分区对应到节点上存在多种不同的分配策略，这里逐一介绍 ：

##### **为什么不用取模？**

我们在前面提到（见图 6-3 ），最好将哈希值划分为不同的区间范围，然后将每个区间分配给一个分区。例如，区间［0，b0）对应于分区0 , [b0, b1） 对应分区 1 等。

也许你会问为什么不直接使用 mod （许多编程语言里的取模运算符%）。例如，hash(key) mod 10会返回 一个介于0和9之间的数字，如果有 10 个节点，则依次对应节点0到 9 ，这似乎是将每个关键字分配到节点的最简单方法。

对节点数取模方法的问题是 ，如果节点数N发生了变化 ，会导致很多关键字需要从现有的节点迁移到另一个节点。 例如 ，假设hash(key) = 123456 ， 假定最初是 10个节点，那么这个关键字应该放在节点 6 ( 123456 mod 10 = 6 ）；当节点数增加到 11 时，它需要移动到节点 3 ( 123456 mod 11 = 3 ） ； 当继续增长到 12个节点时，又需要移动到节点0 ( 123456 mod 12 = 0 ）。这种频繁的迁移操作大大增加了再平衡的成本 。

因此我们需要一种减少迁移数据的方法。

##### **固定数量的分区**

幸运的是，有一个相当简单的解决方案 ： 首先， 创建远超实际节点数的分区数，然后为每个节点分配多个分区。例如，对于一个10节点的集群，数据库可以从一开始就逻辑划分为1000个分区，这样大约每个节点承担100个分区。

接下来 ， 如果集群中添加了一个新节点，该新节点可以从每个现有的节点上匀走几个分区，直到分区再次达到全局平衡。该过程如图 6-6 所示 。 如果从集群中删除节点，则采取相反的均衡措施。

选中的整个分区会在节点之间迁移，但分区的总数量仍维持不变， 也不会改变关键字到分区的映射关系。这里唯一要调整的是分区与节点的对应关系。考虑到节点间通过网络传输数据总是需要些时间， 这样调整可以逐步完成，在此期间， 旧的分区仍然可以接收读写请求。

​    ![0](https://note.youdao.com/yws/res/19753/WEBRESOURCE75a3bd5fb6486abcfe575bf214479aa1)

原则上， 也可以将集群中的不同的硬件配置因素考虑进来，即性能更强大的节点将分配更多的分区，从而分担更多的负载。 

目前，Riak，Elasticsearch、Couchbase和Voldemort都支持这种动态平衡方法。

使用该策略时，分区的数量往往在数据库创建时就确定好，之后不会改变。原则上也可以拆分和合并分区（稍后介绍），但固定数量的分区使得相关操作非常简单，因此许多采用固定分区策略的数据库决定不支持分区拆分功能。所以 ，在初始化时，已经充分考虑将来扩容增长的需求（未来可能拥有的最大节点数），设置一个足够大的分区数。而每个分区也有些额外的管理开销，选择过高的数字可能会有副作用。

如果数据集的总规模高度不确定或可变（例如，开始非常小，但随着时间的推移可能会变得异常庞大）， 此时如何选择合适的分区数就有些困难。每个分区包含的数据量的上限是固定的，实际大小应该与集群中的数据总量成正比。如果分区里的数据量非常大，则每次再平衡和节点故障恢复的代价就很大；但是如果一个分区太小，就会产生太多的开销。分区大小应该“恰到好处”，不要太大， 也不能过小，如果分区数量固定了但总数据量却高度不确定，就难以达到一个最佳取舍点。

##### **动态分区**

对于采用关键字区间分区的数据库，如果边界设置有问题，最终可能会出现所有数据都挤在一个分区而其他分区基本为空，那么设定固定边界、固定数量的分区将非常不便 ：而手动去重新配置分区边界又非常繁琐。

因此， 一些数据库如HBase和RethinkDB等采用了动态创建分区。当分区的数据增长超过一个可配的参数阈值（ HBase上默认值是 10GB ），它就拆分为两个分区，每个承担一半的数据量。相反，如果大量数据被删除，并且分区缩小到某个阈值以下，则将其与相邻分区进行合并。该过程类似于B树的分裂操作（参阅第 3章 的“ B -tree ”）。

每个分区总是分配给一个节点，而每个节点可以承载多个分区，这点与固定数量的分区一样。当一个大的分区发生分裂之后，可以将其中的一半转移到其他某节点以平衡负载。对于HBase ，分区文件的传输需要借助HDFS （底层分布式文件系统） 。

动态分区的一个优点是分区数量可以自动适配数据总量。如果只有少量的数据，少量的分区就足够了，这样系统开销很小；如果有大量的数据，每个分区的大小则被限制在一个可配的最大值。

但是，需要注意的是，对于一个空的数据库 ， 因为没有任何先验知识可以帮助确定分区的边界，所以会从一个分区开始。可能数据集很小，但直到达到第一个分裂点之前，所有的写入操作都必须由单个节点来处理， 而其他节点则处于空闲状态。为了缓解这个问题， HBase和MongoDB允许在一个空的数据库上配置一组初始分区（这被称为预分裂）。对于关键字区间分区，预分裂要求已经知道一些关键字的分布情况。

动态分区不仅适用于关键字区间分区，也适用于基于哈希的分区策略。MongoDB从版本2.4开始，同时支持二者，并且都可以动态分裂分区。

##### **按节点比例分区**

采用动态分区策略，拆分和合并操作使每个分区的大小维持在设定的最小值和最大值之间，因此分区的数量与数据集的大小成正比关系。另一方面，对于固定数量的分区方式，其每个分区的大小也与数据集的大小成正比。两种情况，分区的数量都与节点数无关。

Cassandra和Ketama则采用了第三种方式，使分区数与集群节点数成正比关系。换句话说，每个节点具有固定数量的分区。此时， 当节点数不变时，每个分区的大小与数据集大小保持正比的增长关系； 当节点数增加时，分区则会调整变得更小。较大的数据量通常需要大量的节点来存储，因此这种方法也使每个分区大小保持稳定。

当一个新节点加入集群时，它随机选择固定数量的现有分区进行分裂，然后拿走这些分区的一半数据量，将另一半数据留在原节点。随机选择可能会带来不太公平的分区分裂，但是当平均分区数量较大时 （ Cassandra默认情况下，每个节点有256个分区），新节点最终会从现有节点中拿走相当数量的负载。 Cassandra 在3 .0时推出了改进算法，可以避免上述不公平的分裂。

随机选择分区边界的前提要求采用基于哈希分区（可以从哈希函数产生的数字范围里设置边界） 。这种方法也最符合本章开头所定义一致性哈希 。一些新设计的哈希函数也可以以较低的元数据开销达到类似的效果。

#### **自动与手动再平衡操作**

动态平衡另一个重要问题我们还没有考虑 ： 它是自动执行还是手动方式执行？

全自动式的再平衡（即由系统自动决定何时将分区从一个节点迁移到另一个节点，不需要任何管理员的介入）与纯手动方式（ 即分区到节点的映射由管理员来显式配置）之间，可能还有一个过渡阶段。例如， Couchbase, Riak和Voldemort会自动生成一个分区分配的建议方案，但需要管理员的确认才能生效。

全自动式再平衡会更加方便，它在正常维护之外所增加的操作很少。但是，也有可能出现结果难以预测的情况。再平衡总体讲是个比较昂贵的操作，它需要重新路由请求并将大量数据从一个节点迁移到另一个节点。万一执行过程中间出现异常，会使网络或节点的负载过重，并影响其他请求的性能。

将自动平衡与自动故障检测相结合也可能存在一些风险。例如，假设某个节点负载过重 ，对请求的响应暂时受到影响，而其他节点可能会得到结论：该节点已经失效；接下来激活自动平衡来转移其负载。客观上这会加重该节点、其他节点以及网络的负荷，可能会使总体情况变得更槽，甚至导致级联式的失效扩散 。

出于这样的考虑，让管理员介入到再平衡可能是个更好的选择。它的确比全自动过程响应慢一些，但它可以有效防止意外发生。

### **请求路由**

现在我们已经将数据集分布到多个节点上，但是仍然有一个悬而未决的问题： 当客户端需要发送请求时，如何知道应该连接哪个节点？如果发生了分区再平衡，分区与节点的对应关系随之还会变化。为了回答该问题，我们需要一段处理逻辑来感知这些变化，并负责处理客户端的连接，例如想要读／写关键字“ foo”，需要连接哪个IP地址和哪个端口号。

这其实属于一类典型的服务发现问题，服务发现并不限于数据库，任何通过网络访问的系统都有这样的需求，尤其是当服务目标支持高可用时（在多台机器上有冗余配置 ）。许多公司已经开发了自己的内部服务发现工具，其中很多已经开源。

概括来讲，这个问题有以下几种不同的处理策略（分别如图 6-7 所示的三种情况）：

1. 允许客户端链接任意的节点。如果某节点恰好拥有所请求的分区，则直接处理该请求，否则，将请求转发到下一个合适的节点，接收答复，并将答复返回给客户端。
2. 将所有客户端的请求都发送到一个路由层，由后者负责将请求转发到对应的分区节点上。路由层本身不处理任何请求，它仅充一个分区感知的负载均衡器。
3. 客户端感知分区和节点分配关系。此时，客户端可以直接连接到目标节点，而不需要任何中介。

不管哪种方法， 核心问题是：作出路由决策的组件（可能是某个节点，路由层或客户端）如何知道分区与节点的对应关系以及其变化情况？

​    ![0](https://note.youdao.com/yws/res/19821/WEBRESOURCE4da21bdc1604c1ab437c2ab4a1839ebb)

这其实是一个很有挑战性的问题 ，所有参与者都要达成共识这一点很重要。否则请求可能被发送到错误的节点，而没有得到正确处理。分布式系统中有专门的共识协议算法，但通常难以正确实现（详见第9章）。

许多分布式数据系统依靠独立的协调服务（如ZooKeeper ）跟踪集群范围内的元数据，如图 6-8 所示。每个节点都向 ZooKeeper中注册自己， ZooKeeper维护了分区到节点的最终映射关系。其他参与者（如路由层或分区感知的客户端）可以向 ZooKeeper订阅此信息。一旦分区发生了改变，或者添加、 删除节点， ZooKeeper就会主动通知路由层，这样使路由信息保持最新状态。

例如， Linkedln的Espresso使用 Helix 进行集群管理（底层是ZooKeeper ）， 实现了图 6-8 所示的请求路由层。 HBase, SolrCloud和Kafka也使用 ZooKeeper来跟踪分区分配情况 。 MongoDB有类似的设计，但它依赖于自己的配置服务器和mangos守护进程来充当路由层。

Cassandra和Riak则采用了不同的方法，它们在节点之间使用 gossip 协议来同步群集状态的变化。请求可以发送到任何节点，由该节点负责将其转发到目标分区节点（图6-7中的方法1） 。这种方式增加了数据库节点的复杂性，但是避免了对ZooKeeper之类的外部协调服务的依赖。

​    ![0](https://note.youdao.com/yws/res/19824/WEBRESOURCE5bdba32e50b7d0781dc8e99a0948cebd)

Couchbase并不支持自动再平衡功能，这简化了设计 。 它通过配置一个名为moxi的路由选择层，向集群节点学习最新的路由变化。

当使用路由层或随机选择节点发送请求时， 客户端仍然需要知道目标节点的IP地址 。IP地址的变化往往没有分区-节点变化那么频繁，采用 DNS通常就足够了。

#### **并行查询执行**

到目前为止，我们只关注了读取或写入单个关键字这样简单的查询（对于文档分区的二级索引，里面要求分散／聚集查询） 。这基本上也是大多数NoSQL分布式数据存储所支持的访问类型。

然而对于大规模并行处理（ massively parallel processing, MPP ）这一类主要用于数据分析的关系数据库，在查询类型方面要复杂得多。典型的数据仓库查询包含多个联合、过滤、分组和聚合操作。 MPP查询优化器会将复杂的查询分解成许多执行阶段和分区， 以便在集群的不同节点上并行执行。尤其是涉及全表扫描这样的查询操作，可以通过并行执行获益颇多。

数据仓库中快速并行执行查询可以作为单独的话题。考虑到分析业务的重要性，目前它已得到了广泛的商业关注。我们将在第10章中讨论并行查询执行所需的一些技术 。有关并行数据库更多相关技术细节请参考文献。

### **小结**

本章， 我们探讨了将大规模数据集划分成更小子集的多种方法。数据量如果太大， 单台机器进行存储和处理就会成为瓶颈，因此需要引入数据分区机制。分区的目地是通过多台机器均匀分布数据和查询负载，避免出现热点。这需要选择合适的数据分区方案，在节点添加或删除时重新动态平衡分区。

我们讨论了两种主要的分区方法 ：

- 基于关键字区间的分区。先对关键字进行排序，每个分区只负责一段包含最小到最大关键字范围的一段关键字。对关键字排序的优点是可以支持高效的区间查询，但是如果应用程序经常访问与排序一致的某段关键字，就会存在热点的风险。采用这种方法，当分区太大时，通常将其分裂为两个子区间，从而动态地再平衡分区。
- 哈希分区。将哈希函数作用于每个关键字，每个分区负责一定范围的哈希值。这种方法打破了原关键字的顺序关系，它的区间查询效率比较低，但可以更均匀地分配负载。采用哈希分区时，通常事先创建好足够多（但固定数量）的分区， 让每个节点承担多个分区，当添加或删除节点时将某些分区从一个节点迁移到另一个节点，也可以支持动态分区。

混合上述两种基本方法也是可行的，例如使用复合键：键的一部分来标识分区，而另一部分来记录排序后的顺序 。

我们还讨论了分区与二级索引， 二级索引也需要进行分区，有两种方法：

- 基于文档来分区二级索引 （本地索引）。 二级索引存储在与关键字相同的分区中 ，这意味着写入时我们只需要更新一个分区，但缺点是读取二级索引时需要在所有分区上执行scatter/gather。
- 基于词条来分区二级索引（全局索引）。它是基于索引的值而进行的独立分区。二级索引中的条目可能包含来自关键字的多个分区里的记录。在写入时 ，不得不更新二级索引的多个分区；但读取时 ，则可以从单个分区直接快速提取数据。

最后，我们讨论了如何将查询请求路由到正确的分区，包括简单的分区感知负载均衡器， 以及复杂的并行查询执行引擎。

理论上，每个分区基本保持独立运行 ， 这也是为什么我们试图将分区数据库分布、扩展到多台机器上。但是，如果写入需要跨多个分区，情况就会格外复杂， 例如，如果其中一个分区写入成功，但另一个发生失败，接下来会发生什么？我们将在下面的章节中讨论类似这样的技术挑战。

## **第7章 事务**

在一个苛刻的数据存储环境中，会有许多可能出错的情况，例如：

- 数据库软件或硬件可能会随时失效（ 包括正在执行写操作的过程中）。
- 应用程序可能随时奔溃（包括一系列操作执行到中间某一步）。
- 应用与数据库节点之间的链接可能随时会中断，数据库节点之间也存在同样问题。
- 多个客户端可能同时写入数据库 ，导致数据覆盖。
- 客户端可能读到一些无意义的、部分更新的数据。
- 客户端之间由于边界条件竞争所引入的各种奇怪问题 。

为了系统高可靠的目标，我们必须处理好上述问题，万一发生类似情况确保不会导致系统级的失效。 然而，完善的容错机制需要大量的工作， 要仔细考虑各种可能出错的可能 ，并进行充分的测试才能确保方案切实可靠。

近十年来，事务技术一直是简化这些问题的首选机制。事务将应用程序的多个读、写操作捆绑在一起成为一个逻辑操作单元。即事务中的所有读写是一个执行的整体，整个事务要么成功（提交）、要么失败（中止或回擦）。如果失败，应用程序可以安全地重试。这样，由于不需要担心部分失败的情况（无论出于何种原因），应用层的错误处理就变得简单很多 。

也许对于那些浸淫此领域多年的读者来说， 事务的概念如此简单，但细究起来或许并非如此。事务不是一个天然存在的东西，它是被人为创造出来，目的是简化应用层的编程模型。有了事务，应用程序可以不用考虑某些内部潜在的错误以及复杂的并发性问题，这些都可以交给数据库来负责处理（我们称之为安全性保证）。

然而并非每个应用程序都需要事务机制，有时可以弱化事务处理或完全放弃事务（例如，为了实现更高的性能或更高的可用性）。 一些安全相关的属性也可能会避免引人事务。

那该如何判断是否需要事务呢？为了回答这个问题，我们首先需要确切地理解事务能够提供哪些安全性保证，背后的代价又是什么。 事务的概念看似简单，实际上却有许多微妙而关键的细节值得研究。

本章，我们将首先分析可能出错的各种场景，探讨数据库防范这些问题的基本方法和算法设计。特别是在并发控制方面，深入讨论可能各种竞争条件，数据库所提供的多种隔离级别，例如读提交、快照隔离和可串行化等。

本章的内容可适用于单节点和分布式场景。在第8章中，我们将重点讨论分布式系统的特殊挑战 。

### **深入理解事务**

目前几乎所有的关系数据库和一些非关系数据库都支持事务处理。它们大多数都沿用了和IBM于 1975年推出的第一个SQL数据库 System R相似的总体设计。尽管在一些具体实现方面有些不同，但事务的概念在这四十年中几乎没有发生变化 ，换句话说，MySQL 、 PostgreSQL 、Oracle 、SQL Server等系统实现的事务与当年 System R非常相似 。

然而21 世纪末，非关系（ NoSQL ）数据库开始兴起 。 它们的目标是通过提供新的数据模型（参见第2章），以及内置的复制（参见第5章）和分区（参见第6章）等手段来改进传统的关系模型。然而事务却成了这场变革的受害者 ： 很多新一代的数据库完全放弃了事务支持，或者将其重新定义，即替换为比以前弱得多的保证。

随着这种新型分布式数据库的炒作，很多人开始认为事务与可扩展性是相对立的两面，而大规模系统为了性能与高可用性将不得不牺牲事务的支持。但另一方面，还有一些数据库供应商则坚称事务是“关键应用”和“高价值数据”所必备的重要功能。而笔者看来，这两个观点未免都有些夸大其词。

与其他技术一样，事务有其优势，也有其自身的局限性。为了更好地理解事务设计的权衡之道，让我们考虑正常运行和各种极端（但确实存在）情况，详细分析事务可以为我们提供哪些保证。

#### **ACID的含义**

事务所提供的安全保证即大家所熟知的ACID ，分别代表原子性（ Atomicity ）， 一致性（ Consistency ），隔离性（ Isolation ）与持久性（ Durability ），取这四个特性的首字母。最早由TheoHarder和Andreas Reuter于1983年为精确描述数据库的容错机制而定义。

但实际上，各家数据库所实现的ACID并不尽相同。例如，我们稍后就会看到，围绕着 “隔离性”就存在很多含糊不清的争议。想法非常美好，细节方见真章。当听到一个系统声称自己“兼容ACID”时，其实你无法确信它究竟能提供了什么样的保证，现在的ACID更像是一个市场营销用语。

而不符合 ACID标准的系统有时被冠以 BASE ，取另外几个特性的首字母，即 基本可用性（ Basically Available ），软状态（ Soft state ）和最终一致性（ Eventual consistency) 。听下来它似乎比ACID更加模棱两可。 BASE唯一可以确定的是“它不是ACID”，此外它几乎没有承诺任何东西。

我们还是先搞清楚原子性，一致性，隔离性和持久性的准确含义，目标是建立对事务思想的清晰而牢固的认识 。

##### **原子性**

通常，原子是指不可分解为更小粒度的东西。这个术语在计算机的不同领域里有着相似但却微妙的差异。例如， 多线程编程中，如果某线程执行一个原子操作 ，这意味着其他线程是无法看到该操作的中间结果。它只能处于操作之前或操作之后的状态，而不是两者之间的状态。

而ACID 中的原子性并不关乎多个操作的并发性，它并没有描述多个线程试图访问相同的数据会发生什么情况，后者其实是由 ACID的隔离性所定义（参见本章后面的“隔离性”）。

ACID原子性其实描述了客户端发起一个包含多个写操作的请求时可能发生的情况，例如在完成了一部分写入之后，系统发生了故障，包括进程崩溃，网络中断，磁盘变满或者违反了某种完整性约束等；把多个写操作纳入到一个原子事务，万一出现了上述故障而导致没法完成最终提交时，则事务会中止，并且数据库须丢弃或撤销那些局部完成的更改。

假如没有原子性保证，当多个更新操作中间发生了错误，就需要知道哪些更改已经生效，哪些没有生效，这个寻找过程会非常麻烦。或许应用程序可以重试，但情况类似，并且可能导致重复更新或者不正确的结果。原子性则大大简化了这个问题：如果事务已经中止，应用程序可以确定没有实质发生任何更改，所以可以安全地重试。

因此ACID 中原子性所定义的特征是： 在出错时中止事务，并将部分完成的写入全部丢弃。也许可中止性比原子性更为准确，不过我们还是沿用原子性这个惯用术语。

##### **一致性**

一致性非常重要，但它在不同场景有着不同的具体含义，例如 ：

- 第5章我们讨论了副本一致性以及异步复制模型时，引出了最终一致性问题（参见第5章“复制滞后问题”）。
- 一致性哈希则是某些系统用于动态分区再平衡的方法（参见第6章“一致性哈希”）。
- CAP理论中， 一致性一词用来表示线性化（参见第9章“可线性化”）。
- 而在ACID 中， 一致性主要指数据库处于应用程序所期待的“预期状态”。

可以看出，同一个词至少有四种不同的含义。ACID 中的一致性的主要是指对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或者恒等条件）。例如，对于一个账单系统，账户的贷款余额应和借款余额保持平衡。如果某事务从一个有效的状态开始，并且事务中任何更新操作都没有违背约束，那么最后的结果依然符合有效状态。

这种一致性本质上要求应用层来维护状态一致（或者恒等），应用程序有责任正确地定义事务来保持一致性。这不是数据库可以保证的事情：即如果提供的数据修改违背了恒等条件，数据库很难检测进而阻止该操作（数据库可以完成针对某些特定类型的恒等约束检查，例如使用外键约束或唯一性约束。但通常主要靠应用程序来定义数据的有效／无效状态，数据库主要负责存储）。

原子性，隔离性和持久性是数据库自身的属性，而ACID 中的一致性更多是应用层的属性。应用程序可能借助数据库提供的原子性和隔离性，以达到一致性，但一致性本身并不源于数据库。因此，字母C其实并不应该属于ACID。

##### **隔离性**

大多数数据库都支持多个客户端同时访问。如果读取和写入的是不同数据，这肯定没有什么问题：但如果访问相同的记录， 则可能会遇到并发问题（即带来竞争条件）。

一个简单例子如图 7-1 所示。假设有两个客户端同时增加数据库中的一个计数器。每个客户首先读取当前值 ，再客户端增加 1 ，然后写回新值（这里假设数据库尚不支持自增操作）。图 7-1 中，由于有两次相加，计数器应该由 42 增加到44 ，但实际上由于竞争条件最终结果却是43 。

ACID语义中的隔离性意味着并发执行的多个事务相互隔离，它们不能互相交叉。经典的数据库教材把隔离定义为可串行化，这意味着可以假装它是数据库上运行的唯一事务。虽然实际上它们可能同时运行，但数据库系统要确保当事务提交时，其结果与串行执行（一个接一个执行）完全相同。

​    ![0](https://note.youdao.com/yws/res/19958/WEBRESOURCEe41bccaa0a69cdfad5b61ac86285fde2)

然而实践中，由于性能问题很少使用串行化隔离。一些流行的数据库，如 Oracle 11g ，甚至根本就没有实现它。 Oracle虽然也有声称“串行化”的功能，但它本质上实现的是快照隔离，后者提供了比串行化更弱的保证。我们将在本章后面“弱隔离级别”中讨论快照隔离以及其他形式的隔离。

##### **持久性**

数据库系统本质上是提供一个安全可靠的地方来存储数据而不用担心数据丢失等。持久性就是这样的承诺，它保证一且事务提交成功，即使存在硬件故障或数据库崩溃，事务所写入的任何数据也不会消失。

对于单节点数据库 ，持久性通常意味着数据已被写入非易失性存储设备，如硬盘或SSD 。 在写入执行过程中，通常还涉及预写日志等（参阅第 3章 “可靠的 B-tree”），这样万一磁盘数据损坏可以进行恢复。而对于支持远程复制的数据库，持久性则意味着数据已成功复制到多个节点。为了实现持久性的保证，数据库必须等到这些写入或复制完成之后才能报告事务成功提交。

正如第 1章的“可靠性”所提到的，其实不存在完美的持久性。例如，所有的硬盘和所有的备份如果都同时被（人为）销毁了，那么数据库也无能为力。

#### **GPT解释**

Q：数据库事务实现机制

------

实现数据库事务通常涉及以下机制：

- 日志记录（Logging）: 为了实现原子性和持久性，DBMS在事务执行时在日志文件中记录所有数据修改信息。如果系统故障，利用日志可以重做（redo）已提交的事务或撤销（undo）未完成的事务。
- 锁定（Locking）: 为了保证隔离性和一致性，DBMS会使用锁定机制来控制对数据库对象的访问。锁可以是行级别、页级别或表级别，且有不同类型（如共享锁、排他锁）。
- 隔离级别（Isolation Levels）: 为了允许不同程度的隔离和提高并发性能，SQL标准定义了几种隔离级别，包括读未提交（Read Uncommitted）、读提交（Read Committed）、可重复读（Repeatable Read）和串行化（Serializable）。这些级别各自对应不同的锁定策略和并发控制方法。
- 事务管理（Transaction Management）: 事务管理器是DBMS的一个组成部分，负责事务的协调、控制和持久化。它管理事务的生命周期，包括事务的开始、执行、提交或回滚。
- 两阶段提交（Two-phase Commit, 2PC）: 在分布式数据库系统中，为了确保事务的原子性，两阶段提交协议被用来在所有参与节点间协调事务的提交或回滚。

Q：“为了实现原子性和持久性，DBMS在事务执行时在日志文件中记录所有数据修改信息。如果系统故障，利用日志可以重做（redo）已提交的事务或撤销（undo）未完成的事务。”  详细说一下这点

------

为了保证数据库事务的原子性和持久性，数据库管理系统（DBMS）采用了日志（Logging）来记录事务过程中对数据的所有更改。日志是一种非易失性存储，通常存放在磁盘上。以下是如何利用日志来实现原子性和持久性的详细过程：

**日志记录**

- 当事务开始时，DBMS向日志中写入一条记录，通常包括事务ID和开始标记。
- 在事务过程中，每当数据被修改时，DBMS都会在日志中记录下来。这些日志记录会包括足够的信息来在必要时恢复或撤销数据改动，比如事务ID、被修改数据的标识、修改前的值和修改后的值。
- 当事务成功完成所有操作后，DBMS会在日志中记录一个提交（commit）标记，表明这个事务已经完成，并且其修改是有效的。

**故障恢复**

- 撤销未完成的事务（Undo）:

如果在事务执行过程中遇到系统故障（比如电源中断或系统崩溃），DBMS需要确保事务的原子性，即这个事务的所有操作要么全部完成，要么全部不发生。在系统恢复后，DBMS会查看日志文件，找到未完成的事务（即没有提交标记的事务）。DBMS会利用日志中记录的信息，将数据库中被这些未完成事务修改过的数据恢复（undo）到事务开始前的状态。

- 重做已提交的事务（Redo）:

要确保事务的持久性，即一旦事务提交，它的修改就会永久保存，即使发生系统故障也不会丢失。如果系统出现故障，一些已经提交的事务可能还没来得及将其修改永久写入到数据库文件中。在系统恢复后，DBMS会检查日志文件，对那些已经提交但可能未写入数据库的事务执行重做（redo）操作，确保所有的数据修改被正确应用到数据库。

**写前日志（Write-Ahead Logging, WAL）**

为了确保日志记录能有效地支持事务的原子性和持久性，许多DBMS实现了所谓的写前日志协议（Write-Ahead Logging）。这个协议要求，在对任何数据进行修改之前，必须先将相关的日志记录写入到持久存储。这确保了即使在数据修改还没写回数据库之前系统崩溃，日志中也已经有足够的信息来恢复那些改动。

**日志管理**

为了提高效率，DBMS通常采用批量写入和日志缓冲区来管理日志记录，以减少磁盘I/O操作的次数。此外，日志记录通常是顺序写入的，这比随机写入数据文件快得多。

**总结**

在数据库系统中，日志记录是实现事务原子性和持久性的关键机制。通过适当地记录和管理每个事务对数据所做的更改，并在系统故障时提供撤销未完成事务和重做已提交事务的能力，日志保证了数据库状态的一致性和可靠性。

#### **单对象与多对象事务操作**

回顾一下， ACID 中的原子性和隔离性主要针对客户端在同一事务中包含多个写操作时，数据库所提供的保证：

原子性

如果一系列写操作中间发生了错误，则事务必须中止，并且事务中已完成的写入应该被丢弃。换言之，不用担心数据库的部分失败，它总是保证要么全部成功，要么全部失败。

隔离性

同时运行的事务不应相互干扰。例如，如果某个事务进行多次写入，则另一个事务应该观察到的是其全部完成（或者一个都没完成）的结果，而不应该看到中间的部分结果。

这些定义假定在一个事务中会修改多个对象（如行，文档，记录等）。这种多对象事务目的通常是为了在多个数据对象之间保持同步。图 7-2 展示了一个电子邮件应用的例子。要显示用户的未读邮件数量，可以执行查询如下 ：

SELECT COUNT( *) FROM Emails WHERE recipient_id = 2 AND unread_flag = true

如果电子邮件太多，你会发现查询太慢，然后决定将未读的数量直接保存在一个单独的字段中 （虽然这违反了范式要求） 。这样每当收到一个新邮件， 需要增加未读计数器 ；当邮件标记为已读时，还需减少该计数器。

在图 7-2 中，用户2遇到些异常情况：邮箱列表已显示了未读消息，但计数器却还未更新，所显式的数目是0 。 隔离性将保证用户2看到要么是更新后的电子邮件和更新后的计数器，要么是二者都未更新， 而不会是两者不一致。

​    ![0](https://note.youdao.com/yws/res/20002/WEBRESOURCE51e1ddfde68d7935bca8421a4a5f003f)

图 7-3 则说明了对原子性的需求：如果事务执行过程中发生错误， 导致邮箱和未读计数器二者不同步。 则事务将被中止，且此之前插入的电子邮件将被回滚。

​    ![0](https://note.youdao.com/yws/res/20006/WEBRESOURCE14299f08419078f803d6eb83ffabfd4c)

多对象事务要求确定知道事务包含了哪些读写操作。 对于关系数据库，客户端通常与数据库服务器建立TCP网络连接，因而对于特定的某个连接，SOL语句BEGIN TRANSACTION和COMMIT之间的所有操作都属于同一个事务。

而许多非关系数据库则不会将这些操作组合在一起。即使他们可能支持多对象API ( 例如，键-值存储的 multi-put API 可以在一个操作中更新多个键），但并不意味着具有事务语义，例如可能出现某些键更新成功了而其他则发生了失败，最后结果是数据库处于部分更新的状态。

##### **单对象写入**

原子性和隔离性也同样适用于单个对象的更新。例如，假设向数据库写入20KB的JSON文档 ：

- 如果发送了第一个 10KB之后网络连接中断，数据库是否只存储了无法完整解析的 10KB JSON片段呢？
- 如果数据库在覆盖磁盘现有数据时发生电源故障，最终是否是新旧值混杂在一起？
- 如果另一个客户端在写入的过程中读取该文档，是否会看到部分更新的文档内容？

这些问题着实让人头疼，因此存储引擎几乎必备的设计就是在单节点、单个对象层面上提供原子性和隔离性（比如key-value对）。例如，出现宕机时，基于日志恢复来实现原子性（参阅第3章“可靠的B-tree”），对每个对象采用加锁的方式（每次只允许一个线程访问对象）来实现隔离。

某些数据库还提供了高级的原子操作，例如原子自增操作 ，这样就不需要像图 7-1 那样执行读取－修改－写回，类似地还有原子比较－设置操作，即只有当前值没有被他人修改时才执行写入（参阅本章后面的“compare-and-set”）。

这些单对象操作可以有效防止多个客户端并发修改同一对象时的更新丢失问题（参阅本章后面的“防止更新丢失”）。但需要注意，它们并不是通常意义上的事务。虽然compare-and-set和其他单对象操作有时也被称为“轻量级事务”，甚至“ ACID”,  但这里其实存在一些误导性。通常意义上的事务针对的是多个对象，将多个操作聚合为一个逻辑执行单元。

##### **多对象事务的必要性**

许多分布式数据存储系统不支持多对象事务，主要是因为当出现跨分区时，多对象事务非常难以正确实现，同时在高可用或者极致性能的场景下也会带来很多负面影响。

但是，分布式数据库实现事务并非不可能，并不存什么原理上的限制，我们将在第9章讨论分布式事务的实现。

但是否所有应用都需要多对象事务呢？是否可能只用键－值数据模型和单对象操作就可以满足应用需求？的确有一些情况，只进行单个对象的插入、更新和删除就足够了。但是，还有许多其他情况要求写入多个不同的对象并进行协调：

- 对于关系数据模型，表中的某行可能是另一个表中的外键。类似地， 在图数据模型中，顶点具有多个边链接到其他的顶点。多对象事务用以确保这些外键引用的有效性， 即当插入多个相互引用的记录时，保证外键总是最新 、正确的， 否则数据更新就变得毫无意义。
- 对于文档数据模型，如果待更新的字段都在同一个文档中，则可视为单个对象，此时不需要多对象事务。但是，缺少join支持的文档数据库往往会滋生反规范化（参阅第2章“关系数据库与文档数据库现状”），如图 7-2 所示，当更新这种非规范化数据时，就需要一次更新多个文档。此时多对象事务就可以有效防止非规范化数据之间出现不同步 。
- 对于带有二级索引的数据库（除了纯粹键－值存储以外几乎所有其他系统都支持二级索引），每次更改值时都需要同步更新索引。 从事务角度来看，这些索引是不同的数据库对象 ： 如果没有事务隔离，就会出现部分索引更新。

即使没有事务支持，或许上层应用依然可以工作，然而在没有原子性保证时，错误处理就会异常复杂， 而缺乏隔离性则容易出现并发性方面的各种奇怪问题。我们将在本章后面“弱隔离级别”中讨论这些问题， 并在第12章中探讨其他的一些方案。

##### **处理错误与中止**

事务的一个关键特性是，如果发生了意外，所有操作被中止，之后可以安全地重试。ACID数据库基于这样的一个理念：如果存在违反原子性、隔离性或持久性的风险，则完全放弃整个事务， 而不是部分放弃。

然而， 并不是所有的系统都遵循上述理念。 例如， 无主节点复制的数据存储（参阅第5章“无主节点复制”） 会在“尽力而为”的基础上尝试多做些工作，可以概括理解为 ： 数据库已经尽其所能，但万一遇到错误，系统并不会撤销已完成的操作，此时需要应用程序来负责从错误中进行恢复。

确实我们无法彻底避免错误，然而许多开发人员喜欢只考虑正常的处理路径，而忽视错误处理。比如像流行的Rails ActiveRecord和Django这样的对象关系映射（ORM）框架，当事务出现异常时不会进行重试而只是简单地抛出堆栈信息，用户虽然得到了错误提示，但所有之前的输入都会被抛弃。这绝对不应该，支持安全的重试机制才是中止流程的重点。

重试中止的事务虽然是一个简单有效的错误处理机制，但它并不完美：

- 如果事务实际已经执行成功，但返回给客户端的消息在网络传输时发生意外（所以在客户端看来事务是失败），那么重试就会导致重复执行，此时需要额外的应用级重复数据删除机制 。
- 如果错误是由于系统超负荷所导致， 则重试事务将使情况变得更糟。为此，可以设定一个重试次数上限，例如指数回退，同时要尝试解决系统过载本身的问题。
- 由临时性故障（例如死锁，隔离违例，网络闪断和节点切换等 ）所导致的错误需要重试。但出现了永久性故障（例如违反约束），则重试毫无意义。
- 如果在数据库之外， 事务还产生其他副作用，即使事务被中止，这些副作用可能已事实生效。例如，假设更新操作还附带发送一封电子邮件，肯定不希望每次重试时都发送邮件。如果想要确保多个不同的系统同时提交或者放弃，可以考虑采用两阶段提交（参阅第9章“原子提交与两阶段提交 ” ）。
- 如果客户端进程在重试过程中也发生失败，没有其他人继续负责重试，则那些待写入的数据可能会因此而丢失。

### **弱隔离级别**

如果两个事务操作的是不同的数据，即不存在数据依赖关系，则它们可以安全地并行执行。只有出现某个事务修改数据而另一个事务同时要读取该数据，或者两个事务同时修改相同数据时，才会引发并发问题（引入了竞争条件）。

并发性相关的错误很难通过测试发现，这类错误通常只在某些特定时刻才会触发，这种时机相关的问题发生概率低，稳定重现比较困难。并发性也很难对其进行推理分析，特别是对于一个大型应用程序，几乎不可能知道哪些代码正在访问数据库；只有一个用户访问数据时 ，程序开发就足够困难了 ，当出现多用户并发时情况会变得更加复杂 ，每一块数据随时都可能被多个用户所修改。

正因如此 ，数据库一直试图通过事务隔离来对应用开发者隐藏内部的各种并发问题。从理论上讲，隔离是假装没有发生并发，让程序员的生活更轻松，而可串行化隔离意味着数据库保证事务的最终执行结果与串行（即一次一个，没有任何并发）执行结果相同。

实现隔离绝不是想象的那么简单。可串行化的隔离会严重影响性能，而许多数据库却不愿意牺牲性能，因而更多倾向于采用较弱的隔离级别，它可以防止某些但并非全部的并发问题。这些弱隔离级别理解起来更为困难，甚至可能会带来一些难以捉摸的隐患，但在实践中还是被广泛使用。

弱隔离所引发的并发性错误绝非仅是理论存在，它们已经造成了大量的资金损失，审计部门的调查，以及客户数据破坏等。对此，有一个流行的说法是“如果你正在处理财务数据，请上ACID系统 ！”，但这样的建议其实没有太大实际意义，因为很多流行的关系数据库系统（通常被认为是“ ACID兼容”）其实也采用的是弱级别隔离，所以它们未必可以阻止类似错误的发生。

与其盲目地相信这些宣传，不如对存在的并发问题以及如何防范有一个全面、深刻的理解。然后，我们就可以使用所掌握的工具和方也来构建正确、可靠的应用。

本节将分析几个实际中经常用到的弱级别（非串行化）隔离，并详细讨论可能（或者不可能）发生的竞争条件，有了这些认识之后，可以帮助判断自己的应用更适合什么样的隔离级别。在下一节，我们将详细讨论可串行化。我们主要以示例的方式讨论隔离级别，如果你需要的是严格、正式的定义和分析，可以参考文献。

#### **读-提交**

读－提交是最基本的的事务隔离级别，它只提供以下两个保证 ：

\1. 读数据库时，只能看到已成功提交的数据（防止“脏读”）。

\2. 写数据库时，只会覆盖已成功提交的数据（防止“脏写”）。

这两个保证更深入的介绍如下：

##### **防止脏读**

假定某个事务已经完成部分数据写入，但事务尚未提交（或中止），此时另一个事务是否可以看到尚未提交的数据呢？如果是的话，那就是脏读。

读－提交级别的事务隔离必须做到防止发生脏读。这意味着事务的任何写入只有在成功提交之后，才能被其他人观察到 (并且所有的写全部可见) 。如图7-4所示，用户1设置了x=3，在用户1的事务未提交之前，用户2的get x操作依旧返回的是旧值2。

​    ![0](https://note.youdao.com/yws/res/20102/WEBRESOURCE598b68922700320aee4c32c04f48beb9)

当有以下需求时，需要防止脏读：

- 如果事务需要更新多个对象，脏读意味着另一个事务可能会看到部分更新，而非全部。例如，图 7-2 就是一个电子邮件应用的脏读例子，用户看到了新的未读电子邮件，但看不到更新的计数器。观察到部分更新的数据可能会造成用户的困惑，并由此引发一些不必要的后续操作。
- 如果事务发生中止，则所有写入操作都需要回滚（见图 7-3 ）。 如果发生了脏读，这意味着它可能会看到一些稍后被回滚的数据，而这些数据并未实际提交到数据库中。之后所引发的后果可能都会变得难以预测。

##### **防止脏写**

如果两个事务同时尝试更新相同的对象，会发生什么情况呢？我们不清楚写入的顺序，但可以想象后写的操作会覆盖较早的写入。但是，如果先前的写入是尚未提交事务的一部分，是否还是被覆盖？

如果是，那就是脏写。读提交隔离级别下所提交的事务可以防止脏写，通常的方式是推迟第二个写请求，直到前面的事务完成提交（或者中止）。

防止脏写可以避免以下并发问题：

- 如果事务需要更新多个对象，脏写会带来非预期的错误结果。例如，考虑图7-5的二手车销售网站，Alice和Bob两个人试图购买同一辆车。而购买汽车需要两次数据库写入:网站上商品买主需要更新为新买家，销售发票也需要随之更新。对于图7-5的例子，车主被改为Bob (因为他成功地抢先更新了车辆表单)，但发票却发给了Alice (因为她成功的先执行了发票表单)。读提交隔离要防止这种事故。(GPT解释：在Alice的事务还未提交时，Bob的事务将无法更新同一辆车的状态，因为数据库系统会锁定该数据直到Alice的事务提交或者回滚。这意味着，对于同一个资源的更新操作会被序列化，从而保证一致性。数据库通常通过行锁（Row-Level Locking）或者其他锁机制来实现这种控制。当一个事务尝试修改一行数据时，数据库会对该行数据加锁，直到事务提交或回滚后才释放锁，这样就防止了其他事务在此期间对同一数据进行修改，也就防止了脏写的发生。)
- 但是，读-提交隔离并不能解决图7-1中计数器增量的竞争情况。对于后者，第二次写入确实在第一个事务提交后才执行，虽然不属于脏写，但结果仍然是错误的。在接下来的“防止更新丢失”中，我们将讨论如何安全递增计数器。

​    ![0](https://note.youdao.com/yws/res/20122/WEBRESOURCE34c7081010ea1407b0b8076a943974bd)

##### **实现读－提交**

读-提交隔离非常流行，它是Oracle 11g、PostgreSQL、SQL Server 2012、MemSQL以及许多其他数据库的默认配置。

数据库通常采用行级锁来防止脏写 ： 当事务想修改某个对象（例如行或文档）时，它必须首先获得该对象的锁；然后一直持有锁直到事务提交（或中止）。给定时刻，只有一个事务可以拿到特定对象的锁，如果有另一个事务尝试更新同一个对象，则必须等待，直到前面的事务完成了提交（或中止）后，才能获得锁并继续。这种锁是由处于读－提交模式（或更强的隔离级别）数据库自动完成的。

那如何防止脏读呢？ 一种选择是使用相同的锁，所有试图读取该对象的事务必须先申请锁，事务完成后释放锁。从而确保不会发生读取一个脏的、未提交的值（因为锁在那段期间一直由一个事务所持有）。

然而，读锁的方式在实际中并不可行，因为运行时间较长的写事务会导致许多只读的事务等待太长时间，这会严重影响只读事务的响应延迟，且可操作性差：由于读锁，应用程序任何局部的性能问题会扩散进而影响整个应用，产生连锁反应。

因此，大多数数据库采用了图 7-4 所示的方法来防止脏读：对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。在事务提交之前，所有其他读操作都读取旧值；仅当写事务提交之后，才会切换到读取新值。

然而，这个隔离级别并不阻止并发事务更新同一数据行，即使这些数据行已经被其他并发事务修改但还未提交。在这种情况下，数据库通常会使用锁来确保数据的一致性。当一个事务尝试修改某行数据时，它将获得该行的排他锁。如果该行已经被另一个并发事务锁定，当前事务将不得不等待，直至前一个事务提交或回滚并释放锁。

简而言之，在**读已提交**隔离级别下：

- 一个事务在读取数据时，只能看到已经提交的数据。这防止了脏读（读取未提交数据）。
- 如果一个事务想要更新一行数据，它将请求排他锁。如果该行数据已经被另一个事务锁定（无论该事务是否提交），当前请求更新的事务必须等待。

避免了脏读，但仍然可能发生不可重复读，因为在同一个事务中两次读取同一数据集时，数据可能已经被其他已提交的事务更改。示例：一个事务读取了一行数据，然后另一个事务修改了该数据并提交，当第一个事务再次读取同一行数据，可能会得到不同的结果。

#### **快照级别隔离与可重复读**

表面上看读－提交级别隔离，可能会认为它已经满足了事务所需要一切特征：它支持中止（原子性所必须的），可以防止读取不完整的结果，并且防止并发写的混合。事实上，这些确实非常有用 ，相比没有事务的系统，它的确提供了更多的保证。

但是，在使用此隔离级别时，仍然有很多场景可能导致并发错误。如图 7-6 所示。

​    ![0](https://note.youdao.com/yws/res/20142/WEBRESOURCE3173ef7efdcd06868908bb0c55f8e986)

假设Alice在银行有1000美元的存款，分为两个账户，每个500美元。现在有这样一笔转账交易从账户 1 转 100美元到账户 2。如果在她提交转账请求之后而银行数据库系统执行转账的过程中间，来查看两个账户的余额，她有可能会看到账号2在收到转账之前的余额（500美元），和账户 1 在完成转账之后的余额（400美元）。对于 Alice来说，貌似她的账户总共只有900美元 ，有100美元消失了。

这种异常现象被称为不可重复读取（ nonrepeatable read ）或读倾斜（ read skew ）。如果Alice在交易结束时再次读取账户 1 的余额，她将看到不同的值（600美元） 。读倾斜在读－提交隔离语义下是可以接受的， Alice所看到的账户余额的确都是账户当时的最新值。

对于Alice 这个例子，这并非一个永久性问题，例如几秒钟之后当她重新加载银行页面，可能就能看到一致的账户余额。但是，还有些场景则不能容忍这种暂时的不一致：

备份场景

备份任务要复制整个数据库，这可能需要数小时才能完成。在备份过程中，可以继续写入数据库。因此 ，得到镜像里可能包含部分旧版本数据和部分新版本数据。如果从这样的备份进行恢复，最终就导致了永久性的不一致（例如那些消失的存款）。

分析查询与完整性检查场景

有时查询可能会扫描几乎大半个数据库。这类查询在分析业务中很常见（参阅第3章“事务处理或分析”），亦或定期的数据完整性检查（即监视数据损坏情况）。如果这些查询在不同时间点观察数据库，可能会返回无意义的结果。

快照级别隔离这是解决上述问题最常见的手段。其总体想法是，每个事务都从数据库的一致性快照中读取， 事务一开始所看到是最近提交的数据， 即使数据随后可能被另一个事务更改，但保证每个事务都只看到该特定时间点的旧数据。

快照级别隔离对于长时间运行的只读查询（如备份和分析）非常有用。如果数据在执行查询的同时还在发生变化，那么查询结果对应的物理含义就难以理清。而如果查询的是数据库在某时刻点所冻结的一致性快照，则查询结果的含义非常明确。

快照级别隔离非常流行，目前PostgreSQL，MySQL的InnoDB存储引擎，Oracle，SQLServer等都已经支持。

##### **实现快照级别隔离**

与读－提交隔离类似，快照级别隔离的实现通常采用写锁来防止脏写（参阅本章前面的“实现读－提交”），这意味着正在进行写操作的事务会阻止同一对象上的其他事务。但是，读取则不需要加锁。从性能角度看，快照级别隔离的一个关键点是读操作不会被写操作阻止。这使得数据库可以在处理正常写入的同时，在一致性快照上执行长时间的只读查询，且两者之间没有任何锁的竞争。

为了实现快照级别隔离，数据库采用了一种类似于图 7-4 中防止脏读但却更为通用的机制。考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态，所以数据库保留了对象多个不同的提交版本，这种技术因此也被称为多版本并发控制 (Multi -Version Concurrency Control , MVCC ）。

如果只是为了提供读－提交级别隔离，而不是完整的快照级别隔离，则只保留对象的两个版本就足够了 ： 一个己提交的旧版本和尚未提交的新版本。所以， 支持快照级别隔离的存储引擎往往直接采用MVCC来实现读-提交隔离。典型的做法是，在读－提交级别下，对每一个不同的查询单独创建一个快照；而快照级别隔离则是使用一个快照来运行整个事务。

图 7-7 说明了 PostgreSQL 如何实现基于MVCC的快照级别隔离（其他实现基本类似）。当事务开始时， 首先赋予一个唯一的、单调递增的事务ID (txid ）。每当事务向数据库写入新内容时，所写的数据都会被标记写入者的事务ID 。

​    ![0](https://note.youdao.com/yws/res/20194/WEBRESOURCE24ec3ffdc2c3fdf3d54ce5fb582716e2)

表中的每一行都有一个created_by字段，其中包含了创建该行的事务ID 。每一行还有一个deleted_by字段，初始为空。 如果事务要删除某行， 该行实际上并未从数据库中删除，而只是将deleted_by字段设置为请求删除的事务ID （仅仅标记为删除） 。事后，当确定没有其他事务引用该标记删除的行时，数据库的垃圾回收进程才去真正删除井释放存储空间。

这样一笔更新操作在内部会被转换为一个删除操作加一个创建操作。例如，图 7-7中， 事务13从账户2中扣除 100 美元，余额从500美元减为400 美元。 accounts表里会出现两行账户2 ： 一个余额为$500但标记为删除的行（由事务13删除），另一个余额为$400 ，由事务13创建。

##### **一致性快照的可见性规则**

当事务读数据库时，通过事务ID可以决定哪些对象可见，哪些不可见。要想对上层应用维护好快照的一致性，需要精心定义数据的可见性规则。例如 ：

\1. 每笔事务开始时，数据库列出所有当时尚在进行中的其他事务（即尚未提交或中止），然后忽略这些事务完成的部分写入（尽管之后可能会被提交），即不可见。

\2. 所有中止事务所做的修改全部不可见。

\3. 较晚事务 ID （即晚于当前事务） 所做的任何修改不可见，不管这些事务是否完成了提交。

\4. 除此之外，其他所有的写入都对应用查询可见。

以上规则可以适用于创建操作和删除操作。在图 7-7 中，当事务12从账户2读取时，它看到的是$500的余额，这是因为删除操作是由稍后事务13所产生的（依据规则3 ，事务 12对事务13所做的删除不可见），同理， 400美元余额的创建操作也不可见。

换句话说，仅当以下两个条件都成立， 则该数据对象对事务可见：

- 事务开始的时刻，创建该对象的事务已经完成了提交。
- 对象没有被标记为删除；或者即使标记了，但删除事务在当前事务开始时还没有完成提交。

长时间运行的事务可能会使用快照很长时间，从其他事务的角度来看，它可能在持续访问正在被覆盖或删除的内容。由于没有就地更新，而是每次修改总创建一个新版本，因此数据库可以以较小的运行代价来维护一致性快照。

##### **索引与快照级别隔离**

接下来一个问题是，这种多版本数据库该如何支持索引呢？一种方案是索引直接指向对象的所有版本，然后想办法过滤对当前事务不可见的那些版本。当后台的垃圾回收进程决定删除某个旧对象版本时，对应的索引条目也需要随之删除。

在实践中，有许多细节决定了多版本并发控制的实际性能表现。例如，可以把同一对象的不同版本放在一个内存页面上， PostgreSQL采取这样的优化措施来避免更新索引。

CouchDB 、 Datomic和LMDB则使用另一种方法。它们主体结构是B-tree （参阅第3章“ B-tree”），但采用了 一种追加／写时复制的技术，当需要更新时，不会修改现有的页面，而总是创建一个新的修改副本，拷贝必要的内容，然后让父结点，或者递归向上直到树的root结点都指向新创建的结点。那些不受更新影响的页面都不需要复制，保持不变并被父结点所指向。

这种采用追加式的B-tree ，每个写入事务（或一批事务）都会创建一个新的B-tree root ，代表该时刻数据库的一致性快照。这时就没有必要根据事务 ID再去过滤掉某些对象，每笔写入都会修改现有的B-tree，因为之后的查询可以直接作用于特定快照B-tree（有利于查询性能）。 采用这种方法依然需要后台进程来执行压缩和垃圾回收。

##### **可重复读与命名混淆**

快照级别隔离对于只读事务特别有效。但是，具体到实现，许多数据库却对它有着不同的命名。 Oracle称之为可串行化， PostgreSQL和MySQL则称为可重复读。

这种命名混淆的原因是SQL标准并没有定义快照级别隔离，而仍然是基于老的SystemR 1975年所定义的隔离级别，而当时还没有出现快照级别隔离。标准定义的是 “可重复读”，这看起来比较接近于快照级别隔离，所以PostgreSQL和MySQL称它们的快照级别隔为 “可重复读“ 这符合标准要求（即合规性）。

然而必须指出， SQL标准对隔离级别的定义还是存在一些缺陷，某些定义模棱两可，不够精确，且不能做到与实现无关。尽管有几个数据库实现了可重复读，表面上看符合标准，但它们实际所提供的保证却大相径庭。可重复读有一个更为严谨的定义，然而大多数实现并没有遵循它。最后还要指出， IBM DB2的 “可重复读” 实则是可串行化级别隔离。

现在的结果是，我们已经搞不清楚 “可重复读” 究竟代表什么了。

#### **防止更新丢失**

总结一下，我们所讨论的读－提交和快照级别隔离主要都是为了解决只读事务遇到并发写时可以看到什么（虽然中间也涉及脏写问题），总体而言我们还没有触及另一种情况，即两个写事务并发，而脏写只是写并发的一个特例。

写事务并发还会带来其他一些值得关注的冲突问题，最著名的就是更新丢失问题，前面图 7-1正是这样的一个例子。

更新丢失可能发生在这样一个操作场景中：应用程序从数据库读取某些值，根据应用逻辑做出修改，然后写回新值 （ read - modify － write过程）。 当有两个事务在同样的数据对象上执行类似操作时，由于隔离性，第二个写操作并不包括第一个事务修改后的值，最终会导致第一个事务的修改值可能会丢失。这种冲突还可能在其他不同的场景下发生，例如：

- 递增计数器，或更新账户余额（需要读取当前值，计算新值并写回更新后的值）。
- 对某复杂对象的一部分内容执行修改，例如对JSON文档中一个列表添加新元素（需要读取并解析文档，执行更改并写回修改后的文档）。
- 两个用户同时编辑wiki页面，且每个用户都尝试将整个页面发送到服务器，覆盖数据库中现有内容以使更改生效 。

并发写事务冲突是一个普遍问题，目前有多种可行的解决方案。

##### **原子写操作**

许多数据库提供了原子更新操作，以避免在应用层代码完成“读－修改－写回”操作，如果支持的话，通常这就是最好的解决方案。例如，以下指令在多数关系数据库中都是并发安全的：

UPDATE counters SET value = value + 1 WHERE key ＝'foo'；

类似地，像MongoDB这样的文档数据库支持对JSON文档的某部分进行本地修改的原子操作， Redis也提供了对特定数据结构（如优先级队列）修改的原子操作 。 然而，并非所有的应用更新操作都可以以原子操作的方式来表达，例如维基页面的更新涉及各种文本编辑。无论如何，如果原子操作可行，那么它就是推荐的最佳方式。

原子操作通常采用对读取对象加独占锁的方式来实现，这样在更新被提交之前不会其他事务可以读它。这种技术有时被称为游标稳定性。 另一种实现方式是强制所有的原子操作都在单线程上执行。不过，基于对象关系映射（ ORM ）框架可以很容易地就产生出来非“读－修改－写回”的应用层代码，导致无法使用数据库所提供的原子操作。 假如你清楚知道自己在做什么，或许这并不会引发什么问题，但往往这种情况会埋下很多难以发现的潜在错误。

##### **显式加锁**

如果数据库不支持内置原子操作，另一种防止更新丢失的方法是由应用程序显式锁定待更新的对象。 然后，应用程序可以执行“读－修改－写回”这样的操作序列；此时如果有其他事务尝试同时读取对象，则必须等待当前正在执行的序列全部完成。

例如，考虑一个多人游戏，其中几个玩家可以同时移动同一个数字。只靠原子操作可能还不够，因为应用程序还需要确保玩家的移动还需遵守其他游戏规则，这涉及一些应用层逻辑，不可能将其剥离转移给数据库层在查询时执行。此时，可以使用锁来防止两名玩家同时操作相同的棋子，参见示例 7-1 。

​    ![0](https://note.youdao.com/yws/res/20346/WEBRESOURCE475a00631737767302eb38b589c68c0d)

首先该方法是可行的，但要做到这一点，需要仔细考虑清楚应用层的逻辑。很多代码会忘记在必要的地方加锁，结果很容易引入竞争冲突。

##### **自动检测更新丢失**

原子操作和锁都是通过强制 “读－修改－写回” 操作序列串行执行来防止丢失更新。另一种思路则是先让他们并发执行，但如果事务管理器检测到了更新丢失风险，则会中止当前事务，并强制回退到安全的 “读－修改－写回” 方式。

该方法的一个优点是数据库完全可以借助快照级别隔离来高效地执行检查。的确，PostgreSQL的可重复读， Oracle的可串行化以及SQL Server的快照级别隔离等，都可以自动检测何时发生了更新丢失，然后会中止违规的那个事务。但是， MySQL/InnoDB 的可重复读却并不支持检测更新丢失。有一些观点认为，数据库必须防止更新丢失，要不然就不能宣称符合快照级别隔离，如果基于这样的定义，那么MySQL就属于没有完全支持快照级别隔离。更新丢失检测是一个非常赞的功能，应用层代码因此不用依赖于某些特殊的数据库功能。开发者可能会不小心忘记使用锁或原子操作，但更新丢失检测会自动生效，有效地避免这类错误。

##### **原子比较和设置**

在不提供事务支持的数据库中，有时你会发现它们支持原子 “比较和设置” 操作（之前“单对象写入”有提到）。使用该操作可以避免更新丢失，即只有在上次读取的数据没有发生变化时才允许更新；如果已经发生了变化 ， 则回退到 “读－修改－写回” 方式。例如，为了防止两个用户同时更新同一个wiki页面，可以尝试下面的操作，这样只有当页面从上次读取之后没发生变化时，才会执行当前的更新 ：

​    ![0](https://note.youdao.com/yws/res/20360/WEBRESOURCE02cebde7b2c081a50f2eb3087d70d74e)

如果内容已经有了变化且值与“旧内容”不匹配，则更新将失败，需要应用层再次检查并在必要时进行重试。需要注意，如果WHERE语句是运行在数据库的某个旧的快照上，即使另一个并发写入正在运行，条件可能仍然为真，最终可能无法防止更新丢失问题。所以在使用之前，应该首先仔细检查 “比较－设置” 操作的安全运行条件。

##### **冲突解决与复制**

对于支持多副本的数据库（参见第5章），防止丢失更新还需要考虑另一个维度 ：由于多节点上的数据副本，不同的节点可能会并发修改数据，因此必须采取一些额外的措施来防止丢失更新。

加锁和原子修改都有个前提即只有一个最新的数据副本。然而，对于多主节点或者无主节点的多副本数据库，由于支持多个并发写 ，且通常以异步方式来同步更新，所以会出现多个最新的数据副本。 此时加锁和原子比较将不再适用（我们将在第9章“线性化”详细讨论这个问题）。

正如第5章“检测并发写”所描述的，多副本数据库通常支持多个并发写，然后保留多个冲突版本（互称为兄弟），之后由应用层逻辑或依靠特定的数据结构来解决、合并多版本。

如果操作可交换（顺序无关，在不同的副本上以不同的顺序执行时仍然得到相同的结果）， 则原子操作在多副本情况下也可以工作。例如，计数器递增或向集合中添加元素等都是典型的可交换操作。这也是Riak 2.0新数据类型的设计思路，当一个值被不同的客户端同时更新时， Riak 自动将更新合并在一起，避免发生更新丢失。

而 “最后写入获胜（ LWW ）”（详见第5章）冲突解决方法则容易丢失更新。不幸的是，目前LWW是许多多副本数据库的默认配置。

#### **写倾斜与幻读**

当多个事务同时写入同一对象时引发了两种竞争条件，即前面章节所讨论的脏写和更新丢失。为了避免数据不一致，需要借助数据库的一些内置机制，或者采取手动加锁、执行原子操作等。

然而，这还不是并发写所引发的全部问题。本节马上将看到更为微妙的写冲突的例子。

首先，设想这样一个例子：你正在开发一个应用程序来帮助医生管理医院的轮班。通常，医院会安排多个医生值班，医生也可以申请调整班次（例如他们自己生病了），但前提是确保至少一位医生还在该班次中值班。

现在情况是，Alice和Bob是两位值班医生。两人碰巧都感到身体不适，因而都决定请假。不幸的是，他们几乎同一时刻点击了调班按钮。接下来发生的事情如图 7-8 所示。

每笔事务总是首先检查是否至少有两名医生目前在值班。如果是的话，则有一名医生可以安全里离开。由于数据库正在使用快照级别隔离，两个检查都返回有两名医生，所以两个事务都安全地进入到下一个阶段。接下来Alice更新自己的值班记录为离开，同样， Bob也更新自己的记录。两个事务都成功提交，最后的结果却是没有任何医生在值班，显然这违背了至少一名医生值班的业务要求。

##### **定义写倾斜**

这种异常情况称为写倾斜。它既不是一种脏写，也不是更新丢失，两笔事务更新的是两个不同的对象（分别是Alice和Bob的值班记录） 。这里的写冲突并不那么直接，但很显然这的确是某种竞争状态： 试想，如果两笔事务是串行执行， 则第二个医生的申请肯定被拒绝；只有同时执行两个事务时才会引发该异常。

​    ![0](https://note.youdao.com/yws/res/20460/WEBRESOURCEbd9a360f09ef2cb608c4c577bce5aa1f)

可以将写倾斜视为一种更广义的更新丢失问题。即如果两个事务读取相同的一组对象，然后更新其中一部分：不同的事务可能更新不同的对象，则可能发生写倾斜 ； 而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失（具体取决于时间窗口）。

我们已经给出了多种防范更新丢失的手段。然而对于写倾斜，可选的方案则有很多限制 ：

- 由于涉及多个对象，单对象的原子操作不起作用。
- 基于快照级别隔离来实现更新丢失自动检测也有问题：目前所有的数据库实现，包括PostgreSQL的可重复读，MySQL/InnoDB可重复读 ， Oracle可串行化以及SQL Server的快照级别隔离级别都不支持检测写倾斜问题。自动防止写倾斜要求真正的可串行化隔离（参阅本章后面“可串行化” ） 。
- 某些数据库支持自定义约束条件，然后由数据库代为检查 、 执行约束（例如 ，唯一性，外键约束或限制一些特定值）。但是，至少一名医生值班这样的要求涉及对多个对象进行约束，目前大多数数据库不支持这种类型约束，所以取决于具体的数据库，开发者可能可以采用触发器或物化视图来自己实现类似约束。
- 如果不能使用可串行化级别隔离， 一个次优的选择是对事务依赖的行来显式的加锁。对于上述医生值班的例子，可以这样：

​    ![0](https://note.youdao.com/yws/res/20482/WEBRESOURCE824012ec21fa9bb96e31825cc006d063)

##### **更多写倾斜的例子**

写倾斜可能看起来很晦涩拗口，可一旦深刻意识到问题的本质，就会注意到还有更多可能发生的场景。下面就是一些例子 ：

会议室预订系统

假设要求同一时间、同一个会议室不能被预订两次。 当有人想要预订时，首先检查是否有冲突的预订（即对同一房间的预订存在时间范围重叠），如果没有，则提交申请，参见示例7-2

​    ![0](https://note.youdao.com/yws/res/20493/WEBRESOURCEbd803d5a08cc41dba7f1babcf6c4755a)

需要指出，快照级别隔离无法阻止并发用户预订同一个会议室。 为了保证预订不会产生冲突，需要可串行化的隔离。

多人游戏

在示例 7-1 中，我们使用加锁来防止更新丢失（即两个玩家不能同时移动同一个数字）。 但是，锁并不能阻止玩家将两个不同的数字移动到棋盘上的同一个位置上，或者其他可能违反游戏规则的移动。这取决于具体的游戏规则，可能需要更多的条件约束，否则很容易发生写倾斜。

声明一个用户名

网站通常要求每个用户有唯一的用户名，两个用户可能同时尝试创建相同的用户名。可以采用事务的方式首先来检查名称是否被使用，如果没有，则使用该名称创建胀户。但是，和之前的例子类似，在快照级别隔离下这是不安全的。不过，对于该例子， 一个简单的方案是采用唯一性约束（第二个事务由于违反约束，会中止创建相同用户名）。

防止双重开支

支付或积分相关的服务通常需要检查用户的花费不能超过其限额。一种方式是在用户的账户中插入一个临时的支出项目，然后对于所有项目，检查总开销并对比限额。由于写倾斜问题，可能会同时插入两个支出项目，两个交易各自都不超额，也不会注意到对方，但加在一起则会超额。

##### **为何产生写倾斜**

上述所有写倾斜的例子都遵循以下类似的模式：

\1. 首先输入一些匹配条件，即采用 SELECT查询所有满足条件的行（例如，至少有两名医生正在值班，同一时刻房间没有预订，棋盘的某位置没有出现数字，用户名还没有被占用，账户里还有余额等）。

\2. 根据查询的结果，应用层代码来决定下一步的操作（有可能继续，或者报告错误并中止）。

\3. 如果应用程序决定继续执行，它将发起数据库写入（ INSERT , UPDATE或DELETE ）并提交事务。

而这个写操作会改变步骤2做出决定的前提条件。换句话说，如果提交写入之后再重复执行步骤 1 的SELECT查询，就会返回完全不同的结果，原因是刚刚的写操作改变了决定的前提条件（现在只有一名医生在值班，现在会议室已被预订，现在棋盘位置已经出现了数字，现在用户名已被占用，现在余额已经不足等）。

上述步骤可能有不同的执行顺序，例如，可以先写入，然后是SELECT查询，最后根据查询来决定是否提交或者放弃。

对于医生值班的例子，步骤3中所修改的行恰好是步骤1查询结果的一部分，因此如果先修改值班记录并加锁（ SELECT FOR UPDATE ），再查询可以保证事务安全，避免写倾斜。然而，对于其他例子则并不适用，它们检查的是不满足给定搜索条件的行（预期结果为空），接下来添加符合条件的行。如果步骤 1 的查询根本没有返回任何行，则SELECT FOR UPDATE 也就无从加锁。

**GPT解释**

------

这种在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读。快照级别隔离可以避免只读查询时的幻读，但是对于我们上面所讨论那些读－写事务，它却无法解决棘手的写倾斜问题。

可重复读（Repeatable Read）：

- MySQL 的默认隔离级别。
- 确保在一个事务内多次读取同一数据的结果是一致的，即使在这期间其他事务提交了更新该数据的操作。
- 防止了脏读和不可重复读，但在某些情况下仍可能发生幻读，特别是对于范围查询。
- 示例：一个事务读取了一个范围的行，然后另一个事务插入了一些新的行到这个范围中并提交。如果第一个事务再次执行相同的范围查询，可能会看到刚插入的新行（幻读）。

幻读是指当一个事务在两次查询同一个范围的数据时，另一个事务在这个范围内插入或删除了一些记录，导致第一个事务在第二次查询时看到了之前不存在的数据（“幻影”数据）。

例如，一个事务对所有年龄大于18的用户进行了两次查询，而在两次查询之间，另一个事务插入了一个新的年龄大于18的用户。在第二次查询时，第一个事务就会发现一个之前未见过的“幻影”用户。

在可重复读隔离级别下，大多数数据库系统可以防止不可重复读，但无法完全防止幻读。要解决幻读问题，通常需要使用更高级别的隔离，如串行化（Serializable）。

##### **实体化冲突**

如果问题的关键是查询结果中没有对象（空）可以加锁，或许可以人为引入一些可加锁的对象？

例如，对于会议室预订的例子，构造一个时间-房间表，表的每一行对应于特定时间段（例如最小15分钟间隔）的特定房间。我们提前，例如对接下来的6个月，创建好所有可能的房间与时间的组合。

现在，预订事务可以查询并锁定（ SELECT FOR UPDATE ）表中与查询房间和时间段所对应的行。加锁之后，即可检查是否有重叠，然后像之前一样插入新的预订。注意，这种附加表格并不存储预订相关的信息，它仅仅用于方便加锁，防止同一房间和时间范围内的重复预订。

这种方法称为实体化冲突（或物化冲突），它把幻读问题转变为针对数据库中一组具体行的锁冲突问题。然而，弄清楚如何实现实体化往往也具有挑战性，实现过程也容易出错，这种把一个并发控制机制降级为数据模型的思路总是不够优雅。出于这些原因，除非万不得己，没有其他可选方案，我们不推荐采用实体化冲突。而在大多数情况下，可串行化隔离方案更为可行 。

### **串行化**

我们已经分析了很多容易出现竞争条件的例子 。 采用读－提交和快照隔离可以防止其中一部分，但并非对所有情况都有效，例如写倾斜和幻读所导致的棘手问题。最后你会发现面临以下挑战 ：

- 隔离级别通常难以理解，而且不同的数据库的实现不尽一致（例如 “可重复读取” 的含义在各家数据库的差别很大）。
- 如果去检查应用层的代码，往往很难判断它在特定的隔离级别下是否安全，特别是对于大型应用系统， 几乎无法预测所有可能并发情况。
- 同时，还缺乏好的工具来帮助检测竞争状况。理论上，静态分析可能有所帮助，但更多的还只是学术研究缺乏实用性。测试并发性问题往往效率很低，一切取决于时机，它只有在特定的情景下才会出现，存在很大的不确定性。

而这些都不是新问题，自20世纪70年代引人弱隔离级别以后，这种情况就一直存在。长久以来，研究人员给出的答案都很简单 ： 采用可串行化隔离 ！

可串行化隔离通常被认为是最强的隔离级别。它保证即使事务可能会并行执行，但最终的结果与每次一个即串行执行结果相同。这意味着，如果事务在单独运行时表现正确，那么它们在并发运行时结果仍然正确，换句话说，数据库可以防止所有可能的竞争条件。

如果串行化隔离比其他各种弱隔离级别好得多，那么为什么没有广泛使用呢？要回答这个问题，我们需要看看可串行化究竟是什么，以及如何执行。目前大多数提供可串行化的数据库都使用了以下三种技术之一，我们将依次探讨：

- 严格按照串行顺序执行（参阅本章后面的“实际的串行执行”）。
- 两阶段锁定（参阅本章后面的“两阶段加锁”），几十年来这几乎是唯一可行的选择。
- 乐观并发控制技术，例如可串行化的快照隔离（参阅本章后面的“可串行化的快照隔离”）。

我们首先限定在单节点背景下讨论这些技术。在接下来的第9章，我们将其推广到分布式系统多节点场景。

#### **实际串行执行**

解决并发问题最直接的方法是避免并发 ：即在一个线程上按顺序方式每次只执行一个事务 。 这样我们完全回避了诸如检测、防止事务冲突等问题，其对应的隔离级别一定是严格串行化的。

看上去这是个很直白的想法，但数据库设计人员直到2007年前后才完全确信，采用单线程循环来执行事务是可行的。如果多线程并发在过去的30年中一只被认为是提升性能的关键，那么现在转向单线程执行，这意味着什么呢？

有以下两方面的进展促使我们重新做出思考：

- 内存越来越便宜， 现在许多应用可以将整个活动数据集都加载到内存中（参阅第3章“将所有内容加载到内存”）。当事务所需的所有数据都在内存中时，事务的执行速度要比等待磁盘I/O快得多。
- 数据库设计人员意识到 OLTP事务通常执行很快，只产生少量的读写操作（参阅第3章“事务处理或分析”）。相比之下，运行时间较长的分析查询则通常是只读的，可以在一致性快照（使用快照隔离）上运行，而不需要运行在串行主循环里。

VoltDB / H-Store 、 Redis和Datomic等采用串行方式执行事务。单线程执行有时可能会比支持并发的系统效率更高，尤其是可以避免锁开销 。但是 ，其吞吐量上限是单个CPU核的吞吐量。为了充分利用单线程，相比于传统形式， 事务也需要做出相应调整。

##### **采用存储过程封装事务**

在数据库的早期应用阶段，采用事务机制是希望能囊括用户的所有操作序列。例如，预订机票涉及多个步骤（搜索路线，票价和可用座位，决定行程，在行程的某个航班上预订座位，输入乘客信息，最后是付款）。数据库设计者认为，如果整个过程是一个事务，那么就可以方便地原子化执行。

然而，人类做出决定并回应的速度通常比较慢。如果数据库事务总是需要等待来自用户的输入，同时还要支持潜在大量并发需求，那么系统大部分时间将处于空闲状态。这样数据库无法高效运行，所以几乎所有的 OLTP应用程序都避免在事务执行中等待用户交互从而使事务非常简洁。对于Web ，这意味着事务会在一个HTTP请求中提交，而不会跨越多个请求。新的事务往往需要开启新的HTTP请求。

即使把人为交互从关键路径移除掉，事务总体沿用的依然是交互式客户端／服务器风格， 一次一个请求语句。应用程序来提交查询，读取结果，可能会根据前一个查询的结果来进行其他查询，依此类推。请求与结果在应用层代码（某台机器）和数据库服务器（另一台机器）之间来回交互。

对于这种交互式的事务处理，大量时间花费在应用程序与数据库之间的网络通信。如果不允许事务并发，而是一次仅处理一个，那么吞吐量非常低，数据库总是在等待应用提交下一个请求。在这种类型的数据库中，为了获得足够的吞吐性能，需要能够同时处理多个事务。

出于这个原因，采用单线程串行执行的系统往往不支持交互式的多语句事务。应用程序必须提交整个事务代码作为存储过程打包发送到数据库。这之间的差异如图 7-9所示。把事务所需的所有数据全部加载在内存中，使存储过程高效执行，而无需等待网络或磁盘I/O 。

​    ![0](https://note.youdao.com/yws/res/20731/WEBRESOURCE20608961aa6821a3aa393b74df9e829c)

##### **存储过程的优缺点**

关系型数据库支持存储过程已经有很长一段时间了，自 1999年以来已是SQL标准(SQL / PSM ）。然而由于各种原因，存储过程的声誉有所下降 ：

- 每家数据库厂商都有自己的存储过程语言 （ Oracle的PL / SQL, SQL Server的T-SQL, PostgreSQL的PL / pgSQL等）。这些语言并没有跟上通用编程语言的发展，如果从今天的角度来看，这些语义都相当丑陋、过时，而且缺乏如今大多数编程语言所常用的函数库。
- 在数据库中运行代码难以管理：与应用服务器相比，调试更加困难，版本控制与部署复杂，测试不便，并且不容易和指标监控系统集成 。
- 因为数据库实例往往被多个应用服务器所共享 ，所以数据库通常比应用服务器要求更高的性能。数据库中一个设计不好的存储过程（例如，消耗大量内存或CPU时间）要比同样低效的应用服务器代码带来更大的麻烦。

不过这些问题也是可以克服的。最新的存储过程已经放弃了PL / SQL，而是使用现有的通用编程语言，例如VoltDB使用Java或Groovy，Datomic使用Java或Clojure，而Redis使用Lua。

存储过程与内存式数据存储使得单线程上执行所有事务变得可行。它们不需要等待I/O ，避免加锁开销等复杂的并发控制机制，可以得到相当不错的吞吐量 。

VoltDB还借助存储过程来执行复制：它并非将事务的执行结果从一个节点复制到另 一个节点，而是在每个副本上都执行相同的存储过程。因此， VoltDB要求存储过程必须是确定性的（即不同的节点上运行时，结果必须完全相同）。如果事务需要获得当前的日期和时间等，必须通过专门的确定性API来实现。

##### **分区**

串行执行所有事务使得并发控制更加简单，但是数据库的吞吐量被限制在单机单个CPU核。虽然只读事务可以在单独的快照上执行，但是对于那些高写入需求的应用程序，单线程事务处理很容易成为严重的瓶颈。

为了扩展到多个CPU核和多节点，可以对数据进行分区（参见第6章） , VoltDB支持这种配置模式。如果你能找到一个方法来对数据集进行分区，使得每个事务只在单个分区内读写数据，这样每个分区都可以有自己的事务处理线程且独立运行。 此时为每个CPU核分配一个分区，则数据库的总体事务吞吐量可以到达与CPU核的数量成线性比例关系。

但是，对于跨分区的事务，数据库必须在涉及的所有分区之间协调事务。存储过程需要跨越所有分区加锁执行，以确保整个系统的可串行化。

由于跨分区事务具有额外的协调开销，其性能比单分区内要慢得多。 VoltDB报告的跨区事务吞吐量大约只有 1000次／秒，这比单分区吞吐量低了好几个数量级，而且没法通过增加更多机器的方式来扩展性能。

事务是否能只在单分区上执行很大程度上取决于应用层的数据结构。简单的键值数据比较容易切分，而带有多个二级索引的数据则需要大量的跨区协调（参阅第6章“分区与二级素引”），因此不太合适。

##### **串行执行小结**

当满足以下约束条件时，串行执行事务可以实现串行化隔离：

- 事务必须简短而高效，否则一个缓慢的事务会影响到所有其他事务的执行性能。
- 仅限于活动数据集完全可以加载到内存的场景。有些很少访问的数据可能会被移到磁盘，但万一单线程事务需要访问它，就会严重拖累性能。
- 写入吞吐量必须足够低，才能在单个CPU核上处理；否则就需要采用分区，最好没有跨分区事务。
- 跨分区事务虽然也可以支持，但是占比必须很小。

#### **两阶段加锁**

近三十年来，可以说数据库只有一种被广泛使用的串行化算法，那就是两阶段加锁(two-phase locking, 2PL ）。

之前我们看到，可以使用加锁的方法来防止脏写（参阅本章前面的“防止脏写”）即如果两个事务同时尝试写入同一个对象时 ，以加锁的方式来确保第二个写入等待前面事务完成（包括中止或提交）。

两阶段加锁方法类似，但锁的强制性更高。多个事务可以同时读取同一对象，但只要出现任何写操作（包括修改或删除），则必须加锁以独占访问：

- 如果事务A已经读取了某个对象，此时事务B想要写入该对象，那么B必须等到A提交或中止之才能继续。以确保B不会在事务A执行的过程中间去修改对象。
- 如果事务A 已经修改了对象， 此时事务B想要读取该对象， 则B必须等到A提交或中止之后才能继续。对于2PL ，不会出现读到旧值的情况（参见图 7-1 的示例）。

因此2PL不仅在并发写操作之间互斥，读取也会和修改产生互斥 。 快照级别隔离的口号 “读写互不干扰” （ 参阅本章前面的“实现快照级别隔离 ” ）非常准确地点明了它和两阶段加锁的关键区别。另一方面，因为2PL提供了串行化，所以它可以防止前面讨论的所有竞争条件，包括更新丢失和写倾斜。

##### **实现两阶段加锁**

目前， 2PL 已经用于MySQL (InnoDB）和 SQL Server中的“可串行化隔离”， 以及DB2中的“可重复读隔离”。此时数据库的每个对象都有一个读写锁来隔离读写操作 。 即锁可以处于共享模式或独占模式。基本用法如下：

- 如果事务要读取对象 ，必须先以共享模式获得锁。可以有多个事务同时获得一个对象的共享锁，但是如果某个事务已经获得了对象的独占锁，则所有其他事务必须等待。
- 如果事务要修改对象，必须以独占模式获取锁。不允许多个事务同时持有该锁（包括共享或独占模式），换言之，如果对象上已被加锁， 则修改事务必须等待。
- 如果事务首先读取对象，然后尝试写入对象，则需要将共享锁升级为独占锁。升级锁的流程等价于直接获得独占锁。
- 事务获得锁之后， 一直持有锁直到事务结束（包括提交或中止）。这也是名字“两阶段”的来由，在第一阶段即事务执行之前要获取锁，第二阶段（即事务结束时）则释放锁。

由于使用了这么多的锁机制，所以很容易出现死锁现象 ，例如事务A可能在等待事务B释放它的锁， 而事务B在等待事务A释放所持有的锁。数据库系统会自动检测事务之间的死锁情况，并强行中止其中的一个以打破僵局，这样另一个可以继续向前执行 。而被中止的事务需要由应用层来重试。

##### **两阶段加锁的性能**

两阶段加锁的主要缺点，或者说自1970年以来并不被所有人接纳的主要原因在于性能 ： 其事务吞吐量和查询响应时间相比于其他弱隔离级别下降非常多。

部分原因在于锁的获取和释放本身的开销，但更重要的是其降低了事务的并发性 。 按2PL的设计， 两个并发事务如果试图做任何可能导致竞争条件的事情，其中一个必须等待对方完成 。

传统的关系数据库并不限制事务的执行时间，且当初是为和人类输入等交互式应用而设计的。结合2PL ， 最终结果是，当一个事务还需要等待另一个事务时，那么最终的等待时间几乎是没有上限的。即使可以保证自己的事务足够简短、高效，但一旦出现多个事务同时访问同一对象，会形成一个等待队列，事务就必须等待队列前面所有其他事务完成之后才能继续。

因此， 在2PL模式下数据库的访问延迟具有非常大的不确定性，如果工作负载存在严重竞争 ，以百分比方式观察延迟指标会发现非常缓慢（参阅第 1 章“描述性能”）。试想这种情况，某个事务本身很慢，或者是由于需要访问大量数据而获得了许多锁，则它还会导致系统的其他部分都停顿下来。 如果应用需要稳定如一的性能，这种不确定性就是致命的 。

同样是基于加锁方式的读－提交隔离也可能发生死锁，然而在2PL下，取决于事务的访问模式，死锁可能变得更为频繁。因而导致另一个性能问题，即如果事务由于死锁而被强行中止，应用层就必须从头重试，假如死锁过于频繁，则最后的性能和效率必然大打折扣。

##### **谓词锁**

对于加锁，我们还忽略了一个微妙但重要的细节。如本章前面“写倾斜与幻读”中的幻读问题，即一个事务改变另一个事务的查询结果。可串行化隔离也必须防止幻读问题。

以会议室预订为例，如果事务在查询某个时间段内一个房间的预订情况（ 参见示例7-2 ）， 则另一个事务不能同时去插入或更新同一时间段内该房间的预订情况 ，但它可以修改其他房间的预订情况，或者在不影响当前查询的情况下，修改该房间的其他时间段预订。

如何实现呢？技术上讲，我们需要引入一种谓词锁（或者属性谓词锁）。谓词锁不是锁定特定的对象（如行或页），而是锁定一组可能存在的对象。这些对象是由一个谓词（即搜索条件或查询条件）定义的。例如，一个事务可能需要对所有年龄大于30岁的员工记录进行操作。谓词锁会锁定所有满足这个条件的记录，无论这些记录当前是否存在。

**锁定类型有下面两种**

共享谓词锁：如果一个事务仅读取满足特定条件的记录，它可能会获得一个共享谓词锁，这允许其他事务读取同样的记录，但阻止其他事务插入或删除满足这些条件的记录。

独占谓词锁：如果一个事务需要更新满足特定条件的记录，它需要获得一个独占谓词锁，这阻止其他事务读取、插入或删除满足这些条件的记录。

谓词锁会限制如下访问：

- 如果事务A想要读取某些满足匹配条件的对象，例如采用 SELECT查询，它必须以共享模式获得查询条件的谓词锁。如果另一个事务B正持有任何一个匹配对象的互斥锁，那么A必须等到B释放锁之后才能继续执行查询。
- 如果事务A想要插入、更新或删除任何对象，则必须首先检查所有旧值和新值是否与现有的任何谓词锁匹配（即冲突）。如果事务B持有这样的谓词锁，那么A必须等到B完成提交（或中止）后才能继续。

这里的关键点在于， 谓词锁甚至可以保护数据库中那些尚不存在但可能马上会被插入的对象（幻读）。将两阶段加锁与谓词锁结合使用，数据库可以防止所有形式的写倾斜以及其他竞争条件，隔离变得真正可串行化。

##### **索引区间锁**

不幸的是，谓词锁性能不佳 ： 如果活动事务中存在许多锁，那么检查匹配这些锁就变得非常耗时。因此，大多数使用 2PL的数据库实际上实现的是索引区间锁（或者next-key locking ） ，本质上它是对谓词锁的简化或者近似。

简化谓词锁的方式是将其保护的对象扩大化，首先这肯定是安全的。例如，如果一个谓词锁保护的是查询条件是 ： 房间 123 ，时间段是中午至下午1点 ，则一种方式是通过扩大时间段来简化，即保护123房间的所有时间段；或者另一种方式是扩大房间，即保护中午至下午 1 点之间的所有房间（而不仅是123号房间）。这样，任何与原始谓词锁冲突的操作肯定也和近似之后的区间锁相冲突。

对于房间预订数据库，通常会在room id列上创建索引，和／或在start_time和end_time上有索引（否则前面的查询在大型数据库上会很慢） ：

- 假设索引位于room i d上，数据库使用此索引查找123号房间的当前预订情况。现在，数据库可以简单地将共享锁附加到此索引条目，表明事务己搜索了123号房间的所有时间段预订。
- 或者，如果数据库使用基于时间的索引来查找预订，则可以将共享锁附加到该索引中的一系列值， 表示事务已经搜索了该时间段内的所有值 （例如直到 2020年 1月 1日）。

无论哪种方式，查询条件的近似值都附加到某个索引上。接下来，如果另一个事务想要插入、更新或删除同一个房间和／或重叠时间段的预订，则肯定需要更新这些索引 ， 一定就会与共享锁冲突，因此会自动处于等待状态直到共享锁释放。

这样就有效防止了写倾斜和幻读问题。 的确，索引区间锁不像谓词锁那么精确 （会锁定更大范围的对象，而超出了串行化所要求的部分），但由于开销低得多，可以认为是一种很好的折中方案。

如果没有合适的索引可以施加区间锁，则数据库可以回退到对整个表施加共享锁。这种方式的性能肯定不好，它甚至会阻止所有其他事务的写操作，但的确可以保证安全性。

#### **可串行化的快照隔离**

本章已经给大家展示了数据库并发方面很多让人纠结、黯淡的一面。两阶段加锁虽然可以保证串行化，但性能差强人意且无法扩展（由于串行执行）；弱级别隔离虽然性能不错，但容易引发各种边界条件（ 如更新丢失， 写倾斜 ，幻读等）。那么，串行化隔离与性能是不是从根本上就是互相冲突而无法兼得吗？

或许并非如此。最近一种称为可串行化的快照隔离（Serializable Snapshot Isolation,SSI) 算法看起来让人眼前一亮。它提供了完整的可串行性保证，而性能相比于快照隔离损失很小。 SSI算挂面世至今不过数年，它于2008年被首次提出，后来成为Michael Cahill的博士论文研究主题。

目前， SSI可用于单节点数据库（ PostgreSQL 9.1 之后的可串行化隔离）或者分布式数据库（如FoundationDB采用了类似的算位）。相比于其他并发控制机制 ， SSI尚需在实践中证明其性能。即使如此，它很有可能成为未来数据库的标配。

##### **悲观与乐观的并发控制**

两阶段加锁是一种典型的悲观并发控制机制。它基于这样的设计原则 ： 如果某些操作可能出错（例如与其他并发事务发生了锁冲突），那么直接放弃，采用等待方式直到绝对安全。这和多线程编程中互斥锁是一致的。

某种意义上讲，串行执行是种极端悲观的选择 ： 事务执行期间，等价于事务对整个数据库（或数据库的一个分区）持有互斥锁。而我们只能假定事务执行得足够快 、 持锁时间足够短，来稍稍弥补这种悲观色彩。

相比之下，可串行化的快照隔离则是一种乐观并发控制。在这种情况下，如果可能发生潜在冲突，事务会继续执行而不是中止，寄希望一切相安无事：而当事务提交时（只有可串行化的事务被允许提交），数据库会检查是否确实发生了冲突（即违反了隔离性原则），如果是的话，中止事务并接下来重试。

乐观并发控制其实是一个古老的想法，关于其优点和缺点已经争论了很长时间。如果冲突很多，则性能不佳（许多事务试图访问相同的对象），大量的事务必须中止。如果系统已接近其最大吞吐量，反复重试事务会使系统性能变得更差。

但是，如果系统还有足够的性能提升空间，且如果事务之间的竞争不大，乐观并发控制会比悲观方式高效很多。通过可交换的原子操作还可以减少一些竞争情况。例如，如果多个事务同时试图增加某个计数器，那么不管以什么样的顺序去增加（只要同一事务不去读计数器），最后的结果总是等价的 ，并发提交多个增量操作是可行的。

顾名思义， SSI基于快照隔离，也就是说，事务中的所有读取操作都是基于数据库的一致性快照（请参阅本章前面的“快照隔离”和“可重复读”）。这是与早期的乐观并发控制主要区别。在快照隔离的基础上， SSI新增加了相关算法来检测写入之间的串行化冲突从而决定中止哪些事务。

##### **基于过期的条件做决定**

我们在讨论写倾斜（参阅本章前面的“写倾斜与幻读”）时，介绍了这样一种使用场景 ： 事务首先查询某些数据，根据查询的结果来决定采取后续操作，例如修改数据。而在快照隔离情况下，数据可能在查询期间就已经被其他事务修改，导致原事务在提交时决策的依据信息已出现变化。

换句话说，事务是基于某些前提条件而决定采取行动，在事务开始时条件成立，例如“目前有两名医生值班”，而当事务要提交时，数据可能已经发生改变，条件已不再成立。

当应用程序执行查询时（例如“当前有多少医生在值班？”），数据库本身无法预知应用层逻辑如何使用这些查询结果。安全起见，数据库假定对查询结果（决策的前提条件）的任何变化都应使写事务失效。换言之 ， 查询与写事务之间可能存在因果依赖关系。为了提供可串行化的隔离，数据库必须检测事务是否会修改其他事务的查询结果，并在此情况下中止写事务。

数据库如何知道查询结果是否发生了改变呢？可以分以下两种情况 ：

- 读取是否作用于一个（即将）过期的MVCC对象（读取之前已经有未提交的写入）。
- 检查写入是否影响即将完成的读取（读取之后，又有新的写入）。

##### **GPT分析**

在 SSI（可串行化快照隔离）中，系统不是使用传统的锁来防止数据的并发访问，而是使用一种检测机制来确保事务的串行化。这种检测机制涉及到两个关键概念：读集合（read set）和写集合（write set）。

**读集合（Read Set）**

读集合是指事务在执行过程中读取的所有数据项的集合。在 SSI 中，当一个事务开始时，它基于数据库当前的状态获得一个快照，并在此快照上执行所有的读操作。系统会跟踪这个事务读取了哪些数据，这就构成了它的读集合。这个集合的作用是在事务提交时检测是否有其他事务对这些数据进行了修改。如果在当前事务开始后、结束前，读集合中的数据被其他已提交的事务修改了，那么就存在冲突，当前事务可能需要回滚以保持数据的一致性。

**写集合（Write Set）**

写集合是指事务在执行过程中写入或修改的所有数据项的集合。SSI 机制会记录这个事务试图修改的所有数据，这就构成了它的写集合。在事务提交时，系统会检查写集合中的数据自事务开始以来是否被其他事务读取过。如果发现有冲突，即其他事务已经读取了这些数据项，那么当前事务的提交可能会违反串行化原则，因此可能需要回滚。

**冲突检测和处理**

在 SSI 中，事务在提交之前会进行冲突检测。如果系统发现当前事务的读集合或写集合与其他已提交事务的写集合有冲突，那么当前事务不能安全地提交，因为这可能导致不可重复读或幻读问题。

例如，如果事务 A 在读集合中有一条记录，事务 B 在写集合中也有这条记录，并且事务 B 已经提交了，那么事务 A 在提交时会发现冲突，因为它读取的数据已经被修改。同样，如果事务 A 在写集合中有一条记录，事务 B 在读集合中也有这条记录，并且事务 B 已经提交了，那么事务 A 在提交时也会发现冲突。

总之，SSI 中的“锁定机制”实际上是一种逻辑上的冲突检测机制，它记录了事务所读取和修改的数据，并在事务提交时检查这些数据是否与其他事务产生了冲突。这种机制允许更高的并发度，因为事务在执行期间不会直接阻塞其他事务，而是在提交时解决可能的冲突。

看来还是GPT解释得更加通俗易懂啊！！！

##### **检测是否读取了过期的 MVCC对象**

回想一下，快照隔离通常采用多版本并发控制技术（MVCC ，见图7-10）来实现。当事务从MVCC数据库一致性快照读取时，它会忽略那些在创建快照时尚未提交的事务写入。例如图7-10中，事务42(修改Alice的值班状态)未被提交，因此事务43中Alice查询到的on call是true; 当事务43提交时，事务42已经完成了提交。换言之从快照读取时被忽略的写入已经生效，并且直接导致事务43做决定的前提已不再成立。

​    ![0](https://note.youdao.com/yws/res/20912/WEBRESOURCE2a261fc3ebbf4a3d5e9d4a3fa02b6904)

为防止这种异常，数据库需要跟踪那些由于MVCC可见性规则而被忽略的写操作。当事务提交时 ，数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，如果是则必须中止当前事务。

为什么要等到提交： 当检测到读旧值，为何不立即中止事务43呢？可以考虑这些情况， 首先，如果事务 43是个只读事务，没有任何写倾斜风险， 就不需要中止；而事务43读取数据库时，数据库还不知道事务是否稍后有任何写操作。 此外， 事务43提交时，有可能事务42发生了中止或者还处于未提交状态，因此读取的并非是过期值。通过减少不必要的中止， SSI可以高效支持那些需要在一致性快照中运行很长时间的读事务。

##### **检测写是否影晌了之前的读**

第二种要考虑的情况是，在读取数据之后，另一个事务修改了数据。 如图 7-11 所示。

​    ![0](https://note.youdao.com/yws/res/20924/WEBRESOURCE3ae923123a9dc48de4cfe25a19d2a8ba)

在“两阶段加锁”中，我们讨论了索引区间锁（参阅本章前面的“索引区间锁”），它可以锁定与某个查询条件匹配的所有行，例如WHERE shift_id = 1234。这里使用了类似的技术，只有一点差异： SSI锁不会阻塞其他事务。

在图 7-11 中，事务42和事务43都在查询轮班1234期间的值班医生。 如果在 shift_id上建有索引，数据库可以通过索引条目1234来记录事务42和事务43都查询了相同的结果。 如果没有索引，可以在表级别跟踪此信息。该额外记录只需保留很小一段时间，当并发的所有事务都处理完成（提交或中止）之后，就可以丢弃。

当另一个事务尝试修改时，它首先检查索引，从而确定是否最近存在一些读目标数据的其他事务。这个过程类似于在受影响的字段范围上获取写锁，但它并不会阻塞读取，而是直到读事务提交时才进一步通知他们 ： 所读到的数据现在已经发生了变化。

图 7-11 中，事务43和事务42会互相通知对方先前的读已经过期。虽然事务43的修改的确影响了事务42 ，但事务43当时并未提交（修改未生效）， 而事务42首先尝试提交，所以可以成功；随后当事务的试图提交时，来自42的冲突写已经提交生效，事务的不得不中止。

##### **可串行化快照隔离的性能**

有许多工程方面的细节会直接影响算法在实践中的效果。例如， 一个需要权衡考虑的是关于跟踪事务读、写的粒度。如果非常详细地跟踪每个事务的操作，确实可以准确推测有哪些事务受到影响、需要中止，但是记录元数据的开销可能很大；而粗粒度的记录则速度占优，但可能会扩大受影响的事务范围。

有时，读取过期的数据并不会造成太大影响，这完全取决于所处的具体场景。有时可以确信执行的最终结果是可串行化的， PostgreSQL采用这样的信条来减少不必要的中止。

与两阶段加锁相比，可串行化快照隔离的一大优点是事务不需要等待其他事务所持有的锁。这一点和快照隔离一样 ，读写通常不会互相阻塞。这样的设计使得查询延迟更加稳定、可预测。特别是，在一致性快照上执行只读查询不需要任何锁，这对于读密集的负载非常有吸引力。

与串行执行相比，可串行化快照隔离可以突破单个CPU核的限制。 FoundationDB将冲突检测分布在多台机器上，从而提高总体吞吐量。即使数据可能跨多台机器进行分区，事务也可以在多个分区上读、写数据并保证可串行化隔离。

需要指出，事务中止的比例会显著影响 SSI的性能表现。例如，一个运行很长时间的事务，读取和写入了大量数据，因而产生冲突并中止的概率就会增大，所以SSI要求读－写型事务要简短（而长时间执行的只读事务则没有此限制）。但总体讲，相比于两阶段加锁与串行执行， SSI更能容忍那些执行缓慢的事务。

### **小结**

事务作为一个抽象层，使得应用程序可以忽略数据库内部一些复杂的并发问题，以及某些硬件、软件故障，从而简化应用层的处理逻辑，大量的错误可以转化为简单的事务中止和应用层重试 。

本章，我们例举了很多事务能够预防的问题。尽管并非所有的应用程序都会面临这些问题，例如那些简单的访问模式，只读或者只写，可能根本无需事务的帮助。但对于复杂的访问模式， 事务可以大大简化需要考虑的潜在错误情况。

如果没有事务，各种错误情况（如进程崩溃、网络中断、停电、磁盘已满、并发竞争等）会导致数据可能出现各种不一致。 例如，反规格化数据模式和相关操作会导致与源数据不同步。假如没有事务，处理那些复杂交互访问最后所导致的数据库混乱就会异常痛苦。

本章，我们深入探讨了并发控制这一主题。介绍了多个广泛使用的隔离级别，特别是读－提交，快照隔离（或可重复读取）与可串行化。通过分析如何处理边界条件来阐述这些隔离级别的要点：

脏读

客户端读到了其他客户端尚未提交的写入。读－提交以及更强的隔离级别可以防止脏读 。

脏写

客户端覆盖了另一个客户端尚未提交的写入。几乎所有的数据库实现都可以防止脏写。

读倾斜（不可重复读）

客户在不同的时间点看到了不同值。快照隔离是最有用的防范手段， 即事务总是在某个时间点的一致性快照中读取数据。通常采用多版本并发控制（ MVCC ）来实现快照隔离。

更新丢失

两个客户端同时执行读－修改－写入操作序列，出现了其中一个覆盖了另一个的写入，但又没有包含对方最新值的情况，最终导致了部分修改数据发生了丢失。快照隔离的一些实现可以自动防止这种异常，而另一些则需要手动锁定查询结果( SELECT FOR UPDATE ）。

写倾斜

事务首先查询数据，根据返回的结果而作出某些决定，然后修改数据库。当事务提交时，支持决定的前提条件已不再成立。只有可串行化的隔离才能防止这种异常。

幻读

事务读取了某些符合查询条件的对象，同时另一个客户端执行写入，改变了先前的查询结果。快照隔离可以防止简单的幻读，但写倾斜情况则需要特殊处理，例如采用区间范围锁。

弱隔离级别可以防止上面的某些异常，但还需要应用开发人员手动处理其他复杂情况（例如，显式加锁） 。只有可串行化的隔离可以防止所有这些问题。我们主要讨论了实现可串行化隔离的三种不同方式：

严格串行执行事务

如果每个事务的执行速度非常快，且单个CPU核可以满足事务的吞吐量要求，严格串行执行是一个非常简单有效的方案。

两阶段加锁

几十年来，这一直是实现可串行化的标准方式，但还是有很多系统出于性能原因而放弃使用它。

可串行化的快照隔离(SSI)

一种最新的算出， 可以避免前面方法的大部分缺点 。它秉持乐观预期的原则，允许多个事务并发执行而不互相阻塞；仅当事务尝试提交肘，才检查可能的冲突，如果发现违背了串行化，则某些事务会被中止。

本章中的示例都采用关系数据模型。但是 ，正如本章前面的“多对象事务的需求”所描述的，无论对哪种数据模型， 事务都是非常有用的数据库功能。本章所介绍的算法、方案主要针对单节点。对于分布式数据库，还会面临更多、更复杂的挑战，我们将在接下来的两章中继续展开讨论 。

## **第8章 分布式系统的挑战**

前面几章反复出现的主题是系统出错之后该如何处理。例如，我们已经讨论了多副本切换（第5章的“处理节点失效”），复制滞后（第5章的“复制滞后问题”）以及事务的并发控制（第7章的“弱隔离级别”）等。只有更充分地了解实际系统可能出现的各种临界条件，我们才能更好地处理它们。

虽然长篇累牍谈了很多，但是这几章所剖析的错误情况还是过于乐观，现实则更加复杂。现在我们将这种复杂性推向极致，并做一个非常悲观的假定：所有可能出错的事情一定会出错。实际上，有经验的系统管理员会告诉你这其实是一个非常合理的假定，他们可能都遭遇过一些可怕甚至惨痛的教训。

关键在于，分布式系统与在单节点上的软件有着非常显著的区别，你会碰到五花八门、千奇百怪的问题所导致的各种故障。本章我们将了解这些实践中所出现的问题，探明哪些称得上可靠而哪些是不可靠。

作为开发者，我们的核心任务是构建可靠的系统 ， 即使系统面临各种出错可能，也需要完成预定工作（确保满足用户期望）。在下一章，我们将介绍分布式环境下可以提供这类保证的常用算法和具体例子 。 但首先，本章的主要任务还是充分认识眼前的挑战。

本章对分布式系统可能出现的故障做了一个全面、近乎悲观的总结。故障可能来自网络问题（详见本章后面的“不可靠的网络”），以及时钟与时序问题（详见本章后面的“不可靠的时钟”）等，并讨论这些问题的可控程度。坦白讲，这些问题一直在困扰着人们，因此我们将探讨如何认清分布式系统的状态本质，并据此来评估所发生的各种故障（详见本章后面的“知识，真相与谎言”） 。

### **故障与部分失效**

在单节点上开发程序时，通常它应该以一种确定性的方式运行：要么工作，要么出错。有bug的软件可能最终会在某天暴露出来（而问题通常可以由重启机器来解决），但问题的主要原因可能还是软件本身的bug。

单台节点上的软件通常不应该出现模棱两可的现象：当硬件正常工作时，相同的操作通常总会产生相同的结果（即确定性）：而如果硬件存在问题（例如，内存损坏或接口松动），结果往往是系统性故障，如内核崩溃，蓝屏死机，启动失败等。因此在单节点上一个质量合格的软件状态要么是功能正常，要么是完全失效，而不会介于两者之间。

这背后涉及计算机设计一个非常审慎的选择：如果发生了某种内部错误，我们宁愿使计算机全部崩溃，而不是返回一个错误的结果，错误的结果往往更难处理。因此，计算机隐藏了一切模糊的物理世界，呈现以一个理想化的系统模型，像以数学完美的方式运行。 CPU指令通常以确定性方式操作，如果写入一些数据到内存或磁盘，那么这些数据将保持不变且不会被随机破坏。这种确定－正确性的设计目标可以一直追溯到第一台数字计算机。

然而当涉及多台节点时，情况发生了根本性变化。对于这种分布式系统，理想化的标准正确模型不再适用，我们必须面对一个可能说非常乱的现实。

在分布式系统中，可能会出现系统的一部分工作正常，但其他某些部分出现难以预测的故障，我们称之为“部分失效”。问题的难点就在于这种部分失效是不确定的：如果涉及多个节点和网络 ，几乎肯定会碰到有时网络正常，有时则莫名的失败。正如接下来马上要看到的，通过网络发送消息的延迟非常不确定，有时甚至根本不知道执行是否成功。

正是由于这种不确定性和部分失效大大提高了分布式系统的复杂性。

#### **云计算和超算**

关于如何构建大规模计算系统有以下几种不同的思路：

- 规模的一个极端是高性能计算（ high-performance computing, HPC ）。包含成千上万个CPU的超级计算机构成一个庞大的集群，通常用于计算密集型的科学计算任务，如天气预报或分子动力学（模拟原子和分子的运动）。
- 另一个极端是云计算。虽然云计算的定义并非那么明确，但通常它具有以下特征 ： 多租户数据中心， 通用计算机，用 IP以太网链接，弹性／按需资惊分配，并按需计费。
- 传统企业数据中心则位于以上两个极端之间。

不同的集群构建方式所对应的错误处理方法也不尽相同。对于高性能计算，通常会定期对任务状态进行快照，然后保存在持久存储上，当某节点出现故障，解决方案是简单地停止整个集群的任务；等故障节点修复之后，从最近的快照检查点继续执行。从这一点上看，高性能计算其实更像是一个单节点系统而不是分布式系统，它将局部失效升级为整体失效，例如系统的任何部分发生了故障，就干脆让系统停下来，这和单机上内核崩溃类似。

本书的重点是基于互联网的服务系统，这些系统与上述高性能计算有很多不同之处：

- 许多互联网服务都是在线的，需要随时（ 如7 × 24h ）为用户提供低延迟服务。任何服务不可用情况，如停下集群来修复故障，都是不可取的。相比之下， 像天气模拟这样的离线（批处理）作业则可以暂停然后重启，影响相对较小。
- 高性能计算通常采用专用硬件，每个节点的可靠性很高，节点间主要通过共享内存或者远程内存直接访问（ RDMA ）等技术进行通信。而云计算中的节点多是由通用机器构建，出于大规模部署时经济因素的考虑，单节点的成本低廉主要而依靠较高的集群聚合性能，但另一方面也具有较高的故障率。
- 大型数据中心网络通常基于IP和以太网，采用 Clos拓扑结构提供等分带宽。高性能计算则通常特定的网络拓扑结构，例如多维网格和toruses ，它们可以为HPC特定工作负载提供了更好的性能。
- 系统越大，其中局部组件失效的概率就越大。在长时间运行期间，失效，修复，再失效可以看成一个反复的过程。在一个包含成千上万个节点的系统中，我们几乎总是可以假定某些东西发生了失效。此时，如果采用的是简单的停止－修复错误处理策略，对于这样一个庞大的集群系统，最终将花费大量时间在错误恢复上而不是正常的任务执行。
- 如果系统可以容忍某些失败的节点，而使整体继续工作，则对系统运维帮助极大。例如，支持滚动升级（参阅第4章）：每次重启一个节点，而集群总体对外不中断服务。在云环境中，如果发现某台虚拟机有问题，可以将其关闭然后重新启动另一个。
- 对于全球分散部署的多数据中心（使用户访问地理靠近的数据中心，从而降低延迟），通信很可能经由广域网，与本地网络相比，速度更慢且更加不可靠。而高性能计算通常假设所有节点位置靠近、紧密连接。

要使分布式系统可靠工作，就必然面临部分失效，这就需要依靠软件系统来提供容错机制。换句话说，我们需要在不可靠的组件之上构建可靠的系统。另外，正如在第 1 章“可靠性”所讨论的，世界上不存在完美的可靠性，我们需要的现实可行的保证。

即使对于只有几个节点的小型系统，也很有必要审视部分失效问题。在一个小系统中，很可能大部分组件在大部分时间都正常工作，但迟早某一天有一部分系统会出现故障，此时软件必须可以有效处理。这里要强调的是，故障处理是软件设计的重要组成部分。作为系统运维者，需要知道在发生故障时，系统的预期行为是什么。

不能假定故障不可能发生而总是期待理想情况。最好仔细考虑各种可能的出错情况，包括那些小概率故障，然后尝试人为构造这种测试场景来充分检测系统行为。可以说，在分布式系统中，怀疑，悲观和偏执狂才能生存。

### **不可靠的网络**

正如第二部分所介绍的，本书关注的主要是分布式无共享系统，即通过网络连接的多个节点。网络是跨节点通信的唯一途径，我们还假定每台机器都有自己的内存和磁盘，一台机器不能直接访问另一台机器的内存或磁盘除非通过网络向对方发出请求。

首先要说明，无共享并不是构建集群系统的唯一方式 ，但它却是构建互联网服务的主流方式。主要是由于以下几个原因：由于不需要专门的硬件因此成本相对低廉，可以采用通用的商品化硬件，可以采用跨区域的多数据中心来实现高可靠性。

互联网以及大多数数据中心的内部网络（通常是以太网）都是异步网络。在这种网络中， 一个节点可以发送消息（数据包）到另一个节点，但是网络并不保证它什么时候到达，甚至它是否一定到达。发送之后等待响应过程中，有很多事情可能会出错（见图 8- 1 所示的例子）：

1. 请求可能已经丢失（ 比如有人拔掉了网线）。
2. 请求可能正在某个队列中等待，无法马上发送（ 也许网络或接收方已经超负荷）。
3. 远程接收节点可能已经失效（例如崩溃或关机）。
4. 远程接收节点可能暂时无告响应（例如正在运行长时间的垃圾回收，请参阅本章后面的“进程暂停”）。
5. 远程接收节点已经完成了请求处理，但回复却在网络中丢失（例如网络交换机配置错误）。
6. 远程接收节点已经完成了请求处理，但回复却被延迟处理（例如网络或者发送者的机器超出负荷）。

​    ![0](https://note.youdao.com/yws/res/21113/WEBRESOURCEc1cfffe9cb42c93a3fae656650869b2f)

发送者甚至不清楚数据包是否完成了发送，只能选择让接收者来回复响应消息，但回复也有可能丢失或延迟。这些问题在一个异步网络中无法明确区分，发送者拥有的唯一信息是，尚未收到响应 ，但却无法判定具体原因。

处理这个问题通常采用超时机制：在等待一段时间之后，如果仍然没有收到回复则选择放弃，并且认为响应不会到达。但是， 即使判定超时， 仍然并不清楚远程节点是否收到了请求（一种情况，请求仍然在某个地方排队，即使发送者放弃了 ，但最终请求会发送到接收者）。

#### **现实中的网络故障**

我们已经有几十年的计算机网络构建经验，人们也许想当然地会认为现在已经掌握了足够的技能使网络变得非常可靠。但是，情况似乎并非如此。

一些系统研究和大量的侧面证据表明，网络问题出人意料地普遍， 包括那些由公司运营的数据中心。一家中型数据中心完成的调查发现，每月大约有12次网络故障，其中有一半涉及单台机器，有一半甚至是整个机架断网。另一项研究分析了机架式交换机 ， 汇聚层交换机和负载均衡器等组件的故障率，结果发现增加冗余网络设备并不会像期望的那样可以显著减少故障，主要是因为无法有效防范人为错误（例如配置错误），而后者是造成网络中断的主要原因。

公共云服务如AWS 因多次出现临时性网络故障而影响颇大，管理良好的私有数据中心网络或许更为稳定一些。尽管如此，所有人都曾遭受网络问题的困扰：例如，交换机软件升级可能会触发网络拓扑重新配置，在此期间数据包的延迟显著增加，甚至超过了一分钟；有报道发现鲨鱼咬破了海底电缆。其他令人惊讶的故障还包括网络接口会丢弃所有入向数据包，但可以成功发送出向数据包，原因仍然在于网络接口配置问题。

即使网络故障在你的环境中比较少见，但故障可能发生也要求软件需要能够处理它们 。事实上，只要有网络通信，就可能会出现故障，这一点始终无法彻底避免。

如果没有处理或者测试网络故障，可能会发生意想不到的后果。例如，集群可能会死锁，即使网络恢复了也无法提供服务，甚至可能误删除数据。如果触发了一些软件未定义的情形，则发生任何意外都不奇怪。

处理网络故障并不意味着总是需要复杂的容错措施 ： 假定你的网络通常非常可靠，而万一出现问题， 一种简单的方法是对用户提示错误信息。但前提是 ，必须非常清楚接下来软件会如何应对，以确保系统最终可以恢复。我们推荐有计划地人为触发网络问题，目的是测试系统的反应情况（这也是Chaos Monkey系统背后的想法，请参阅第1章 “可靠性”）。

#### **检测故障**

许多系统都需要自动检测节点失效这样的功能。例如：

- 负载均衡器需要避免向已失效的节点继续分发请求（即将其下线处理）。
- 对于主从复制的分布式数据库，如果主节点失败，需要将某个从节点提升为主节点（参阅第5章“处理节点失效”）。不过，由于网络的不确定性很难准确判断节点是否确实失效。
- 然而不幸的是，由于网络的不确定性使得判断节点是否失效非常困难；而只有在某些特定场景下，或许你可以明确知道哪里出错了。
- 假设可以登录节点，但发现服务进程没有侦听目标端口（例如，由于进程已经崩溃），那么操作系统会返回 RST或FIN标志的数据包来辅助关闭或拒绝TCP连接。但是，如果节点在处理请求的过程中发生了崩溃， 则很难知道该节点实际处理了多少数据。
- 如果服务进程崩溃（或被管理员杀死），但操作系统仍正常运行，可以通过脚本通知其他节点，以便新节点来快速接管而跳过等待超时。 HBase采用了这样的方法。
- 如果有权访问数据中心网络交换机， 则可以通过管理接口查询是否存在硬件级别的链路故障（例如远程节点掉电）。不过，该方法也有局限性，例如通过互联网连接，或者是处于共享数据中心而没有访问交换机的权限，以及由于网络问题而根本无法登录管理界面等。
- 如果路由器已经确认目标节点不可访问，则会返回 ICMP “目标不可达”数据包来回复请求。但是，路由器本身并不具有什么神奇的检测能力，从这一点来讲，它和网络上其他节点并无本质区别。

能快速告之远程节点的关闭状态自然有用，但也不是万能的。例如，即使TCP确认一个数据包已经发送到目标节点，但应用程序也可能在处理完成之前发生崩溃。如果你想知道一个请求是否执行成功，就需要应用级别的回复。

总之，如果出现了问题，你可能会在应用堆栈的某个级别拿到了一个关于错误的回复 ，但最好假定最终收不到任何错误报告。接下来尝试重试（TCP重试是透明的，但也可以在应用级别重试），等待超时之后，如果还是没有收到响应，则最终声明节点已经失效。

#### **超时与无限期的延迟**

如果超时是故障检测唯一可行的方位， 那么超时应该设多长呢？不幸的是没有标准的答案。

设置较长的超时值意味着更长时间的等待，才能宣告节点失效（在此期间，用户只能等待或者拿到错误信息）。较短的超时设置可以帮助快速检测故障，但可能会出现误判，例如实际上节点只是出现暂时的性能波动（由于节点或网络上的高负载峰值），结果却被错误地宣布为失效。

如果节点实际上是活着 （例如 ，正在发送一封电子邮件）， 过早地将其声明为失效会带来一些问题，新节点会尝试接管，然后出现一些操作在两个节点上执行两次 。 我们将在后面详细讨论这个问题。

当一个节点被宣告为失效，其承担的职责要交给到其他节点，这个过程会给其他节点以及网络带来额外负担，特别是如果此时系统已经处于高负荷状态 。 例如节点只是负载过高而出现了响应缓慢，转移负载到其他节点可能会导致失效扩散，产生级联扩大效应，在极端情况下，所有节点都宣告对方死亡，造成服务处于事实停止状态。

设想一个虚拟的系统，其网络可以保证数据包的最大延迟在一定范围内：要么在时间d内完成交付，要么丢失 。 此外 ，假定一个非故障节点总能够在一段时间 r 内完成请求处理 。 此时，可以确定成功的请求总能够在2d+r时间内收到响应，如果在此时间内没有收到响应，则可以推断网络或者远程节点发生了失效，那么 2d+r 是一个理想的超时设置。

然而事实上绝大多数系统都没有类似的保证 ： 异步网络理论上的延迟无限大（即使尽力发送数据包，但数据包到达时间并没有上确界）， 多数服务端也无法保证在给定的某个时间内一定完成请求处理（参阅本章后面的“响应时间保证”）。如果超时设置太小，只需要一个短暂的网络延迟尖峰就会导致包超时进而将系统标记为失效。

##### **网络拥塞与排队**

驾车时往往由于交通堵塞，导致行车时间变化很大。同样，计算机网络上数据包延的变化根源往往在于排队:

- 当多个不同节点同时发送数据包到相同的目标节点时，网络交换机会出现排队，然后依次将数据包转发到目标网络（见图 8-2 ）。如果网络负载过重 ， 数据包可能必须等待一段时间才能获得发送机会（即网络拥塞）。如果数据量太大，交换机队列塞满，之后的数据包则会被丢弃，网络还在运转，但会引发大量数据包重传。
- 当数据包到达目标机器后，如果所有CPU核都处于繁忙状态， 则网络数据包请求会被操作系统排队， 直到应用程序能够处理。根据机器的配置和负载情况，这里也会引人一段不确定的等待时间。
- 在虚拟化环境下， CPU核会切换虚拟机，从而导致正在运行的操作系统会突然暂停几十毫秒。在这段时间，客户虚机无法从网络中接收任何数据，入向的包会被虚拟机管理器排队缓冲，进一步增加 了网络延迟的不确定性。
- TCP执行流量控制时，节点会主动限制自己的发送速率以避免加重网络链路或接收节点负载。这意味着数据甚至在进入网络之前，已经在发送方开始了排队。

​    ![0](https://note.youdao.com/yws/res/21245/WEBRESOURCE5fbad6211500ec6c5061569e11400dad)

而且， 对于TCP如果在某个超时范围内（根据往返时间来推算）没有收到确认，则认为数据包已经丢失进而触发自动重传。虽然这一过程对应用程序透明，但肯定会引人额外的延迟（等待超时到期，等待重传的数据包得到确认）。

所有以上因素都会造成网络延迟的变化或者不确定性。当系统还有足够的处理能力，排队之后可以快速处理；但当系统接近其最大设计上限时，系统负载过高，队列深度就会显著加大，排队对延迟的影响变得特别明显。

在公有云和多租户数据中心中，许多客户共享网络资源包括交换机、机器的网卡以及CPU （如虚拟机）等 。 批处理工作负载例如MapReduce（参阅第10章）很容易使网络带宽达到饱和。通常用户无能控制或者没有权限观测其他用户对共享资源的使用情况，如果不巧旁边有个疯狂的邻居（如虚拟机）正在大量使用资源，网络延迟就会被动很大。

在这种环境下，只能通过实验方式一步步设置超时 。先在多台机器上，多次测量网络往返时间，以确定延迟的大概范围；然后结合应用特点，在故障检测与过早超时风险之间选择一个合适的中间值。

更好的做法是，超时设置并不是一个不变的常量，而是持续测量响应时间及其变化（抖动），然后根据最新的响应时间分布来自动调整。可以用Phi Accrual故障检测器完成，该检测器目前已在 Akka和Cassandra中使用。 TCP的重传超时也采用了类似的机制。

#### **同步与异步网络**

如果网络层可以在规定的延迟内保证完成数据包的发送，且不会丢弃数据包，那么分布式系统就会简单很多。为什么我们不能考虑在硬件层解决这个问题呢？使网络足够可靠，然后软件就无需如此担心。

为了回答这个问题，可以将数据中心网络与传统的固定电话网络（非移动蜂窝，非VoIP ）进行对比分析，首先后者非常可靠：语音延迟和掉话现象极为罕见。这样的固定电话网络需要有持续端到端的低延迟和足够的带宽来传输音频数据。 计算机网络能否实现类似的高可靠性和确定性呢？

当通过电话网络拨打电话时，系统会动态建立一条电路 ： 在整个线路上为呼叫分配一个固定的、带宽有保证通信链路，该电路一直维持到通话结束。 例如， ISDN网络固定以每秒4000帧的速率运行。当新的呼叫建立后，在每个帧（每个方向）内分配16bit的空间，在通话期间，每一方都可以保证在250µs内完成发送一条16bit的音频数据。

这种网络本质是同步的 ： 即使数据中间经过了多个路由器， 16bit空间在电路建立时已经在网络中得到预留，不会受到排队的影响。由于没有排队，网络最大的端到端延迟是固定的。我们称之为有界延迟。

##### **网络延迟是否可预测**

请注意，固定电话网络中的电路与TCP连接存在很大不同 ： 电路方式总是预留固定带宽，在电路建立之后其他人无法使用；而TCP连接的数据包则会尝试使用所有可用的网络带宽。 TCP可以传送任意大小可变的数据块（例如电子邮件或网页），它会尽力在最短的时间内完成数据发送。而当 TCP连接空闲时，通常不占用任何带宽出。

假设数据中心网络和互联网基于电路交换网络， 一旦电路建立完成则可以保证最大往返时间。然而，事实是以太网和IP都是基于分组交换协议，这种协议注定受到排队的影响，从而导致网络延迟不确定，在这些协议里完全没有电路的概念。

那为什么数据中心网络和互联网采用分组交换呢？答案是，它们针对突发流量进行了很多优化。电路非常适合音频或视频通话，通话期间只需每秒传送固定数量的数据。但对于访问网页，发送电子邮件或传输文件等无法事先确定带宽需求，我们只是希望它尽快完成。

如果你想通过电路链接来传输文件，将不得不预估一个待分配的带宽。 如果预估值太低，传输速度就特别缓慢，甚至无法实际可用；如果预估带宽太高，电路甚至无法完成建立（因为如果无法预留所需的带宽，电路就无法建立）。所以，对于突发数据的传输，电路网络无法充分利用网络容量，导致发送缓慢。相比之下， TCP动态调整传输速率则可以充分利用所有可用的网络容量。

曾经也有一些尝试建立支持电路交换和分组交换的混合网络，比如 ATM。lnfiniBand 网络有一些相似之处：它在链路层实现端到端的流量控制，从而减少了网络中的排队，但仍可能会由于链路拥塞而影响延迟；然后通过服务质量（ QoS,数据包的优先级和调度）和准入控制（限制发送速率），最终可以在分组网络上模拟电路交换，或者说提供统计意义上的有限延迟。

但是，目前此类QoS在多租户数据中心、公有云和广域网中并未启用。总之，当前广泛部署的技术无法为我们提供延迟或可靠性方面的硬件级保证，我们必须假设会出现网络拥塞，排队和无上限的延迟。基于此，超时设置并不存在某个绝对正确的值，而是需要通过实验的方式来确定 。

### **不可靠的时钟**

时钟和计时非常重要。有许多应用程序以各种方式依赖于时钟，例如 ：

1. 某个请求是否超时了？
2. 某项服务的 99%的响应时间是多少？
3. 在过去的五分钟内 ，服务平均每秒处理多少个查询？
4. 用户在我们的网站上浏览花了多段时间？
5. 这篇文章什么时候发表？
6. 在什么时间发送提醒邮件？
7. 这个缓存条目何时过期？
8. 日志文件中错误消息的时间戳是多少？

上述 1～4测量的持续时间（例如请求发送与响应接收之间的时间间隔），而5~8所描述的某个时间点（在特定日期，特定时间发生的事件）。

在分布式系统中， 时间总是件棘手的问题，由于跨节点通信不可能即时完成，消息经由网络从一台机器到另一台机器总是需要花费时间。收到消息的时间应该晚于发送的时间，但是由于网络的不确定延迟，精确测量面临着很多挑战。这些情况使得多节点通信时很难确定事情发生的先后顺序。

而且，网络上的每台机器都有自己的时钟硬件设备，通常是石英晶体振荡器 。这些设备并非绝对准确，即每台机器都维护自己本地的时间版本，可能比其他机器稍快或更慢。可以在一定程度上同步机器之间的时钟，最常用的方也是网络时间协议（Network Time Protocol , NTP ），它可以根据一组专门的时间服务器来调整本地时间，时间服务器则从精确更高的时间源（如GPS接收机） 获取高精度时间 。

#### **单调时钟与墙上时钟**

现代计算机内部至少有两种不同的时钟 ： 一个是墙上时钟 （或称钟表时间）， 一个是单调时钟。虽然它们都可以衡量时间，但要仔细区分二者，本质上他们是服务于不同的目的 。

##### **墙上时钟**

墙上时钟根据某个日历（也称为墙上时间）返回当前的日期与时间。例如， Linux的clock_gettime ( CLOCK_REALTIME ）和Java中的System .currentTimeMillis() 会返回自纪元 1970年 1 月 1 日（ UTC ）以来的秒数和毫秒数，不含闰秒。而有些系统则使用其他日期作为参考点。

墙上时钟可以与NTP同步。但是，如下一节所述，这里还存在一些奇怪问题。特别是，如果本地时钟远远快于NTP服务器，强行重置之后会跳回到先前的某个时间点。这种跳跃以及经常忽略闰秒 ，导致其不太适合测量时间间隔。

曾经墙上时钟粗糙的精度也被人诟病，例如在较早的Windows系统上只能提供10毫秒的精度。不过在较新的系统上，精度已经不成问题。

##### **单调时钟**

单调时钟更适合测量持续时间段 (时间间隔)，例如超时或服务的响应时间: Linux上的clock_gettime (CLOCK_MONOTONIC) 和Java中的System.nanoTime() 返回的即是单调时钟。单调时钟的名字来源于它们保证总是向前 (而不会出现墙上时钟的回拨)。

可以在一个时间点读取单调时钟的值，完成某项工作，然后再次检查时钟。时钟值之间的差值即两次检查之间的时间间隔。注意，单调时钟的绝对值并没有任何意义，它可能是电脑启动以后经历的纳秒数或者其他含义。因此比较不同节点上的单调时钟值毫无意义，它们没有任何相同的基准。

如果服务器有多路CPU ，则每个CPU可能有单独的计时器，且不与其他CPU进行同步。由于应用程序的线程可能会调度到不同的CPU上，此时，操作系统会补偿多个计时器之间的偏差， 从而为应用层提供统一的单调递增计时。不过最好还是对这种偏差补偿持谨慎态度。

如果NTP检测到本地石英比时间服务器上更快或者更慢， NTP会调整本地石英的震动频率（这被称为摆动）。默认情况下， NTP允许速率加快或减慢的最大幅度为0.05% ，但NTP并不会直接调整单调时钟向前或者回拨。单调时钟的精度通常很高，在如今大多数系统中，可以测量几微秒或更短的时间间隔 。

##### **GPT解释**

在计算机科学和时间管理中，"墙上时钟"（Wall Clock Time）和"单调时钟"（Monotonic Clock）是两种常用的时间度量概念，它们在不同的上下文和用途中各有特点。

1. 墙上时钟（Wall Clock Time）：

- - 墙上时钟指的是实际的日历时间，也就是我们日常生活中看到的时间，如2021年10月1日下午3点。
  - 在计算机中，它通常是系统时间，可以由用户或网络时间协议（如NTP）调整。
  - 墙上时钟易受到时区变化、夏令时调整或手动设置的影响。
  - 在编程中，墙上时钟常用于日志记录、事件发生的时间戳记以及任何需要反映实际日期和时间的场景。

1. 单调时钟（Monotonic Clock）：

- - 单调时钟是一种始终向前移动的时钟，它不受系统时间调整的影响，主要用于测量时间间隔。
  - 它的初始点是不确定的，不代表任何实际日期时间，通常是系统启动后的某个点。
  - 单调时钟对于计算超时、性能度量、事件间隔等非常有用，因为它不会因为系统时间更改而出现跳跃或回退。
  - 在编程中，单调时钟常用于需要高精度、稳定性的时间间隔测量。

举个例子，如果你在编写一个程序来监控任务执行的时间，使用单调时钟更为合适，因为即使用户更改了系统时间，也不会影响到你的测量结果。而如果你的程序需要记录事件发生的具体日期和时间，那么使用墙上时钟是更佳的选择。

在大多数现代操作系统中，都提供了获取墙上时钟和单调时钟的方法。例如，在Linux系统中，date 命令或 time 函数可以用来获取墙上时钟时间，而 clock_gettime() 函数配合 CLOCK_MONOTONIC 标志则用来获取单调时钟时间。在编程时，应根据实际需求选择适合的时钟类型。

#### **时钟同步与准确性**

单调时钟不需要同步，但是墙上时钟需要根据NTP服务器或其他外部时间源做必要的调整 。然而，我们获取时钟的方法并非预想那样可靠或准确，硬件时钟和NTP可能会出现一些莫名其妙的现象。举几个例子 ：

- 计算机中的石英钟不够精确，存在漂移现象（运行速度会加快或减慢）。时钟漂移主要取决于机器的温度。谷歌假设其服务器的时钟偏移为200 ppm （百万分之一 ），相当于如果每 30秒与服务器重新同步一次，则可能出现的最大偏差为6毫秒，或者每天一次同步，则最大偏差为 17秒 。 即使其他一切工作正常，漂移问题也限制了可以达到的最佳精度 。
- 如果时钟与NTP服务器的时钟差别太大，可能会出现拒绝同步，或者本地时钟将被强制重置。在重置前后应用程序观察可能会看到时间突然倒退或突然跳跃的现象。
- 由于某些原因，如果与NTP服务器链接失败（如防火墙），可能会很长一段时间没有留意到错误配置最终导致同步失败。有证据表明，实践中确实发生这类问题。
- NTP同步会受限于当时的网络环境特别是延迟，如果网络拥塞、数据包延迟变化不定， 则NTP 同步的准确性会受影响。实验表明，当通过互联网进行同步时，可能会产生至少35毫秒的偏差，最坏时（如网络抖动出现包发送失败）则可能超过 1秒。取决于具体的参数配置情况，如果网络延迟特别严重，则NTP客户端可能会被迫放弃同步 。
- 一些NTP服务器本身出现故障、或者配置错误 ，其报告的时间可能存在数小时的偏差。 NTP客户端往往比较稳定，可以同时查询多个服务器并忽略掉异常值。尽管如此，相信互联网上一个陌生的服务器告诉你的时间，还是值得警惕。
- 闰秒会产生一分钟为59秒或61秒的现象，这会在使一些对闰秒毫无防范的系统出现混乱。闰秒曾经使许多大型系统崩溃，过去的教训表明，不经意之间许多系统已经埋下了对时钟不正确处理的隐患。而处理闰秒的推荐方式是，不管NTP服务器具体如何实现 ，在NTP服务器汇报时间时故意做些调整 ，目的是在一天的周期内逐步调整闰秒 （称为拖尾 ） 。
- 在虚拟机中，由于硬件时钟也是被虚拟化的，这对于需要精确计时的应用程序提出了额外的挑战。当虚拟机共享一个CPU核时，每个虚拟机会出现数十毫秒内的暂停以便切换客户虚机。但从应用的角度来看，这种停顿会表现为时钟突然向前发生了跳跃。
- 如果运行在未完全可控的设备上（例如，移动设备或嵌入式设备），需要留意不能完全相信设备上的硬件时钟。某些用户会故意将其硬件时钟设置为错误的日期和时间，例如为了规避游戏的时间限制。因此，获取的时钟可能是某个过去的、或者将来的时间。

如果确实需要投入大量资源，是可以达到非常高的时钟精度。例如，针对金融机构的欧洲法规草案MiFID II就明确要求所有高频交易基金必须在UTC时间100微秒内同步时钟 ， 以便调试 “崩盘”等市场异常并检测市场操纵等违规行为。

高精度的时钟可以采用 GPS接收机，精确时间协议（PTP）并辅以细致的部署和监测。但通常也意味着大量的资源投入和技术门槛，并持续监控时钟同步可能出现的错误情况。例如NTP守护程序配置错误，防火墙阻止NTP通信等，避免导致时钟误差迅速变大 。

#### **依赖同步的时钟**

时钟虽然看起来简单 ，但却有不少使用上的陷阱： 一天可能不总是86 400秒，时钟会向后回拨，一个节点上的时间可能与另一个节点上的时间完全不同。

本章前面讨论了网络丢包和数据包延迟。对此，我们的建议是，即使网络在大多数情况下表现良好，软件也必须假设网络偶尔会出现故障 ，因此要有对应的措施来妥善处理这些故障。时钟也是如此：尽管大多数时间工作很好，但仍需以备不测。

假如一台机器的CPU出现了故障或者网络有问题，系统可能根本无法工作，所以很快就会被注意到进而得到修复， 但时钟问题却不那么容易被及时发现 。 如果石英时钟有缺陷，或者NTP客户端配置错误， 最后出现了时间偏差，对大多数功能可能并没太大影响。但对于一些高度依赖于精确时钟的软件，出现的后果可能是隐式的，或许会丢失一小部分数据而不是突然的崩溃。

因此，如果应用需要精确同步的时钟，最好仔细监控所有节点上的时钟偏差。如果某个节点的时钟漂移超出上限， 应将其宣告为失效，并从集群中移除。这样的监控的目的是确保在造成重大影响之前尽早发现并处理问题。

##### **时间戳与事件顺序**

对于一个常见的功能： 跨节点的事件排序，如果它高度依赖时钟计时，就存在一定的技术风险。例如，两个客户端同时写入分布式数据库，谁先到达？哪一个操作是最新的呢？

图 8-3 给出了这样的危险例子，即多主节点复制的分布式数据库高度依赖于墙上时钟。客户端A在节点 1 上写入x = 1 ，写入被复制到节点 3; 客户端B在节点3上增加 x（现在x = 2 ） 。最后 ，这两个写入都被复制到节点2上。在图 8-3 中，写入被复制到其他节点时，会根据源写入节点上的墙上时钟来标记时间戳。在该例子中，时钟同步机制稳定工作，节点 1 和节点3之间的时钟偏差小于 3ms, 这比实践中的多数情况可能都要更好。	

​    ![0](https://note.youdao.com/yws/res/21437/WEBRESOURCEd2fa995438611af619f61e7f48a226e3)

但是，这样的时间戳却不能正确排序事件：写入x = 1 的时间戳为42.004秒， 写入x = 2虽然后续发生，时间戳却是42.003s 。当节点2收到这两个事件时，会根据时间戳错误地判断x =1是最新值，然后决定丢弃x = 2 ，就给就导致客户端B的增量操作丢失。

这种冲突解决策略被称为最后写入获胜（ LWW ），在多主节点以及无主节点复制数据库（如Cassandra和Riak）中广泛使用（参阅第5章“最后写入获胜”） 。 有些实现会在客户端生成时间戳而非服务器端，但无论如何没有改变LWW的根本问题：

- 数据库写入可能会奇怪地丢失：明明后续发生的写操作却没法覆盖另一个较早的值，原因是后者节点的时钟太快了。 这会导致一些数量未知的数据被悄悄地丢弃，并且不会向应用报告任何错误。
- LWW无法区分连续快速发生的连续写操作（图 8-3 中客户端A写入之后才发生了客户端B的增量操作）和并发写入（每个写操作都不依赖于其他写 ） 。需要额外的因果关系跟踪机制（例如版本向量 ）来防止因果冲突（参阅第5章 “检测并发写“）。	
- 由于时钟精度的限制（例如毫秒级），两个节点可能各自独立产生了完全相同的时间戳。为了解决这样的冲突，需要一个额外的仲裁值（可以简单地引入一个大的随机数），但该方法还是无法区分因果关系。

因此，通过保持“最新”值并丢弃其他值来解决冲突看似不错，但要注意， “最新”的定义如果取决于墙上时钟就会引入偏差。即使采用了NTP同步时钟，依然可能会出现在时间戳 100毫秒时（根据发送者的时钟中） 发送了某个数据包，却在时间戳99毫秒（根据接收者的时钟）到达，这看起来好像是数据包还没发送就先到达了。

那么NTP时钟同步能否做到极高的精度从而避免这种错误的顺序问题呢？很难做到。因为除了石英漂移等误差来源之外， NTP同步精度本身要受限于所在的网络延迟。要达到正确的排序， 需要时钟源精度要远远高于被测量的对象 （即网络延迟 ） 。对于排序来讲，基于递增计数器而不是振荡石英晶体的逻辑时钟是更可靠的方式（ 参见第5章“检测并发写” ） 。逻辑时钟并不测量一天的某个时间点或时间间隔，而是事件的相对顺序（事件发生的相对前后关系）。与之对应的，墙上时钟和单调时钟都属于物理时钟。我们会在第9章“顺序保证”中继续讨论顺序问题。

Q：为什么NTP 通常不能实现极高的精度？

------

您的理解是正确的。虽然网络时间协议（NTP）可以为分布式系统中的设备提供时间同步，但是由于多种因素，NTP 通常不能实现极高的精度，尤其是在需要微秒或纳秒级别精度的场景下。

以下是一些限制 NTP 精度的主要因素：

1. 网络延迟：NTP 使用网络请求来同步时钟，这些请求在到达服务器和返回客户端时都会受到网络延迟的影响。由于网络延迟的不确定性和可变性，时间同步的精度受到限制。
2. 石英晶体振荡器的漂移：许多计算机使用石英晶体振荡器作为时钟源，这些振荡器随时间会漂移，从而影响其准确性。
3. NTP 算法限制：尽管 NTP 会尝试计算和校正网络延迟，但它的算法本身存在限制。例如，NTP 通常无法区分单向网络延迟的不对称性。
4. 系统负载：高系统负载可能会影响操作系统处理 NTP 请求的速度和定时，这可能导致时间同步的不精确。
5. NTP 服务器和层级：NTP 服务器通常被组织成不同的层级，客户端可能不会直接与原子钟同步，而是通过层级中的其他服务器。每一级的间接性都可能增加误差。

在大多数情况下，NTP 可以提供毫秒级甚至更好的精度，这对于许多应用来说已经足够。但是，对于金融交易、高频交易、科学实验等需要极高时钟同步精度的场合，可能需要采用更高等级的时间同步技术，比如精确时间协议（PTP，IEEE 1588标准），它能够提供亚微秒级的精度。

总之，虽然NTP 提供了一个实用的时间同步解决方案，但是在并发写操作的场景中，可能还需要其他机制（如逻辑时钟、向量时钟、CRDTs 等）来保证正确的操作顺序和一致性。

##### **时钟的置信区间**

或许墙上时钟会返回微秒甚至纳秒级别的信息，但是这种精度的测量值其实并不可信。如前所述，石英漂移问题可导致偏差高达几毫秒，即使每分钟都与本地网络的NTP服务器进行同步，也无法保证上述精度。如果使用公共互联网上的NTP服务器，最好的精度也只能到几十毫秒，而一旦出现网络拥塞，偏差很容易就超过100毫秒。

因此，我们不应该将时钟读数视为一个精确的时间点，而更应该视为带有置信区间的时间范围。例如，系统可能有95%的置信度认为目前时间介于10.3 ~10.5秒之间。如果我们可完全相信的精度为＋／- 100毫秒，那么时间戳中那些微秒级的读数并无实际意义。

可以根据具体的时间源来推算出时钟误差的上限。如果节点上直接装有GPS接收器或原子时钟，那它的误差范围通常可查询制造商的手册 。如果节点是从服务器获取时间，则不确定性取决于上次服务器同步以来的石英漂移范围，加上NTP服务器的不确定性，再加上与服务器之间的网络往返时间（对于第一次同步，我们假定服务器完全可信）。

可惜大多数系统并不提供这种误差查询接口。例如，当调用clock_gettime()时 ，返回值没有任何误差信息，所以无法确切知道置信区间应该是五毫秒还是五年。

这里有趣的是Google Spanner中的 TrueTime API，它会明确地报告本地时钟的置信区间。当查询当前时间时，你会得到两个值： ［不早于，不晚于］分别代表误差的最大偏差范围。基于上述两个时间戳，可以知道实际时间应在其范围之内。该间隔的范围主要取决于本地石英钟最后与高精时钟源同步后所经历的时间长短。

##### **全局快照的同步时钟**

在第7章“快照隔离与可重复读”中，我们介绍了快照隔离，它广泛用于小数据量、快速读写的事务以及大数据量，长时间运行的只读事务 （例如备份或分析），可以在数据库的某个一致状态上不需加锁、不违背读写隔离性的前提下高效支持只读事务。

常见的快照隔离实现中需要单调递增事务ID 。 如果写入发生在快照之后（即写入具有比快照更大的事务ID），那么该写入对于快照不可见。在单节点数据库上，一个简单的计数器足以生成事务ID 。

但是，当数据库分布在多台机器上（可能跨越多个数据中心）时，由于需要复杂的协调以产生全局的、单调递增的事务 ID （跨所有分区）。 事务 ID要求必须反映因果关系 ： 事务B如果要读取事务A写入的值 ，则B的事务ID必须大于A的事务ID ，否则快照将不一致。考虑到大量、频繁的小数据包，在分布式系统中创建事务ID通常会引入瓶颈。

能否使用同步后的墙上时钟作为事务ID呢？如果我们能够获得足够可靠的同步时钟，自然它可以符合事务ID属性要求：后发生的事务具有更大的时间戳。然而问题还是时钟精度的不确定性 。

​    ![0](https://note.youdao.com/yws/res/21552/WEBRESOURCE10f5f341acb57130f7e561fae437b952)

为了确保事务时间戳反映因果关系， Spanner在提交事务之前故意等待置信区间的长度 。这样做的目的是，确保所有事务要足够晚才发生，避免与先前的事务的置信区间产生重叠。而为了尽量缩短潜在的等待时间， Spanner需要使时钟的误差范围尽可能的小，为此，Google在每个数据中心都部署了一个GPS接收器或原子钟，保证所有时钟同步在约7ms之内完成。

借助时钟同步来处理分布式事务语义是一个非常有趣和活跃的研究领域。 但除了Google以外 ，目前主流数据库中还没有更多的实现。

Q：Spanner基本工作原理？

------

Spanner 是 Google 开发的一个全球分布式数据库，它结合了传统数据库的强一致性特性和NoSQL数据库的水平扩展能力。Spanner 的一大创新之处在于其时间戳机制，该机制确保了跨全球分布式系统的事务遵循因果关系，即使在存在网络延迟和时钟漂移的情况下也能保持一致性和顺序。

在 Spanner 中，每个事务都被分配一个时间戳，这个时间戳不仅表示事务提交的顺序，而且还反映了因果关系。为了实现这一点，Spanner使用了TrueTime API，它提供了一个时间的置信区间（通常是一个从最早可能时间到最晚可能时间的范围）。

**TrueTime 的工作原理如下**：

- TrueTime 依赖于一组API，这些API为当前时间提供了一个有界的置信区间 [earliest, latest]
- 系统会在提交事务之前等待，直到间隔的结束时间晚于任何可能与该事务冲突的其他事务的开始时间。这就意味着它会等待直到事务的时间戳晚于任何因果上相关的事务的时间戳。
- 这个等待过程确保了所有的事务都是按照因果顺序提交的，因此即使是在不同的地理位置，也不会发生两个事务的时间戳互相重叠的情况。

为了让这个置信区间尽可能小，从而减少等待时间并提高系统的性能，Google 在每个数据中心都部署了GPS接收器或原子钟。这些高精度的时钟可以极大地减少时间的不确定性，允许Spanner维持一个非常狭窄的置信区间（约7毫秒），从而提供了几乎与单个数据中心一样的性能，同时又维护了全局数据的一致性。

通过使用TrueTime和高精度时钟同步，Spanner能够在全球范围内提供一个有序、一致的视图，这对于需要强一致性保证的分布式应用是至关重要的。这种方法祛除了传统分布式系统中的许多时间相关的问题，比如操作顺序的歧义性和数据版本控制的复杂性。

Q：详细解释一下工作原理的第二点

------

当然可以，让我们通过一个例子来说明 Spanner 如何使用 TrueTime API 来确保事务时间戳反映因果关系：

假设我们有两个事务，事务 A 和 事务 B。

1. 事务 A：

- - 开始于 TrueTime 时间 TT(A_start) = [t1, t2]，这意味着根据 TrueTime API，事务 A 可能在 t1 到 t2 的任何时间开始。
  - 提交于 TrueTime 时间 TT(A_commit) = [t3, t4]，这意味着事务 A 可能在 t3 到 t4 的任何时间提交。

1. 事务 B：

- - 要开始于 TrueTime 时间 TT(B_start) = [t5, t6]，这意味着根据 TrueTime API，事务 B 可能在 t5 到 t6 的任何时间开始。

现在，假设事务 A 和事务 B 涉及到相同的数据片段，并且在逻辑上，事务 B 必须在事务 A 完成后发生（例如，事务 B 可能是根据事务 A 的结果进一步更新数据）。

在这种情况下，为了确保事务 B 的时间戳正确反映这一因果关系，Spanner 会在提交事务 B 之前等待，直到 TrueTime 的当前时间晚于事务 A 提交时间的最晚可能时间 t4。这意味着，事务 B 的开始时间 TT(B_start) 必须晚于 t4。

简而言之，如果 t5（事务 B 开始时间的最早可能时间）小于或等于 t4（事务 A 提交时间的最晚可能时间），Spanner 将会延迟事务 B 的提交，直到 t5 大于 t4。这个等待过程确保了，按照 TrueTime 的定义，事务 B 不可能在事务 A 提交之前发生。因此，通过这种方式，Spanner 能够确保事务的时间戳正确地体现了因果顺序。

这个过程依赖于 TrueTime 提供的时间区间的精确性，这也是为什么 Google 在每个数据中心部署 GPS 或原子钟来保证时间同步的高精度。通过将时间误差范围控制在极小的范围内（如约7毫秒），Spanner 能够有效地减少事务提交前必须等待的时间，从而优化性能。

#### **进程暂停**

另一个分布式系统中危险使用时钟的例子：假设数据库每个分区只有一个主节点，只有主节点可以接受写入。那么其他节点该如何确信该主节点没有被宣告失效，可以安全地写入呢？

一种思路是主节点从其他节点获得一个租约，类似一个带有超时的锁。某一个时间只有一个节点可以拿到租约，某节点获得租约之后，在租约到期之前，它就是这段时间内的主节点。为了维持主节点的身份，节点必须在到期之前定期去更新租约 。如果节点发生了故障， 则续约失败，这样另一个节点到期之后就可以接管。

典型处理流程如下所示：

​    ![0](https://note.youdao.com/yws/res/21444/WEBRESOURCEfaecbd2b0c176d6465dbec47453e0477)

这代码有什么问题么？首先，它依赖于同步的时钟：租约到期时间由另一台机器所设置（ 例如，另一台机器的当前时间加上30秒得到到期时间），并和本地时钟进行比较。如果时钟之间有超过几秒的差异，这段代码会出现些奇怪的事情。

其次，还有另一个问题：代码假定时间检查点System.currentTimeMillis()与请求处理 process(request)间隔很短，通常代码运行足够快，所以设置10秒的缓冲区来确保在请求处理过程中租约不会过期。

但是，如果程序执行中出现了某些意外的暂停呢？例如，假设线程在 lease.isValid()消耗了整15秒。那么当开始处理请求时，租约已经过期，另一个节点已经接管了主节点。可惜我们无法有效通知线程暂停了这么长时间了，后续代码也不会注意到租约已经到期，除非运行到下一个循环迭代。不过，到那个时候它已经做了一些不安全的请求处理。

那么，一个线程可能会暂停这么长时间么？这是可能的，发生这种情况的原因有很多种 ：

- 许多编程语言（如Java虚拟机）都有垃圾收集器（ GC ），有时运行期间会暂停所有正在运行的线程。这些GC暂停甚至有时会持续数分钟！即使像HotSpotJVM CMS所谓的“并发”垃圾收集器也不能完全与应用代码并行运行，需要时不时地停止活动的线程。通过改变分配模式或调整GC某些参数可以减少一些暂停，但是我们还是要防范最差情况以提供可靠的保证。
- 在虚拟化环境中，可能会暂停虚拟机(暂停所有执行进程并将内存状态保存到磁盘)然后继续 (从内存中加载数据然后继续执行)。暂停可能发生进程运行的任一时刻，并且可能持续很长的时间。该功能通常用于实时迁移，即把虚拟机从一个主机迁移到另一个主机而不需要重启，这种情况下，暂停的长度主要取决于进程写入内存的速率。
- 运行在终端用户设备（如笔记本电脑）时，执行也可能发生暂停 ， 例如用户关闭了笔记本电脑或休眠 。
- 当操作系统执行线程上下文切换时，或者虚拟机管理程序切换到另一个虚机时，正在运行的线程可能会在代码的任意位置被暂停。在虚拟机环境中，这种被其他虚拟机中断的CPU时间称为窃取时间 。如果机器负载很高（ 即等待运行的线程很长），被暂停的线程可能需要一段时间之后才能再次运行。
- 如果应用程序执行同步磁盘操作， 则线程可能暂停并等待磁盘 I/O完成。在许多语言中，即使代码并没有明确执行文件操作，也可能意外引入磁盘 I/O。 例如，Java类加载器在第一次使用类文件时会推迟加载，最终可能发生在执行时的任何时刻。 I/O暂停和GC暂停甚至可能会同时发生，从而进一步恶化情况。如果磁盘其实是个网络文件系统或网络块设备（ 如亚马逊的EBS）, I/O还要受到网络延迟变化的影响。
- 如果操作系统配置了基于磁盘的内存交换分区，内存访问可能触发缺页中断，进而需要从磁盘中加载内存页。 I/O进行时（通常比较慢）线程为暂停。如果内存使用压力很大，还可能迫使更多的页面换出到磁盘 。 极端的情况下，操作系统可能会花费大量时间在页面换入换出上，而实际工作完成很少（所谓的颠簸）。为了避免此类问题，通常在服务器上禁用分页 （ 宁愿杀死一些进程来释放内存而不是反复抖动） 。
- 通过发送 SIGSTOP信号来暂停UNIX进程，例如在shell 中按下Ctrl-Z。这个信号会立即停止进程避免其拿到更多的CPU周期， 直到接下来收到信号SIGCONT之后才从停止的地方继续运行。另外也不排除 SIGSTOP信号是由运维人员不小心意外发送。

所有上述情况都可能随时抢占一个正在运行的线程，然后在之后的某个时间点再恢复线程的执行，而线程自身却对此一无所知。这个问题类似于在一台机器上运行多线程代码且保证线程安全。总之，你不能假定任何有关时间的事情，记住上下文切换和并行性可能随时可以发生。

在单台机器上编写多线程代码时，有不少工具可以帮助实现线程安全 ： 互斥量，信号量 ，原子计数器，无锁数据结构， 阻塞队列等。不幸的是 ， 这些工具无法直接转为分布式系统，因为分布式系统通常不采用共享内存，而是在不可靠的网络上发送消息。

分布式系统中的一个节点必须假定，执行过程中的任何时刻都可能被暂停相当长一段时间，包括运行在某个函数中间 。暂停期间，整个集群的其他部分都在照常运行，甚至会一致将暂停的节点宣告为故障节点。最终，暂停的节点可能会回来继续运行，除非再次检查时钟，否则它对刚刚过去的暂停毫无意识。

##### **响应时间保证**

如上所述 ，在许多编程语言和操作系统中，线程和进程可能会暂停相当长的时间 。如果仔细调教系统，可以做到避免很多这种暂停。某些软件如果在指定时间内无法响应则会导致严重后果，这些运行环境包括：飞机，火箭，机器人，汽车和其他需要对输入传感器快速做出响应的组件等。对于这些系统，软件有一个必须做出响应的上限：如果无法满足，会导致系统级故障，这就是所谓的硬实时系统。

例如，如果车载传感器检测到当前正在经历碰撞，肯定不希望系统由于不合适宜的GC暂停导致无法及时释放安全气囊。提供实时保证需要来自软件栈的多个层面的支持：首先是一个实时操作系统（ real­time operating system, RTOS ），保证进程在给定的间隔内完成CPU时间片的调度分配：其次，库函数也必须考虑最坏的执行时间；然后，动态内存分配很可能要受限或者完全被禁止（如果存在实时垃圾收集器 ，确保GC不能处理太多任务）：最终还是需要大量、充分的测试和验证，以确保满足要求 。

显然，这需要大量额外的工作，也严重限制了可使用的编程语言、库和工具的范围（因为大多数语言和工具库不提供实时保证）。由于这些原因，开发实时系统代价昂贵，通常只用于对安全至关重要的关键性嵌入式设备中。另外， “实时”与“高性能”不一样。实际上，实时系统往往吞吐量较低 ，它须优先考虑并晌应高优先级的请求（参阅本章前面的“延迟与资源利用率”） 。对于大多数服务器端数据处理系统来说，实时性保证并不经济或者不合适。因此，现在这些运行在非实时环境下的系统就得承受如进程暂停、 时钟不稳定等困扰 。

##### **调整垃圾回收的影响**

无需昂贵的实时调度，还有一些其他措施可以减轻进程暂停所导致的负面影响。语言绑定的垃圾回收机制可以跟踪对象的分配情况以及剩余的空闲内存，因而可以在运行时灵活控制垃圾回收。

现在一个较新的想法是把GC暂停视为节点的一个计划内的临时离线，当节点启动垃圾回收时，通知其他节点来接管客户端的请求。此外 ，系统可以提前为前端应用发出预警， 应用会等待当前请求完成 ，但停止向该节点发送新的请求，这样垃圾回收可以在无干扰的情况下更加高效运行。 这个技巧以某种方式对客户端隐藏垃圾回收， 降低负面影响。目前一些对延迟敏感的系统（如金融交易系统）已经采用了该方法。

该方法的一个变种是，只对短期对象（可以快速回收）执行垃圾回收，然后在其变成长期存活对象之前，采取定期重启的策略从而避免对长期存活对象执行全面回收。每次选择一个节点重新启动，在重启之前， 重新平衡节点之间的流量， 思路与滚动升级类似（参阅第4章 ）。

这些措施虽然并不能完全避免垃圾回收导致的进程暂停，但可以有效地减少对应用层的影响。

### **知识，真相与谎言**

本章到目前为止，已经探索了分布式系统与单节点程序的许多不同之处。例如，很少使用共享内存，通过不可靠网络传递消息且延迟不确定，可能遭受部分失效，不可靠的时钟以及进程暂停等。

如果还没有深谙分布式系统之道 ，那么下面些问题看起来有些难以理解 。 网络中的一个节点无法确信信息，只能通过网络收到（或没有收到）的消息来猜测。节点只能通过消息交换来获得其他节点当前的状态（存储了哪些数据，是否正常工作等）。如果远程节点没有响应，由于没能区分网络本身的问题还是节点的问题，就无从知道节点究竟处于什么状态。

进一步深究上述问题，可能会涉及一些哲学相关话题：我们从系统获得的信息哪些是真实的、哪些是假的？如果感知和测量的手段都不可靠 ，那么获得的信息究竟有多大的可信度？软件系统是否应该遵循物理世界的那些通用法则（例如因果关系） 呢？

还好，我们并不是非要搞清楚生命的意义才能回答上面的问题。在分布式系统中，我们可以明确列出对系统行为（系统模型）所做的若干假设，然后以满足这些假设条件为目标来构建实际运行的系统。在给定系统模型下，可以验证算法的正确性。这也意味着即使底层模型仅提供了少数几个保证，也可以在系统软件层面实现可靠的行为保证。

显然这不是一件容易的事情。在本章接下来的部分，我们将进一步探讨分布式系统中知识和真相，目的是帮忙我们审视可以做出哪些合理假设，以及通常可以提供哪些保证 。第9章将介绍具体的例子，例如典型分布式系统和算法在特定条件下提供的哪些特定保证。

#### **真相由多数决定**

假定在一个发生了非对称故障的网络环境中，即某节点能够收到发送给它的消息，但是该节点发出的所有消息要么被丢弃，要么被推迟发送。该节点即使本身运行良好，可以接收来自其他节点的请求，但其他节点却无法顺利收到响应。当消息超时之后，由于都收不到回复，其他节点就会一致声明上述节点发生失效。打个比方，就像这种情况：处于半连接的节点被强行摁倒在车里，即使它满心不情愿，即使在里面不停地哭喊“我没有问题”，可没人听到其呼救声，其他人只能忍痛将其塞进车里。

接下来是一个情况稍好的场景，半断开的节点可能会注意到其发送的消息没有被其他节点所确认，因此意识到网络一定发生了某种故障。尽管如此，节点还是会被其他节点错误地宣告为失效，改变不了该节点最终的命运。

第三种情况，该节点上垃圾回收运行了很长时间，所有线程包括那些事务处理任务都被GC抢占并暂停了足足一分钟，在此期间，没有处理任何请求，也没有发送任何响应。那么其他节点只能苦苦等待，不停重试，最后无奈宣布该节点已经失效，然后将其塞进车里。可节点最终还是完成了垃圾回收，原有的工作线程得以继续，好像什么都没有发生。此时，轮到其他节点感到惊讶：刚刚宣告有问题的节点突然从车里爬出来，活蹦乱跳，甚至和周围兴奋地聊天。显然，运行垃圾回收的节点根本没有意识它中间休克了一分钟，从它的角度看，自上次正常的通信之后， 一切正常，没有奇怪的停顿。

我们讲这些故事的寓意是，节点不能根据自己的信息来判断自身的状态。由于节点可能随时会失效，可能会暂停－假死，甚至最终无法恢复 ，因此，分布式系统不能完全依赖于单个节点。目前，许多分布式算法都依靠法定票数 ，即在节点之间进行投票（参阅第5章“读写quorum”）。任何决策都需要来自多个节点的最小投票数，从而减少对特定节点的依赖 。

这其中包括关于宣告节点失效的决定。如果有法定数量的节点声明另一个节点失效，即使该节点仍感觉活得很自在，那它也必须接受失效的裁定，所有个体节点必须遵循法定投票的决议然后离线。

最常见的法定票数是取系统节点半数以上（也有其他类型的法定人数）。如果某些节点发生故障， quorum机制可以使系统继续工作（对于三个节点的系统，可以容忍一个节点失效；五个节点则可以容忍两个节点故障）。由于系统只可能存在一个多数， 绝不会有两个多数在同时做出相互冲突的决定，因此系统的决议是可靠的。第9章介绍一致性算法时，我们将更详细地讨论如何使用quorum 。

##### **主节点与锁**

有很多情况，我们需要在系统范围内只能有一个实例。例如 ：

- 只允许一个节点作为数据库分区的主节点，以防止出现脑裂（参阅第5章“处理节点失效”）。
- 只允许一个事务或客户端持有特定资源的锁，以防止同时写入从而导致数据破坏。
- 只允许一个用户来使用特定的用户名，从而确保用户名可以唯一标识用户 。

在分布式系统实现时需要额外注意：即使某个节点自认为它是“唯一的那个” （例如分区的主节点，锁的持有者，成功拿走用户名的请求），但不一定获得了系统法定票数的同意！一个节点可能以前确实是主节点，但其他节点有可能在此期间已宣布其失效（例如，出现了网络中断或GC暂停），节点已被降级而系统选出了另一个主节点。

当多数节点声明节点已失效，而该主节点还继续充当“唯一的那个”，如果系统设计不周就会导致负面后果。该节点会按照自认为正确的信息向其他节点发送消息，其他节点如果还选择相信它，那么系统就会出现错误的行为。

例如图 8-4 展示了由于不正确的加锁而导致数据破坏的例子。 该bug并非只是理论存在， HBase 曾遭遇过该问题。其设计目标是确保存储系统的文件一次只能由一个客户端访问，如果多个客户端试图同时写入该文件，文件就会被破坏。因此，在访问文件之前客户端需要从锁服务获取访问租约。

​    ![0](https://note.youdao.com/yws/res/21689/WEBRESOURCE3bf62d72b6ff15f75da4e07572d74f8a)

这个问题属于前面“进程暂停”中的一种情况 ： 持有租约的客户端被暂停太久直到租约到期。然后另一个客户端已经获得了文件的锁租约，并开始写文件。接下来，当暂停的客户端重新回来时，它仍然（错误地）认为合法持有锁并尝试写文件。结果导致客户端2的文件写入被破坏。

##### **Fencing令牌**

当使用锁和租约机制来保护资源的并发访问时（见图 8-4 ），必须确保过期的“唯一的那个”节点不能影响其他正常部分。要实现这一目标，可以采用一种相当简单的技术: fencing（栅栏，隔离之意），如图 8-5 所示。

我们假设每次锁服务在授予锁或租约时，还会同时返回一个fencing令牌， 该令牌（数字）每授予一次就会递增（例如，由锁服务增加） 。然后，要求客户端每次向存储系统发送写请求时，都必须包含所持有的fencing令牌。

图 8-5 中，客户端 1获得锁租约的同时得到了令牌号33 ，但随后陷入了一个长时间的暂停直到租约到期。这时客户端2 已经获得了锁租约和令牌号34 ，然后发送写请求（以及令牌号34 ）到存储服务 。接下来客户端 1恢复过来，并以令牌号33来尝试写入，存储服务器由于记录了最近已经完成了更高令牌号（34），因此拒绝令牌号33的写请求。

​    ![0](https://note.youdao.com/yws/res/21736/WEBRESOURCEa20e6b24a96f2d293f394a042a588721)

当使用ZooKeeper作为锁服务时，可以用事务标识zxid或节点版本cversion来充当fending令牌，这两个都可以满足单调递增的要求。

请注意，只靠客户端自己检查锁状态是不够的，这种机制要求资源本身必须主动检查所持令牌信息，如果发现已经处理过更高令牌的请求，要拒绝持有低令牌的所有写请求。如果资源不支持额外的令牌检查，可以采取一些临时技巧来绕过去（例如，对于访问文件存储服务的情况，可以将令牌信息内嵌在文件名中）。总之，为了避免在锁保护之外发生请求处理，需要进行额外的检查机制。

在服务器端检查令牌可能看起来有些复杂 ，但其实是推荐的正确做法：系统服务不能假定所有的客户端都表现符合预期，事实上客户端通常由权限级别相对较低的人来操作运行，因此存在一定的误用、滥用风险，从安全角度讲，服务端必须防范这种来自客户端的滥用。

#### **拜占庭故障**

fencing令牌可以检测并阻止那些无意的误操作（例如节点并没有发现其租约已经过期）。但是，如果节点故意试图破坏系统，在发送消息时可以简单地伪造令牌即可。

本书总是假设节点虽然不可靠但一定是诚实的：它们尽管运行很慢或者由于故障而无法响应，或者状态可能已经过期（例如由于GC暂停或网络延迟），但一旦做出了晌应，则一定是完全基于其所知的全部信息和事先协议约定好的行为准则，晌应代表了其所知的“真相”。

如果节点存在“撒谎”的情况（即故意发送错误的或破坏性的响应），那么分布式系统处理的难度就上了一个台阶。例如，节点明明没有收到某条消息，但却对外声称收到了。这种行为称为拜占庭故障，在这样不信任的环境中需要达成共识的问题也被称为拜占庭将军问题。

如果某个系统中即使发生部分节点故障，甚至不遵从协议，或者恶意攻击、 干扰网络，但仍可继续正常运行，那么我们称之为拜占庭式容错系统。这些担忧在某些特定场景是合理的。例如 ：

- 在航空航天领域，计算机内存或CPU寄存器中的数据可能会被辐射而发生故障，导致以不可预知的方式响应其他节点。这种情况下如果将系统下线，代价将异常昂贵（例如，可能出现飞机撞毁，杀死船员，或致使火箭与国际空间站相撞等），飞行控制系统必须做到容忍拜占庭故障。
- 在有多个参与者的系统中，某些参与者可能会作弊或者欺骗他人。这时节点不能完全相信另一个节点所发送的消息，它可能就是恶意的。例如，像比特币和其他区块链一样的点对点网络就是让互不信任的当事方就某项交易达成一致，且不依赖于集中的机制。

然而，在本书所讨论的这些系统中，我们可以安全地假定没有拜占庭式的故障。在数据中心里，所有的节点都是由一个组织来集中控制（可信任 ），辐射水平也足够低因而内存损坏可以忽略 。 解决拜占庭容错的系统协议异常复杂， 而容错的嵌入式系统还依赖于硬件层面的支持。因而在绝大多数服务器端数据系统中，部署拜占庭容错解决方案基本不太可行。

Web应用程序确实可能会接收来自任意客户端（如Web浏览器）的请求，其中可能带有恶意行为。因此需要输入验证、安全监测和输出转义等步骤，例如防止SQL注入和跨站恶意脚本。但我们通常并不使用拜占庭容错协议，而只是全权让服务器决定什么是可接受的客户端行为，什么是不允许的。只有在没有这种中央决策机制的点对点网络中，拜占庭容错才更为必要。

另外，软件中的bug可以被认为是拜占庭式故障，但如果将相同的软件部署到所有节点上，那么即使拜占庭式的容错算法也无法解决问题。大多数拜占庭容错算法要求系统超过三分之二的节点即绝大多数要功能正常（如果有四个节点，则最多允许一台发生故障）。要采用这类算法对付bug，必须有四个不同的软件实现，然后寄希望该bug只出现在四个实现中的一个。

试想如果有这样一个协议或者算法能同时保护我们免受漏洞 ，安全防范降级以及恶意攻击等，那将是多么美好。不幸的是，这是不现实的。通常如果攻击者可以入侵一个节点，则很可能会攻陷几乎所有节点（由于运行相同的软件）。因此，传统的安全措施如认证、访问控制、加密、防火墙等 ，仍是防范攻击的主要保护机制。

##### **弱的谎言形式**

尽管我们假设节点通常是诚实的，但依然推荐增加必要的机制来防范一些不那么恶意的“谎言”。例如由于硬件问题造成的无效消息、软件bug和配置错误。这种保护机制显然并不是完整的拜占庭式容错，无法防范敌手的攻击，但它们更为简单实用，可以帮助提高软件系统的可靠性和健壮性 。 例如 ：

- 由于硬件问题或操作系统、驱动程序、路由器等方面的错误，导致网络数据包有时出现损坏。通常，可以借助TCP/UDP中内置的数据包校验和来发现这类问题，但有时他们会逃避检测。 此时， 一个简单的防范措施是在应用层添加校验和。
- 对公众开放的应用必须仔细检查用户的所有输入，例如输入值是否在合理的范围内，并限制字符串的大小，防止分配超大内存导致拒绝服务攻击。位于防火墙后面的内部服务可能不用太严格的检查，但依然推荐执行基本的安全检查（例如，接口协议解析）。
- NTP客户端最好配置多个时间服务器。同步时间时，连接到多个时间服务器，收到回应之后要评估时间偏差，使得多数服务器就一定的时间范围达成一致。只要大多数服务器都正常，某个错误的服务器就可以被检测出来，从而排除在同步结果之外。总之，使用多台NTP服务器可以比仅使用一台服务器更为鲁棒。

#### **理论系统模型与现实**

目前分布式系统方面已有许多不错的具体算法，如第9章中要介绍的共识算法。这些算法需要容忍本章所讨论的各种故障。

算法的实现不能过分依赖特定的硬件和软件配置。这就要求我们需要对预期的系统错误进行形式化描述。我们通过定义一些系统模型来形式化描述算法的前提条件。

关于计时方面 ， 有三种常见的系统模型 ：

同步模型

同步模型假定有上界的网络延迟，有上界的进程暂停和有上界的时钟误差。注意，这并不意味着完全同步的时钟或者网络延迟为零。它只意味着你清楚地了解网络延迟、暂停和时钟漂移不会超过某个固定的上限。大多数实际系统的实际模型并非同步模型，因为（如本章所讨论的）无限延迟和暂停确实可能发生。

部分同步模型

部分同步意味着系统在大多数情况下像一个同步系统一样运行，但有时候会超出网络延迟，进程暂停和时钟漂移的预期上界。这是一个比较现实的模型：大多数情况下，网络和进程比较稳定（否则几乎不可能提供持续的服务），但是我们必须考虑到任何关于时机的假设都有偶尔违背的情况，而一旦发生，网络延迟，暂停和时钟偏差可能会变得非常大。

异步模型

在这个模型中， 一个算法不会对时机做任何的假设，甚至里面根本没有时钟（也就没有超时机制）。某些算法可以支持纯异步模型，但并不常见。

除了时机之外，我们还需要考虑节点失效。有以下三种最常见的节点失效系统模型：

崩溃－中止模型

在崩溃－中止模型中，算法假设一个节点只能以一种方式发生故障，即遭遇系统崩溃。这意味着节点可能在任何时候突然停止响应，且该节点以后永远消失，无法恢复。

崩溃－恢复模型

节点可能会在任何时候发生崩溃，且可能会在一段（未知的）时间之后得到恢复并再次响应。在崩溃－恢复模型中，节点上持久性存储（即非易失性存储）的数据会在崩溃之后得以保存，而内存中状态可能会丢失。

拜占庭（任意）失效模型

如上节所述，节点可能发生任何事情，包括试图作弊和欺骗其他节点。

对于真实系统的建模，最普遍的组合是崩溃 －恢复模型结合部分同步模型。那么接下来上层的分布式算法该如何应对这样的模型呢？

##### **算法的正确性**

为了定义算法的正确性，我们可以描述它的属性信息。例如，排序算法的输出具有以下特性 ： 对于输出列表中的任何两个不同的元素，左边的元素小于右边的元素。这就是一个对列表进行排序的正确性描述。

类似的思路，我们可以通过描述目标分布式算法的相关属性来定义其正确性。例如，对于锁服务的fencing 令牌生成算法 (参阅本章前面的“fencing令牌”)，要求算法具有以下属性:

唯一性

两个令牌请求不能获得相同的值。

单调递增

如果请求x返回了令牌tx，请求y返回了令牌ty，且x在y开始之前先完成，那么tx＜ ty。

可用性

请求令牌的节点如果不发生崩溃则最终一定会收到响应。

如果针对某个系统模型的算法在各种情况下都能满足定义好的属性要求，那么我们称这个算法是正确的。这有何意义呢？如果换一个角度来看一种极端情况，所有节点全部崩溃，或者所有的网络延迟突然变得无限长，那么所有的算法都不可能完成其预期功能。

##### **安全与活性**

为进一步加深理解，有必要区分两种不同的属性：安全性和活性。在上面的例子中，唯一性和单调递增属于安全属性，而可用性则属于活性。

这两种性质有何区别呢 ？ 一种理解思路是， 活性的定义中通常会包括暗示“最终” 一词（是的，你猜对了，最终一致性也是一种活性）。

安全性通常可以理解为“没有发生意外”，而活性则类似“预期的事情最终一定会发生”。这个非正式定义中，有很多主观因素，所以不用过度解读。安全性和活性其实有准确和数学化的定义描述，请参阅文献 :

- 如果违反了安全属性，我们可以明确指向发生的特定的时间点（例如，唯一性如果被违反， 我们可以定位到具体哪个操作产生了重复令牌）。且一旦违反安全属性，违规行为无法撤销，破坏已实际发生。
- 活性则反过来：可能无法明确某个具体的时间点 (例如一个节点发送了 一个请求，但还没有收到响应），但总是希望在未来某个时间点可以满足要求（即收到回复）。

区分安全性和活性的一个好处是可以帮助简化处理一些具有挑战性的系统模型。通常对于分布式算法，要求在所有可能的系统模型下，都必须符合安全属性。也就是说，即使所有节点发生崩溃，或者整个网络中断， 算法确保不会返回错误的结果 。

而对于活性，则存在一些必要条件。例如，我们可以说，只有在多数节点没有崩溃，以及网络最终可以恢复的前提下 ，我们才能保证最终可以收到响应。部分同步模型的定义即要求任何网络中断只会持续一段有限的时间，然后得到了修复，系统最终返回到同步的一致状态 。

##### **将系统模型映射到现实世界**

安全性、活性以及所建立的系统模型对于评测分布式算法的正确性意义重大。然而，很明显系统模型只是对现实情况的简化抽象，实践中具体实施算法时， 各种因素也杂在一起会提出更严峻的挑战 。

例如，在崩溃－恢复模型中，算法通常假设保存在持久性介质的数据可以安然无恙。但是，如果硬盘上的数据发生损坏，或者由于硬件错误，配置错误等导致数据被清除，会发生什么后果呢？即使硬盘本身正确连接到服务器，但服务器存在固件错误，导致重启时无法正确识别硬盘，又会发生什么情况？

Quorum算法（参见第5章 “读写 Quorum" ）要求节点必须记录之前对外所宣告的数据。如果节点发生意外而丢弃存储的数据，会打破法定条件并破坏算法的正确性。或许此时我们需要一个新的系统模型，它假定通常情况下数据存储非常可靠，但还是有丢失的可能。但那个模型就变得更难以推理了。

算法的理论描述可以简单地宣称某些事情绝不会发生，例如在非拜占庭系统中，我们就会明确假定一些可能和不可能发生的错误。不过，真正去实现时最好还是有一些必要的代码来简单处理一些几乎不可能发生的事情，即使只是去输出一些提醒信息（如printf ）和程序退出错误代码（如exit-666 ），以方便操作人员来清理最后的烂摊子。这些错误处理也很好地体现了计算机科学和软件工程之间的差异。

这绝对不是说抽象的系统模型没有价值，恰恰相反，它把实际系统中的复杂性提炼成一个更容易理解、更具可控性的抽象错误集合，可以有效帮助我们理解问题之本质，然后设计系统性方法来最终解决问题。如果我们可以确定在给定的系统模型中， 算法总能满足属性要求，那么我们可以证明算也就是正确的 。

证明算法正确却并不意味着真实系统上的某个具体实现一定是正确的。毫无疑问，这依然是极其重要的一步。理论分析并不能覆盖现实系统隐藏的每一个问题细节，例如某些边界条件一旦触发，会有负面影响，但这些边界条件归根结底一定是违背了模型的某个前提假设（例如，关于时间点）。我们可以说，理论性分析与实证性检验对最终的成功同等重要。

### **小结**

本章讨论了分布式系统中可能发生的各种典型问题，包括 ：

- 当通过网络发送数据包时，数据包可能会丢失或者延迟；同样，回复也可能会丢失或延迟。所以如果没有收到回复，并不能确定消息是否发送成功。
- 节点的时钟可能会与其他节点存在明显的不同步（尽管尽最大努力设置了 NTP服务器），时钟还可能会突然向前跳跃或者倒退， 依靠精确的时钟存在一些风险，没有特别简单的办法来精确测量时钟的偏差范围。
- 进程可能在执行过程中的任意时候遭遇长度未知的暂停（一个重要的原因是垃圾回收），结果它被其他节点宣告为失效，尽管后来又恢复执行，却对中间的暂停毫无所知。

部分失效可能是分布式系统的关键特征。只要软件试图跨节点做任何事情，就有可能出现失败，或者随机变慢，或者根本无应答（最终超时）。对于分布式环境，我们的目标是建立容忍部分失效的软件系统，这样即使某些部件发生失效，系统整体还可以继续运行。

为了容忍错误，第一步是检测错误，但即使这样也很有挑战。多数系统没有检测节点是否发生故障的准确机制，因此分布式算法更多依靠超时来确定远程节点是否仍然可用。但是，超时无法区分网络和节点故障，且可变的网络延迟有时会导致节点被误认为发生崩溃。此外，节点可能处于一种降级状态 ： 例如 ，由于驱动程序错误，千兆网络接口可能突然降到 1 kb/s的吞吐量。这样一个处于“残废”的节点比彻底挂掉的故障节点更难处理。

检测到错误之后，让系统容忍失效也不容易。在典型的分布式环境下，没有全局变量， 没有共享内存，没有约定的尝试或其他跨节点的共享状态。节点甚至不太清楚现在的准确时间， 更不用说其他更高级的了。信息从一个节点流动到另一个节点只能是通过不可靠的网络来发送。单个节点无法安全的做出任何决策，而是需要多个节点之间的共识协议，并争取达到法定票数。

如果习惯于编写单节点理想化环境运行的软件（即同一个操作总是确定性地返回相同的结果）， 当转向分布式系统时 ，种种看似凌乱的现实可能着实让人震惊。相反，如果在单节点上即可解决问题，那么对于一个分布式系统工程师通常会被认为该问题微不足道（现在单节点确实可以完成很多任务）。如果可以避免打开潘多拉之盒，那么把工作都放在一台机器也值得一试。

但正如在第二部分开头所讨论的那样，可扩展性并不是使用分布式系统的唯一原因 。容错与低延迟（将数据放置在距离用户较近的地方） 也是同样重要的目标，而后两者无法靠单节点来实现。

本章，我们也探讨了网络 、 时钟和进程的不可靠性是否是不可避免的自然规律。我们对此给出的结论是否定的：的确有可能在网络中提供硬实时的延迟保证或者具有上确界的延迟，但代价昂贵，且硬件资源利用率很低。除了安全关键场景 ，目前绝大多数都选择了低成本（和不可靠）。

我们还谈到了高性能计算，它们多采用更加可靠的组件，发生故障时完全停止系统，之后重新启动。相比之下，分布式系统会长时间不间断运行，以避免影响服务级别：故障处理和系统维护多以节点为单位进行处理，或者理论上如此（实际上，如果错误的配置不小心被应用到集群的所有节点，仍然会导致整个集群系统瘫痪）。

这样看起来本章揭露的全是问题，前景黯淡。那么在下一章 ，我们将讨论解决方案，重点是针对这些问题而设计相关的分布式算法。

## **第9章 一致性与共识**

正如第8章所述，分布式系统存在太多可能出错的场景。而处理故障最简单的办法就是直接让整个服务停下来，然后向用户提示出错信息。但如果不能接受服务中止，就需要更加容错的解决方案，这样即使某些内部组件发生了故障，整个系统依然可以对外提供服务。

本章我们将讨论构建容错式分布式系统的相关算法和协议。这里假设第8章中所有的故障都可能发生，这包括网络数据包可能会丢失、 顺序紊乱、重复发送或延迟，时钟也有一定偏差，节点可能发生暂停 （例如由于垃圾回收）甚至随时崩溃。

为了构建容错系统，最好先建立一套通用的抽象机制和与之对应的技术保证，这样只需实现一次，其上的各种应用程序都可以安全地信赖底层的保证。这与第7章我们引人事务的道理相同：通过事务，应用程序可以假装没有崩溃（原子性），没有与其他人并发访问数据库（隔离性），且存储设备是完全可靠的（持久性）；总之，抽象的事务机制可以屏蔽系统内部很多复杂的问题，例如发生崩溃、边界条件、磁盘故障等，使得应用层轻松无忧。

现在继续沿着这个思路，尝试建立可以让分布式应用忽略内部各种问题的抽象机制。例如，分布式系统最重要的抽象之一就是共识： 所有的节点就某一项提议达成一致。通过本章的介绍，最后你会发现面对各种网络故障和进程失效，可靠地达成共识是一件多么了不起的事情。

一旦解决了共识问题 ，就可以服务于应用层很多的目标需求。 例如，对于一个主从复制的数据库，如果主节点发生失效，就需要切换到另一个节点，此时数据库节点可以采用共识算法来选举新的主节点。正如第5章“处理节点失效”所强调的，某一时刻必须只有一个主节点，所有的节点必须就此达成一致。如果有两个节点都自认为是主节点，就会发生脑裂，导致数据丢失。正确实现共识算法则可以避免此类问题。

本章我们将主要研究解决共识问题的相关算法。在此之前，首先我们会简要讨论分布式系统可提供的若干保证和抽象机制。

我们需要了解系统能力的边界，即哪些可行，哪些不可行。在什么情况下，系统可以容忍故障并继续工作：而其他情况，却无法保证。在理论证明和具体实现两方面，业界对此都有着非常深入的研究，在此本章即将为大家总体介绍各种系统边界情况。

事实上， 几十年来分布式系统领域的研究人员一直在持续探索 ，积累了大量的研究资料，由于篇幅所限，我们无法一一触及。所以本章会省去相关的形式化模型与证明细节，更多的是给出较为直观的示例和解释。如有兴趣，本章后面的“参考文献”提供了更详细的信息。

### **一致性保证**

在第5章 “复制滞后问题”中，我们探讨了复制数据库时的计时问题。如果在同一时刻查询数据库的两个节点，则可能会看到不同的数据，这主要是因为写请求会在不同的时间点到达不同的节点 。无论数据库采用何种复制方法（包括主从复制， 多主节点复制或者无主节点复制），都无法完全避免这种不一致情况。

大多数多副本的数据库者至少提供了最终的一致性，这意味着如果停止更新数据库，并等待一段时间（长度未知）之后，最终所有读请求会返回相同的内容。换句话说，不一致现象是暂时的，最终会达到一致（假设网络故障最终会被修复）。换言之，最终一致性意味着“收敛”，即预期所有的副本最终会收敛到相同的值。

但是，这是一个非常弱的保证，它无法告诉我们系统何时会收敛。而在收敛之前，读请求可能会返回任何值甚至读失败。例如，如果完成一笔更新操作之后立即读取，由于读取可能会路由到不同的副本，系统不保证一定读到刚刚写入的值（参阅第5章“读自己的写”）。

对于应用开发人员而言，最终一致性会带来很大的处理挑战，这与普通的单线程程序中变量读写行为大相径庭。对于后者，如果将对变量赋予某个值，接下来去读变量 ，不可能发生读失败或者读不到刚赋的值。数据库表面上看起来像一个可以进行读写的变量，但事实上它内部有无比复杂的更多语义要求。

当面对只提供了弱保证的数据库时，需要清醒地认清系统的局限性，切不可过于乐观。应用可能在大多数情况下都运行良好，但数据库内部可能已经发生了非常微妙的错误，只有当系统出现故障（例如网络中断）或高并发压力时，最终一致性的临界条件或者错误才会对外暴露出来，因而测试与发现错误变得非常困难。

因此本章将探索更强的一致性模型。不过，这也意味着更多的代价，例如性能降低或容错性差。尽管如此，更强的保证的好处是使上层应用逻辑更简单，更不容易出错 。当了解、对比了多种不同的一致性模型之后，可以结合自身需求，从中选择最合适的。

分布式一致性模型与我们之前讨论过的多种事务隔离级别有相似之处（参阅第7章“弱隔离级别”）。虽然存在某些重叠 ，但总体讲他们有着显著的区别：事务隔离主要是为了处理并发执行事务时的各种临界条件，而分布式一致性则主要是针对延迟和故障等问题来协调副本之间的状态。

本章内容涵盖非常广泛，但细究起来，这些内容之间存在着密切联系 ：

- 我们首先介绍线性化，这是最强的一致性模型，并考察其优缺点。
- 然后，我们将探讨分布式系统中事件顺序问题（参阅本章后面的“顺序保证”），特别是因果关系和全局顺序。
- 最后“分布式事务与共识”小节，我们将探索如何自动提交分布式事务，并最终解决共识问题。

### **可线性化**

在最终一致性数据库中，同时查询两个不同的副本可能会得到两个不同的答案。这会使应用层感到困惑。如果数据库能够对上提供只有单个副本的假象，情况会不会大为简化呢？这样让每个客户端都拥有相同的数据视图，而不必担心复制滞后。

这就是可线性化（也称为原子一致性，强一致性等）的思想。线性化的确切定义比较微妙，我们将稍后再详细探讨。其基本的想法是让一个系统看起来好像只有一个数据副本，且所有的操作都是原子的。有了这个保证，应用程序就不需要关心系统内部的多个副本 。

在一个可线性化的系统中， 一旦某个客户端成功提交写请求 ，所有客户端的读请求一定都能看到刚刚写入的值。这种看似单一副本的假象意味着它可以保证读取最近最新值，而不是过期的缓存。换句话说，可线性化是一种就近的保证。为了解释该想法，我们先来看一个非线性化系统的例子。

​    ![0](https://note.youdao.com/yws/res/22137/WEBRESOURCE031f44f10cfb4dcb6b4faa4064051443)

图 9-1 是一个非线性化的体育网站。 Alice和Bob坐在同一个房间里各自观看自己的手机，焦急地等待2014年FIFA世界杯决赛的结果。刚刚宣布了最终比分之后， Alice刷新了页面马上看到获胜者，然后兴奋地告诉Bob 。于是Bob马上在自己的手机上刷新页面，但他的请求发向了某个落后的数据库副本，结果却显示比赛还在进行之中。

如果AIice和Bob几乎同时刷新页面得到两个不同的结果 ，他们也不清楚服务器端究竟何时接受、处理这些请求，因此可能并不会特别惊讶。然而，现在的情况却是Bob听到了Alice兴奋的比分之后再单击刷新，他希望至少是看到刚刚Alice播报的最近比分，但却读到过期的结果，这就违背了线性化规则 。

#### **如何达到线性化?**

可线性化背后的基本思想很简单：使系统看起来好像只有一个数据副本。然而，细究起来还有更多的含义。为了更好地理解可线性化，来看看更多的例子。

图 9-2 展示了三个客户端在线性化数据库中同时读写相同的主键x。在分布式语义下，x被称为寄存器，例如，它可以是键－值存储中的一个键，关系数据库中的一行或文档数据库中的一个文档。

​    ![0](https://note.youdao.com/yws/res/22161/WEBRESOURCE9b2edb10f80645dc2389944ca02d7b60)

为简单起见，图 9-2 仅展示了客户端所观察到请求内容，而不是数据库内部。由于网络延迟不确定，客户端并不清楚数据库具体何时处理请求，而只知道它是在发送之后、响应之前的某个中间时间点。

在这个例子中，寄存器有两类操作：

- read (x) => v 表示客户端读取x的值，数据库返回了值v 。
- write (x, v) => r 表示客户端将x设置为值v ， 数据库返回处理结果r （可能表示处理成功或者发生了失败） 。

在图9-2中，x的初始值为0，客户端C提交写请求将其设置为1。同时，客户端A和B在反复轮询数据库以读取最新值。A和B可能会分别读到什么样的返回值呢?

- 客户端A的第一个读取操作在写入开始之前已完成，因此返回的是旧值0 。
- 客户端A的最后一次读操作是在写操作完成之后才开始的，如果数据库是可线性化的，它肯定会返回新值 1 。道理很简单，执行写操作肯定是在写请求发送之后并且响应之前 ：执行读操作同理。 如果写入结束后开始读取，那么读一定发生在执行写之后，所以看到的一定是写入的新值。
- 与写操作有时间重叠的任何读取操作则可能返回 0 或者 1 ，这是因为读写之间存在并发， 无法确切知道在执行读取时，写入是否已经生效。

然而，这还没有精确描述线性化：如果与写并发的读操作可能返回旧值或新值，那么在这个过程中，不同的读客户端会看到旧值和新值之间来回跳变的情况 。 这肯定不符合我们所期望的模拟“单一数据副本” 。

为使系统可线性化 ，我们需要添加一个重要的约束，如图 9-3所示。

​    ![0](https://note.youdao.com/yws/res/22176/WEBRESOURCEdf7cef9faf4c688051838cf7bdfba487)

在一个可线性化的系统中，在写操作的开始与结束之间必定存在某个时间点， x的值发生了从 0 到 1 的跳变。 如果某个客户端的读取返回了新值 1 ，即使写操作尚未提交 ，那么所有后续的读取也必须全部返回新值。

图 9-3 中的箭头表示时序依赖关系。客户端A首先读到新值 1 ，在A读取返回之后， B开始读取，由于B的读取严格在A的读取之后发生，因此即使C的写入仍在进行之中，也必须返回 1 。这和图 9-1 中 Alice和Bob的情况类似，在Alice读取新值之后， Bob也预期读取新值。

可以进一步细化时序图来可视化每步操作具体在哪个时间点生效，如图 9-4 所示。

在图 9-4 中，除了读写之外，我们引入了第三种类型的操作 ：

- CaS(x, Vold, Vnew) => r 表示一个原子比较－设置操作（ compare-and -set, CAS) （参阅第7章“原子比较和设置”）。如果寄存器 x 当前值等于 Vold，则将其原子设置为Vnew ；否则保留现有 x 值不变，然后返回错误， r是返回值，表示成功或者失败。

图 9-4 中的每个操作都有一条竖线，表示可能的执行时间点。这些标记以前后关系依次连接起来，最终的结果必须是一个有效的寄存器读写顺序，即每个读操作须返回最近写操作所设置的值。

可线性化要求，如果连接这些标记的坚线，它们必须总是按时间箭头（从左到右）向前移动，而不能向后移动。这个要求确保了之前所讨论的就近性保证： 一旦新值被写入或读取，所有后续的读都看到的是最新的值，直到被再次覆盖。

​    ![0](https://note.youdao.com/yws/res/22224/WEBRESOURCEe4950a40f22fc41802557f6fa68d8b66)

图 9-4 中有一些有趣的细节值得仔细分析 ：

- 客户端B首先发送读x的请求，接下来客户端D发送请求将x置为 0 ，紧接着客户端A又发送请求将 x置为 1 ，而最终返回给B的值为 1 (A所写入的值）。这是可能的，它意味着数据库执行的顺序是：首先处理D的写入0 ，然后是A的写入 1 ，最后是B的读取。虽然这并不是请求发送的顺序，但考虑到请求并发以及网络延迟等情况，例如或许B的读请求网络延迟更大，导致在两次写执行之后才到达数据库，因此这是一个合法的可接受的处理顺序。
- 客户端A在收到数据库写响应之前，客户端B即读到了值 1 ，这表明写入已成功 。这是可能的，但它并不代表执行读发生在执行写之前，只是意味着很可能由于网络延迟而耽搁了客户端A接受响应。
- 模型没有假定事务间的隔离，即另一个并发客户端可能随时会修改值。例如， C首先读取到 1 ，然后读到2 ，原因是两次读取之间值被客户端B修改了。我们可以使用原子比较和设置（ cas ）操作来检查值是否被其他并发客户端修改，例如客户端B和C的 cas 请求成功，但是D的 cas 操作失败（因为数据库处理时， x的值已不再为0 ）。
- 客户B的最后一次读取（阴影的方框）不满足线性化 。 该操作与C的 cas 写操作同时发生，后者将x从2更新为4。按照可线性化的要求，它应该读到的是4，因为那是已知的最新值。

以上就是线性化背后的直觉含义。正式的定义请参考文献。通过记录所有请求和响应的时序，然后检查它们是否可以顺序排列，可以用来测试系统是否可线性化（这里存在额外的计算开销） 。

#### **线性化的依赖条件**

那什么情况下应该使用线性化呢？上面足球比赛比分的例子只是个最简单的情况，结果存在几秒的延迟通常不会造成实质的伤害。然而，在有些场景下，线性化对于保证系统正确工作至关重要。

##### **加锁与主节点选举**

主从复制的系统需要确保有且只有一个主节点，否则会产生脑裂。选举新的主节点常见的方法是使用锁：即每个启动的节点都试图获得锁，其中只有一个可以成功即成为主节点。不管锁具体如何实现，它必须满足可线性化：所有节点都必须同意哪个节点持有锁，否则就会出现问题 。（GPT解释：分布式锁的实现必须是可线性化的，意味着系统的所有参与节点都必须能够以一种一致的顺序查看操作（例如，获取锁和释放锁），就好像这些操作是按顺序执行的一样。）

提供协调者服务的系统如Apache ZooKeeper和etcd等通常用来实现分布式锁和主节点选举。它们都使用了支持容错的共识算法确保可线性化（本章后面的“支持容错的共识”会详细讨论这些算法）。虽然目前也有像Apache Curator这样的上层库，在ZooKeeper之上提供了更高级别的接口以方便使用，但正确实现加锁和选举其实还有很多重要的设计细节（参阅第8章“主节点与锁”）。归根结底，线性化存储服务是所有这些协调服务的基础。

在一些分布式数据库如Oracle Real Application Clusters (RAC) ，分布式锁有更细粒度的实现 ： RAC为每个磁盘页面均设置一把锁，多个节点因此可以并发地共享访问存储系统。这些可线性化的锁处于事务执行的关键路径上，出于性能考虑， RAC部署时通常都要求专用的集群互连网络来连接数据库节点。

##### **GPT：分布式锁基本知识**

Q：解释一下分布式锁

------

分布式锁是在分布式系统中用于确保在多个节点上运行的不同进程或线程之间的互斥访问共享资源的机制。它是一种同步工具，用于防止多个客户端同时对同一数据或资源进行修改，从而避免数据竞争和不一致的情况。

由于在分布式环境中，系统组件可能分散在不同的物理或逻辑节点上，因此传统的单机锁机制不能直接应用。分布式锁需要跨网络边界协调，这增加了复杂性和潜在的风险。

分布式锁的常见用途包括：

1. 确保资源的独占访问：避免在执行关键操作时发生冲突，例如在更新数据库或文件系统中的数据时。
2. 维护操作的顺序：在工作流中，某些操作可能需要以特定顺序执行。
3. 实现领导选举：在分布式系统中选择一个主节点来协调操作或执行特殊任务。

实现分布式锁的方式有多种，下面是一些常见的方法：

1. 基于数据库的锁：

- - 使用数据库的行锁或表锁来实现分布式锁。
  - 适用于数据库操作，但可能会受到数据库本身的性能和可用性限制。

1. 基于缓存系统的锁：

- - 使用如Redis或Memcached这样的缓存系统实现分布式锁。
  - 这些系统通常提供了原子性操作，如SETNX在Redis中，可以用来实现锁的机制。

1. 基于ZooKeeper的锁：

- - 使用ZooKeeper的临时顺序节点创建一个锁目录，每个尝试获得锁的客户端在这个目录下创建一个节点。
  - 客户端监视序号最小的节点，如果它是最小的，那么该客户端获得锁；否则，它等待直到比它序号小的节点被删除。

1. 基于分布式一致性算法的锁：

- - 实现如Raft或Paxos这样的一致性算法，通过集群共识来控制锁的获取和释放。
  - 这些方法通常用在更复杂的系统中，可实现高可用性和容错性。

使用分布式锁时需要特别注意几个挑战和风险：

- 死锁：由于网络延迟或节点故障，锁可能无法被释放，导致资源无法被其他客户端访问。
- 性能问题：获取和释放分布式锁可能需要进行网络通信，增加了延迟和开销。
- 可靠性问题：分布式锁的实现必须能正确处理节点故障和网络问题，同时保证锁的语义（互斥、不会丢失锁等）。

因此，尽管分布式锁是实现分布式系统中的资源同步的有力工具，但在使用时需要谨慎设计和实施，以确保系统的正确性和性能。

Q：能具体说一说第四点：基于分布式一致性算法的锁 吗？

------

当然可以。基于分布式一致性算法的锁利用了一致性算法（如Raft或Paxos）来在分布式系统中实现锁的互斥性。这些算法设计用来在分布式系统中达成一致的决定，即使在面对网络延迟、分区和节点故障等问题时也能保持一致。下面是基于分布式一致性算法的锁的一些关键点：

**一致性算法概述：**

1. Raft：Raft算法将集群中的节点分为Leader、Follower和Candidate三种角色。正常工作时，只有一个Leader负责处理所有的客户端请求（包括对锁的请求）并且与Follower节点进行日志复制以保持状态的同步。如果Leader宕机，Follower可以成为Candidate并启动新一轮的领导选举。
2. Paxos：Paxos算法侧重于如何在分布式系统中对一个值达成一致。它通过一系列提议（Proposals）和承诺（Promises）的过程来达成共识。Paxos在实现上比Raft更复杂，但同样可以用于构建强一致性的系统。

**分布式锁的实现：**

1. 共识过程：在分布式锁的上下文中，共识过程可以用来协调哪个节点（或客户端）拥有锁。例如，一个节点可能请求获取锁，并通过集群共识来决定它是否获得该锁。
2. 日志复制：在Raft中，Leader节点负责将锁请求作为一个日志条目复制到Follower节点上。只有当多数节点都写入了这个日志条目，锁请求才会被批准。
3. 领导者选举：如果Leader节点发生故障，其他节点会通过一致性算法的领导者选举机制选出新的Leader。新的Leader会处理挂起的锁请求和释放锁的操作。
4. 锁的获取与释放：锁的获取和释放操作被转化为集群状态机的状态变更，这些变更通过一致性算法在集群中达成一致。这保证了即使在有节点故障的情况下，锁的状态也不会丢失。

**优点：**

- 强一致性：基于一致性算法的锁提供了强一致性保证，这意味着在任何时刻，整个分布式系统对于锁的状态都有一个一致的视图。
- 容错性：由于一致性算法能够处理节点故障，基于这些算法的锁可以在节点宕机的情况下继续工作。

**挑战：**

- 复杂性：实现和理解这些一致性算法相对复杂，对开发和运维的要求较高。
- 性能：这些算法通常需要多轮网络通信来达成共识，并复制日志条目，这可能会导致性能瓶颈。

基于一致性算法的锁通常用于需要强一致性和高可用性的分布式系统。然而，这种类型的锁可能不适用于对延迟敏感的场景，因为锁请求可能需要等待集群共识，这会引入额外的延迟。在设计系统时，需要仔细考虑这些因素，并评估不同的锁机制以找到满足特定应用需求的最佳方案。

Q：有哪些项目实现了基于分布式一致性算法的锁

------

有几个项目和服务实现了基于分布式一致性算法的锁，以下是一些比较著名的例子：

1. Etcd：

- - Etcd 是一个高可用的分布式键值存储，它经常被用来存储关键数据，以帮助分布式系统的配置管理和服务发现。
  - 它使用 Raft 一致性算法来管理一个高可靠的复制日志。
  - Etcd 提供了分布式锁的API，可以被用来实现分布式系统中的锁机制。

1. Apache ZooKeeper：

- - ZooKeeper 是一个开源的分布式协调服务，它为分布式应用程序提供一致性服务。
  - 虽然 ZooKeeper 内部使用的是自己的一致性算法（类似于 Paxos），但它可以用于建立分布式锁和其他同步原语。

1. Consul：

- - Consul 是一个用于服务网络的多功能数据平台，提供服务发现、健康检查、键值存储等功能。
  - 它同样使用 Raft 协议来保证数据中心级别的一致性。
  - Consul 提供了分布式锁的功能，称为 "sessions"，可以用来实现基于锁的协调。

1. Redisson：

- - Redisson 是一个在 Redis 基础上构建的 Java 分布式数据结构的库。
  - 它提供了分布式锁的实现，并且有多种锁的模式，例如公平锁和联锁（MultiLock）。
  - 虽然 Redis 本身不是一个一致性算法的实现，但 Redisson 利用了 Redis 的特性来保证在分布式环境中的锁的一致性。

1. Amazon DynamoDB Lock Client:

- - 这是 Amazon 提供的一个客户端库，用于在 DynamoDB 之上创建分布式锁。
  - 它并不直接使用一致性算法，而是通过 DynamoDB 的条件写入功能确保锁的一致性。

尽管以上提到的项目并不是全部直接实现了 Raft 或 Paxos 算法，它们都提供了构建分布式锁需要的一致性和协同工作的能力。在选择适合自己项目的分布式锁实现时，需要考虑锁的性能、容错能力、易用性以及和现有系统的兼容性。

Q：单个节点的etcd锁服务也叫分布式锁吗？

------

分布式锁的目的是为了确保在分布式系统中不同节点或服务实例之间对共享资源的互斥访问。如果在 Etcd 单节点部署中使用锁机制，它确实可以提供锁的基本功能，即确保获得锁的客户端可以独占访问某个资源。

但是，“分布式锁”这个术语通常意味着锁服务本身是分布式的，它能够在多个系统节点间保持高可用性和容错性。如果锁服务只运行在单个节点上，那么它不具备分布式系统中通常需要的这些特性。换句话说，单个节点的 Etcd 能够提供锁的机制，但如果在这样的部署中使用锁，就失去了分布式锁的两个关键优势：

1. 高可用性：在分布式锁系统中，即使某个节点故障，锁服务仍然可以继续工作，因为其他节点会接管服务，确保锁机制不会中断。
2. 容错性：分布式锁系统可以容忍一定数量的节点故障（例如，在 Etcd 集群中可以容忍少于半数的节点故障）而不影响锁服务的可用性。

如果 Etcd 部署为单节点，当这个节点不可用时，整个锁服务也会不可用，这就使得在分布式环境中依赖于这种锁机制的应用也会受到影响。因此，尽管从技术上讲单节点 Etcd 可以提供锁的功能，但为了实现真正的分布式锁特性，推荐在多节点集群中部署 Etcd。这样可以确保锁服务即使在节点故障的情况下也能保持正常运作。

Q：raft算法在etcd中起到哪些功能的作用

------

在 Etcd 中，Raft 算法是核心的一致性协议，它用来保证分布式系统中数据的一致性和系统的高可用性。以下是 Raft 算法在 Etcd 中扮演的一些关键功能：

1. 领导者选举（Leader Election）：

- - Raft 算法通过领导者选举来确保集群有一个明确的指挥节点（Leader），该节点负责管理数据的复制（日志条目）和维护集群的状态一致性。
  - 当集群启动或当现有的 Leader 失效时，Raft 算法负责在集群的所有成员节点（Follower）中选举出新的 Leader。

1. 日志复制（Log Replication）：

- - Leader 节点负责接收客户端请求（如键值对的更新或新增操作），将请求作为日志条目添加到它的本地日志中，并在集群中复制这些日志条目到 Follower 节点。
  - Raft 保证所有节点的日志条目顺序一致，即使在网络分区或节点故障的情况下，一致性也不会被破坏。

1. 安全性和一致性保证（Safety and Consistency）：

- - Raft 确保即使在出现网络问题和节点故障的情况下，也不会有冲突的值被提交。
  - 它通过“提交规则”来保证一旦某个日志条目被复制到大多数节点，该条目就可以安全地应用到系统状态。

1. 容错处理（Fault Tolerance）：

- - Raft 通过容忍集群中少数节点的故障来提供容错能力。
  - 只要集群中的大多数节点是正常的，系统就能够继续工作，包括进行领导者选举和日志复制。

1. 读一致性（Read Consistency）：

- - Raft 算法还提供了读操作的一致性保证。当客户端从集群的 Leader 节点读取数据时，Leader 会确保它所服务的数据是最新的，或者在需要时，它会从其他节点更新其数据以保证一致性。

1. 成员变更（Membership Changes）：

- - Raft 允许在不停机的情况下动态地添加或移除节点，这对于维护大规模分布式系统至关重要。
  - 成员变更协议确保在集群配置变更的过程中，系统的一致性和可用性不会受到影响。

通过以上这些功能，Raft 算法使得 Etcd 能够作为一个高可用且一致的键值存储，为分布式系统提供关键的服务，如配置管理、服务发现、分布式锁等。Raft 的设计使得它非常适合用于这些场景，因为它比其他一致性算法更容易理解和实现，并且它的实现更加健壮和可靠。

##### **约束与唯一性保证**

唯一性约束在数据库中很常见。例如，用户名或电子邮件地址必须唯一标识一个用户，文件存储服务中两个文件不能具有相同的路径和文件名。如果要在写入数据时强制执行这些约束（例如，如果两个人试图同时创建具有相同名称的用户或文件，其中一个必须返回错误），则也需要线性化。

这种情况本质上与加锁非常类似 ： 用户注册等同于试图对用户名进行加锁操作。该操作也类似于原子比较和设置：如果当前用户名尚未被使用，就设置用户名与客户 ID 进行关联。

其他类似约束包括银行账户余额不应出现负值，或者避免出售库存里已经没有的商品，或者不能同时预定航班或者剧院的相同的座位。这样的约束条件都要求所有节点就某个最新值达成一致（例如账户余额，库存水平，座位占用率）。

当然在某些实际场合中，有时可以放宽这些限制（例如，如果航班发生超额预订，可以将客户转移到其他的航班并提供必要的补偿）。在这种情况下，或许不需要线性化，我们将在第 12章“时效性与完整性”讨论这些松散的约束条件。

然而，硬性的唯一性约束，常见如关系型数据库中主键的约束，则需要线性化保证。其他如外键或属性约束，则并不要求一定线性化。

##### **跨通道的时间依赖**

请注意图 9-1 中的一个细节 ：如果Alice没有高呼比分， Bob可能就不会知道他的查询结果是过期的。或许他会在几秒之后再次刷新页面，然后看到最终的比方 。线性化违例之所以被注意到，是因为系统中存在其他的通信渠道（例如， Alice对Bob发出的声音来传递信息）。

计算机系统也会出现类似的情况。例如，用户可以上传照片到某网站，有一个后台进程将照片调整为更低的分辨率（即缩略图）以方便更快下载。该网站架构和数据流如图 9-5 所示。

这里需要明确通知图像调整模块来调整哪些图片，系统采用了消息队列将此命令从Web服务器发送到调整器。因为大多数消息队列系统并不适合大数据流，而考虑到照片的大小可能到数兆字节，因此Web服务器并不会把照片直接放在队列中。相反，照片会先写入文件存储服务，当写入完成后，把调整的命令放入队列。

如果文件存储服务是可线性化的，那么系统应该可以正常工作。否则，这里就会引入竞争条件 ： 消息队列（图 9-5 中的步骤3和步骤4 ）可能比存储服务内部的复制执行更快。在这种情况下，当调整模块在读取图像（步骤 5 ）时，可能会看到图像的某个旧版本，或者根本读不到任何内容 。 如果它碰巧读到了旧版本的图像并进行处理， 会导致文件存储中的全尺寸图片与调整之后图片出现永久的不一致 。

​    ![0](https://note.youdao.com/yws/res/22325/WEBRESOURCE85ff0fdaaaf419ade59f8ccf97990bcd)

之所以出现这个问题是因为Web服务器和调整模块之间存在两个不同的通信通道 ：文件存储器和消息队列。如果没有线性化的就近性保证，这两个通道之间存在竞争条件。这种情况类似于图 9-1 ：网页数据库有数据复制通道，而在计算机系统之外，Alice和Bob之间还有口耳相传的通道。

线性化并非避免这种竞争的唯一方法，但却是最容易理解的。如果可以控制某一个通信通道（例如消息队列，但注意不适合Alice和Bob的例子，因为后者并非计算机系统），可以尝试第5章的 “读自己的写”方法，但会引入额外的复杂性 。

#### **实现线性化系统**

现在我们已经看了几个线性化的例子，接下来考虑如何实现这样可线性化的系统。

由于线性化本质上意味着 “表现得好像只有一个数据副本，且其上的所有操作都是原子的” 所以最简单的方案自然是只用一个数据副本。但显然，该方法无法容错 ： 如果仅有的副本所在的节点发生故障，就会导致数据丢失，或者至少在重启之前都无法访问服务。

系统容错最常见的方法就是采用复制机制。我们再来回顾一下第5章所介绍的多种复制方案，看看哪些满足可线性化 ：

主从复制（部分支持可线性化）

在主从复制的系统中（参阅第5章的“主节点与从节点”），只有主节点承担数据写入，从节点则在各自节点上维护数据的备份副本。如果从主节点或者同步更新的从节点上读取，则可以满足线性化。但并非每个主从复制的具体数据库实例都是可线性化的， 主要是因为它们可能采用了快照隔离的设计，或者实现时存在并发方面的 bug。

而从主节点上读取的前提是你确定知道哪个节点是主节点。正如在第8章“真相由多数决定”中所讨论的 ，某节点可能自认为是主节点，但事实并非如此，这个“自以为是”的主节点如果对外提供服务，就会违反线性化 。 如果使用了异步复制，故障切换过程中甚至可能会丢失一些己提交的写入（ 参阅第5章“处理节点失效”），结果是同时违反持久性和线性化 。

共识算法 （可线性化）

我们本章稍后即将讨论的一些共识算法，与主从复制机制相似。不过共识协议通常内置一些措施来防止裂脑和过期的副本。正是由于这些专门的设计，共识算法可以安全地实现线性化存储，这些系统包括ZooKeeper和etcd等 。

多主复制（不可线性化）

具有多主节点复制的系统通常无法线性化的，主要由于它们同时在多个节点上执行并发写入，并将数据异步复制到其他节点。因此它们可能会产生冲突的写入，需要额外的解决方案（参阅第5章的“处理写冲突”）。 这类冲突其实正是多副本所引入的结果。

无主复制（可能不可线性化）

对于无主节点复制的系统（即Dynamo风格，参阅第5章的“无主节点复制”），有些人认为只要配置法定读取和写入满足 （ w+r>n ） 就可以获得“强一致性”。但这完全取决于具体的quorum的配置，以及如何定义强一致性，它可能并不保证线性化。

例如基于墙上时钟（包括Cassandra ，参阅第8章“依赖于同步的时钟”）的“最后写入获胜”冲突解决方法几乎肯定是非线性化，因为这种时间戳无法保证与实际事件顺序一致（例如由于时钟偏移）。 不规范的quorum（ 参阅第5章“宽松的quorum与数据回传”）也会破坏线性化。甚至即使是严格的 quorum ，正如之后即将介绍的，也会发生违背线性化的情况 。

##### **线性化与quorum**

直觉上，对于Dynamo风格的复制模型，如果读写遵从了严格 quorum， 应该是可线性化的。然而如果遭遇不确定的网络延迟，就会出现竞争条件，如图 9-6所示。

​    ![0](https://note.youdao.com/yws/res/22369/WEBRESOURCEc63cc6aef4499cc218899815043189f0)

图 9-6 中，x的初始值为0 ，写客户端向所有三个副本 （ n=3, w=3 ）发送写请求将x更新为 1 。与此同时， 客户端A从两个节点 （ r =2 ）读取数据，然后在其中一个节点上看到新值 1 。与此同时， 客户端B从两个节点的读取，两者在都返回了旧值0 。

我们发现它虽然满足了仲裁条件（ w+r>n ），但很明显这不是线性化的：B的请求在A的请求完成之后才开始， A返回了新值，但B却得到了旧值。 这又类似图 9-1 中Alice和Bob的情况。

有趣的是，可以使Dynamo风格的复制系统以牺牲性能为代价来满足线性化：读操作在返回结果给应用之前，必须同步执行读修复（参阅第5章“读修复与反熵”）；而写操作在发送结果之前，必须读取quorum节点以获取最新值。然而，由于会显著降低性能， Riak并不支持同步读修复;  Cassandra确实会等待读修复完成，但是，它使用了“最后写入获胜”冲突解决方案，当出现同一个主键的并发写入时，就会丧失线性化（解释：线性化是一种强一致性模型，要求系统能够按照操作的实际发生顺序来顺序地执行所有操作。在线性化系统中，任何给定时间的读操作都应该返回该时间点之前最后一次写操作的结果。当 Cassandra 使用 LWW 来解决冲突时，实际上它是在牺牲线性化保证以换取性能和可用性。因为时间戳是基于每个节点的本地时钟来分配的，所以可能受到时钟漂移或同步问题的影响。这意味着，即使一个写操作实际上是在另一个写操作之后发生的，如果它的时间戳更晚，那么它的结果会被认为是“胜出”的，从而可能会覆盖实际上更“新”的数据。）。

此外， 这种方式只能实现线性化读、 写操作，但无法支持线性化的“比较和设置”操作，后者需要共识算法的支持。总而言之，最安全的假定是类似Dynamo风格的无主复制系统无法保证线性化。

#### **线性化的代价**

由于有一部分复制方案能够保证线性化，而其他则无法保证，因此有必要更加深入地探讨线性化的优缺点。

在第五章我们已经讨论了不同复制方案各自适合的场景。例如，多主复制非常适合多数据中心（参阅第5章“多数据中心操作”）。图 9-7给出了这样的部署例子。

​    ![0](https://note.youdao.com/yws/res/22373/WEBRESOURCE60064980aaae489a8aa5e2457b5614b2)

如果两个数据中心之间发生网络中断，会发生什么情况？我们假设每个数据中心内的网络工作正常，客户端可以到达就近的数据中心，但数据中心之间却无法互连。

基于多主复制的数据库，每个数据中心内都可以继续正常运行：由于从一个数据中心到另一个数据中心的复制是异步，期间发生的写操作都暂存在本地队列，等网络恢复之后再继续同步。

与之对比，如果是主从复制，则主节点肯定位于其中的某一个数据中心。所有写请求和线性化读取都必须发送给主节点，因此，对于那些连接到非主节点所在数据中心的客户端，读写请求都必须通过数据中心之间的网络，同步发送到主节点所在的数据中心。

因此，对于这样的主从复制系统，数据中心之间的网络一旦中断，连接到从数据中心的客户端无法再联系上主节点，也就无法完成任何数据库写入和线性化读取。从节点可以提供读服务，但内容可能是过期的（非线性化保证）。所以，如果应用程序要求线性化读写，则网络中断一定会违背这样的要求。

另一种情况，如果客户端可以直接连接到主节点所在的数据中心，则可以避免此问题。否则，只能等到数据中心之间的网络恢复之后才能继续正常工作。

##### **CAP理论**

不仅仅是主从复制和多主复制才有上面的问题，无论如何实现，任何可线性化的数据库都有这样问题 ： 事实上，这个问题也不局限于多数据中心部署的情况，即使在一个数据中心内部，只要有不可靠的网络 ，都会发生违背线性化的风险。我们可以做以下的权衡考虑:

- 如果应用要求线性化，但由于网络方面的问题，某些副本与其他副本断开连接之后无法继续处理请求，就必须等待网络修复，或者直接返回错误。无论哪种方式，结果是服务不可用 。
- 如果应用不要求线性化，那么断开连接之后，每个副本可独立处理请求例如写操作（多主复制）。此时，服务可用，但结果行为不符合线性化 。

因此，不要求线性化的应用更能容忍网络故障。这种思路通常被称为CAP定理，它由 Eric Brewer于2000年正式命名，但基本想法可追溯到20世纪70年代，很多分布式数据库设计者当时都已经注意到这种现象。

CAP最初是作为一个经验法则而提出的，并没有准确的定义，目的也只是帮助大家深入探讨数据库设计的权衡之道 。 当时，许多分布式数据库仍热衷于在集中共享的存储集群上提供可线性化的语义，而CAP则事实上在鼓励大家去探索无共享系统，后者更适合于大规模的Web服务，拥有更广阔的发展前景。CAP确实值得称赞，正是由于这种思路的转变，我们才见证了2000年以来新型数据库技术爆炸式的增长（可以慨括为NoSQL系统）。

正式定义的CAP定理范围很窄，它只考虑了一种一致性模型（即线性化）和一种故障（网络分区，节点仍处于活动状态但相互断开），而没有考虑网络延迟、节点失败或其他需要折中的情况。因此，尽管CAP在历史上具有重大的影响力，但对于一个具体的系统设计来说，它可能没有太大的实际价值。

分布式系统中还有很多有趣的研究结果，目前CAP已被更精确的研究成果所取代，所以它现在更多的是代表历史上曾经的一个关注热点而已 。

##### **CAP理论是否有用？**

CAP有时也代表一致性，可用性，分区容错性，系统只能支持其中两个特性。 不过 ，这种理解存在误导性， 网络分区是一种故障， 不管喜欢还是不喜欢，它都可能发生，所以无法选择或逃避分区的问题。

在网络正常的时候 ， 系统可以同时保证一致性（线性化）和可用性 。 而一旦发生了网络故障，必须要么选择线性（一致性），要么可用性 。 因此，更准确的称呼应该是“网络分区情况下，选择一致还是可用 ”。 高可靠的网络会帮助减少发生的概率，但无法做到彻底避免。

有必要指出，在CAP的诸多讨论中，术语可用性存在争议，其形式化定理中的可用性与通常意义上的理解有些差别。 许多所谓的“高可用性” （容错）系统实际上并不符合CAP对可用性的特殊定义。总之，围绕着 CAP有太多的误解与困扰，最后反而无法帮助我们史好地理解系统，所以本人建议最好避免使用CAP 。

##### **CAP 理论的重新思考与理解**

来自：极客时间

基于 BASE 理论支撑的 NoSQL 运动坚持创造各种可用性优先、数据一致性其次的方案，而传统数据库则坚守 ACID 特性（原子性、一致性、隔离性、持久性），优先数据一致性，在必要的时候，可以放弃系统可用性。当时 BASE 理论还没有被广泛接受，人们还是不愿意放弃 ACID 的优点。

当 CAP 理论提出后，我们明白了在分布式系统中，只能在强一致性和 100% 的可用性之间二选一，不能两个都要。从此 BASE 理论也逐渐被人们所接受，在大规模存储的场景中广泛应用，并且开创了从 2000 年到 2010 年， NoSQL 运动的黄金十年。这十年里，工业界产生了大量优秀的 NoSQL 系统，比如 BigTable 、 HBase 、 MongoDB 、 Cassandra ，解决了人们当时遇到的大规模数据存储的问题。

**对可用性的重新思考与理解**

关于具体的实践，我认为基于 Raft 算法实现的 etcd 就是一个非常好的，对可用性进行重新思考的实践。如果依据 CAP 理论来划分的话，etcd 属于 CP 模型。

而在 etcd 系统的实现中，如果网络没有出现分区，整个系统是 100% 可用的；就算网络出现分区了，也不会有整个 etcd 系统都不可用的情况。在这时，超过半数 etcd 实例所在的网络分区一侧，系统是正常可用的，虽然网络分区的另一侧是不可用的，但是整个 etcd 系统的可用性依然可能超过 50% 。

**对一致性的重新思考与理解**

对于数据的一致性（ C ） ，除了 CAP 理论要求的强一致性外，还有单调一致性、会话一致性和最终一致性等。如果我们的系统设计选择了 AP 模型，在数据一致性方面，虽然我们无法实现强一致性，但是我们也不要全部放弃，可以努力去实现更高的一致性级别，为系统的服务提供更好的抽象。

这里我们通过一个例子来说明，假设我们设计一个 AP 模型的分布式系统，正常情况下，如果依据 CAP 理论，在系统设计时，我们需要放弃数据的一致性。但是，我们可以从另一个思路来设计，在系统没有出现网络分区的时候，这个分布式系统应该设计为强一致性的。

如果出现网络分区了，我们可以根据系统情况，有选择并且精心设计地降低系统的一致性级别。比如，从强一致性降低到单调一致性或会话一致性等，这样的设计，既符合 CAP 理论依据，也为系统提供了更好的一致性级别，特别是在网络分区的时候。

**对分区容错性的重新思考与理解**

最后，我们来分析一下分区容错性 P 的问题。在分布式系统中，节点之间必须通过网络来通信，可是网络可能会丢包和中断，节点也可能会宕机，这样的情况就要求我们在系统设计的时候，必须做好系统的分区容错处理。

但是，系统出现分区的情况非常少见，所以我们可以来试想一下，在网络不出现分区的时候，我们将数据强一致性和 100% 的可用性都选择，等到网络出现分区的时候，系统再选择放弃部分的可用性或者降低数据一致性的级别，这种处理方式是否可行呢？

其实这样的处理方式是可以的，在上面对可用性和一致性的重新思考与理解中，所举的例子都是按这个方式来处理的，它实际是将 CAP 理论的选择，推迟到出现网络分区的时候，而不是系统一启动就进行 CAP 的选择。这样可以大大提高系统的可用性和数据一致性，并且系统依然能容忍网络分区。

所以对于 CAP 理论的重新思考，总而言之就是一句话：CAP 理论给我们定义了系统的设计边界，虽然想要设计出超过边界的系统是徒劳的，但是我们却可以无限逼近边界，并且把它作为我们设计系统的目标。

##### **可线性化与网络延迟**

虽然线性化是个很有用的保证，但实际上很少有系统真正满足线性化。例如 ，现代多核CPU上的内存甚至就是非线性化： 如果某个CPU核上运行的线程修改一个内存地址，紧接着另一个CPU核上的线程尝试读取，则系统无法保证可以读到刚刚写入的值，除非使用了内存屏障或fence指令。

出现这种现象的原因是每个CPU核都有自己独立的cache和寄存器。内存访问首先进入cache系统，所有修改默认会异步地刷新到主存。由于访问cache比访问主存要快得多，所以这样的异步刷新特性对于现代CPU的性能至关重要。但是，这就导致出现了多个数据副本 (一个在主存，另外几个在不同级别的cache中) ，而副本更新是异步方式，无法保证线性化。

为什么这样呢？首先，CAP理论不适用于当今的多核内存一致性模型：在计算机内部，我们通常假设通信是可靠的，例如我们不会假定一个CPU核在与其他核断开之后还能安然工作。之所以放弃线性化的原因就是性能，而不是为了容错。

许多分布式数据库也是类似，它们选择不支持线性化是为了提高性能，而不是为了保住容错特性。无论是否发生了网络故障，线性化对性能的影响都是巨大的。

那我们是否能找到一个更有效的线性化实现方案呢？目前看来答案是否定的。 Attiya和Welch证明如果想要满足线性化，那么读、写请求的响应时间至少要与网络中延迟成正比。考虑到多数计算机网络高度不确定的网络延迟（参阅第7章“超时与无限延迟”），线性化读写的性能势必非常差。虽然没有足够快的线性化算法，但弱一致性模型的性能则快得多，这种取舍对于延迟敏感的系统非常重要。在第12章，我们将讨论一些避免线性化但又可以确保正确性的方法 。

##### **GPT解释**

Q：线性化与性能

------

为了提高性能和响应速度，许多分布式数据库系统选择放宽一致性的要求，不支持线性一致性（Linearizability），而是采用更弱的一致性模型。

这里是几个原因说明为何分布式数据库可能不支持线性化：

1. 性能开销：

- - 线性化要求系统中的所有操作看起来都是按严格的顺序执行的，这通常需要复杂的协调和同步机制，尤其是在跨数据中心的环境中。
  - 这种同步机制往往引入了额外的网络通信和等待时间，从而导致了明显的性能开销。

1. 可扩展性：

- - 支持线性化可能会限制系统的可扩展性。为了保持一致性，系统可能需要限制并发和分区之间的数据复制，这会影响数据库的吞吐量和可扩展性。

1. 可用性与延迟：

- - 为了实现线性化，系统可能需要等待网络中的所有相关节点同意某个操作，这会增加每个操作的延迟。
  - 如果系统遇到网络分区或节点故障，为了维护线性化，系统可能需要牺牲可用性。

1. 应用需求：

- - 许多实际应用并不需要严格的线性化一致性，它们可以容忍最终一致性或其他弱一致性模型。
  - 弱一致性模型通常能够提供更好的性能和用户体验，尤其是在读多写少的场景中。

因此，为了平衡性能、可用性和一致性，许多分布式数据库（如Cassandra、DynamoDB等）默认提供了弱一致性保证，同时提供了配置选项来允许用户根据业务需求选择不同级别的一致性保障。

同时，也有一些分布式数据库（如Google Spanner、CockroachDB等）选择支持较强的一致性模型，如序列化（Serializability）或线性化。这些系统通常利用额外的机制（如原子时钟、同步协议等）来减少线性化对性能的影响，但通常它们的性能仍然不如那些提供弱一致性保证的系统。

### **顺序保证**

我们之前曾说过，线性化寄存器对外呈现的好像只有一份数据拷贝，而且每一个操作似乎都是原子性生效 。这意味着操作是按照某种顺序执行，如图 9-4 所展示的执行顺序。

顺序是本书反复出现的主题，某种程度也表明它确实是一个非常重要的基本概念。让我们简要回顾一下本书讨论顺序时涉及的前后上下文 ：

- 在第5章，我们看到主从复制系统中主节点的主要作用是确定复制日志中的写入顺序，这样使从节点遵从相同的顺序执行写入。如果没有这样的唯一主节点，则可能由于并发操作而引发冲突（参阅第5章“处理写冲突”）。
- 第7章中讨论的可串行化则是确保事务的执行结果与按照某种顺序方式执行一样。实现方式可以是严格顺序执行 ，或者允许并发但需要相应的冲突解决方案（例如加锁或冲突－中止）。
- 第8章讨论了分布式系统的时间戳与时钟（参阅第 8 章“依赖于同步的时钟”），试图将顺序引入到无序的操作世界，例如确定两个写操作哪一个先发生。

事实证明，排序、可线性化与共识之间存在着某种深刻的联系。尽管这些概念听起来比本书的其他部分更加理论和抽象，但它对于理解系统能做什么和不能做什么非常有帮助。

#### **顺序与因果关系**

之所以反复出现“顺序”问题，其中的一个原因是它有助于保持因果关系。我们已经有好几个这样的例子来反复说明因果关系的重要性 ：

- 在第5章“一致前缀读” （ 见图5-5 ）中，我们看到这样的例子， 一个对话的观察者首先看到了问题的答案接着才是问题本身。这违背了我们对因果的直觉认识，因而感觉困惑：问题之所以被回答， 一定是有问题在先，意味着回答的人一定是先看到了问题（当然，假定他们没有精神问题，也无法预知未来）。此时，问题与回答之间存在因果关系。
- 图 5-9类似， 三个主节点之间进行数据复制，由于网络延迟， 一些写操作会覆盖其他的写入。从某个副本的角度来看，好像是发生了一个对不存在数据行的更新。这里的因果意味着首先必须先创建数据行，然后才能去更新。
- 在第5章“检测并发写”，如果有两个操作A和B ，则它们之间一共有三种可能性： A发生在B之前， B发生在A之前，或者A和B并发。这种“ A发生在B之前”其实是因果关系的另一种表示。如果A发生在B之前，意味着B可能已经知道了A ，或者基于A的操作，或者依赖于A。如果A和B是并发关系，则它们之间不存在因果关系；换言之，互相不知道对方。
- 在事务的快照隔离上下文中（参阅第7章“快照隔离与可重复读”），事务是从一致性快照读取。这里的“一致性”又是什么含义呢？这意味着与因果关系一致 ： 如果快照中包含了答案，则它也必须包含所提的问题。这样才能确保在某个时间点观察数据库时符合因果关系：快照创建时刻点之前的所有数据都要可见，但此后发生的事件则不可见。读倾斜（例如图7-6的不可重复读取）则违反了因果关系因而读到了本不可见的数据。
- 事务之间写倾斜的例子（参阅第7章“写倾斜与幻读”）也说明了因果关系。在图 7-8 中， Alice 申请调班成功是因为事务以为 Bob仍在值班，反之亦然。在这种情况下，调班动作的因果关系取决于当前是谁在值班。可序列化的快照隔离（参阅第7章“可串行化的快照隔离”）主要通过跟踪事务之间的因果依赖关系从而达到检测写倾斜的目的。
- 在Alice和Bob一起看足球的例子中（见图 9-1），当听到 AIice惊呼比分之后，Bob从服务器却得到过期的结果违背了因果关系。 Alice之所以高呼是因为她先看到了最新的比分，因而道理上讲， Bob也应该看到和Alice一样的比分。另一个类似例子则是通过两个通道调整图片大小。

因果关系对所发生的事件施加了某种排序：发送消息先于收到消息; 问题出现在答案之前等， 或者就像在现实生活中一样， 一件事情会导致另一件事情 ： 一个节点根据读取的数据做出决定，然后写入结果，另一个节点读取写入的结果之后再写入新的内容，诸如此类。这些因果关系的依赖链条定义了系统中的因果顺序，即某件事应该发生另一件事情之前。

如果系统服从因果关系所规定的顺序，我们称之为因果一致性。例如，快照隔离提供了因果一致性 ： 当从数据库中读数据时，如果查询到了某些数据， 也一定能看到触发该数据的前序事件（假设期间没有发生删除操作）。

##### **因果顺序并非全序**

全序关系支持任何两个元素之间进行比较，即对于任意两个元素，总是可以指出哪个更大，哪个更小。例如，自然数符合全序关系，随便给出两个数字比如5和13，都可以进行比较。

但是，有些集合并不符合全序，例如集合{a，b}大于集合{b，c}么？因为它们都不是对方的子集，所以无能直接比较它们。我们称之为不可比较，数学集合只能是偏序。某些情况下， 一个集合可以包含另一个，否则则无法比较。

全序和偏序的差异也会体现在不同的数据库一致性模型中 ：

可线性化

在一个可线性化的系统中，存在全序操作关系。系统的行为就好像只有一个数据副本，且每个操作都是原子的，这意味着对于任何两个操作，我们总是可以指出哪个操作在先。这种全序排列序如图9-4中的时间线所示。

因果关系

如果两个操作都没有发生在对方之前， 那么这两个操作是并发关系（参阅第5章“ Happens-before关系与并发”）。换言之，如果两个事件是因果关系（ 一个发生在另一个之前），那么这两个事件可以被排序；而并发的事件则无法排序比较。这表明因果关系至少可以定义为偏序，而非全序。

因此，根据这个定义，在可线性化数据存储中不存在并发操作， 一定有一个时间线将所有操作都全序执行。可能存在多个请求处于等待处理的状态，但是数据存储保证了在特定的时间点执行特定的操作，所以是单个时间轴，单个数据副本，没有并发。

并发意味着时间线会出现分支和合并，而不同分支上的操作无法直接比较。第5章中我们给出了这种例子，如图 5-14并非一条直线式的全序，而是多个不同的操作同时进行。图中的箭头表明这只是因果关系，即部分操作之间的偏序。

如果熟悉像Git这样的分布式版本控制系统，那么它们的版本历史非常类似于因果关系图。通常情况下，提交会以直线形式呈现，但有时会产生分支（特别是多个人同时在一个项目上工作时），当同时有多个提交时就需要进行合并。

**GPT解释==**

Q：解释一下全序和偏序

------

全序（Total Order）和偏序（Partial Order）是数学中关于集合内元素排序的概念，这些概念在计算机科学特别是数据库一致性模型中也有所体现。

**全序（Total Order）**

一个全序关系是指在集合中的每一对元素之间都可以进行比较，可以明确地说出哪个元素先发生，哪个元素后发生。在数据库的可线性化一致性（Linearizability）模型中，操作之间存在全序关系。每个操作都好像在一个全局的、单一的数据副本上执行一样，操作是不可分割的，并且每个操作都能立即反映到每个客户端。这种模型就像是所有操作都按照某种特定的顺序在时间线上排列一样。

**偏序（Partial Order）**

一个偏序关系是指在集合中只有部分元素之间可以进行比较。有些元素之间没有明确的先后顺序，即它们是并发的。在数据库的因果一致性（Causal Consistency）模型中，操作之间存在偏序关系。如果两个操作在不同的进程中，并且没有直接的因果关系，它们可能是并发的，没有明确的先后顺序。但如果一个操作明显导致了另一个操作，那么它们之间就存在因果关系，可以被偏序排序。

例如，考虑两个操作A和B：

- 如果A导致了B，那么我们可以说A在B之前。
- 但如果A和B是并发的，没有直接的因果联系，那么在偏序关系中我们不能说A在B之前，也不能说B在A之前。

在数据库系统中实现不同级别的一致性模型通常会影响系统的性能和复杂性。可线性化要求严格的同步和协调，以确保全序，但这可能会降低系统的并发性和可扩展性。另一方面，因果一致性放松了同步要求，允许更高的并发性，但可能无法保证所有客户端都立即看到最新的更新。

在分布式系统的设计中，开发人员需要根据应用程序的需求和特性选择适当的一致性模型。通常会在性能、一致性和可用性之间进行权衡，这通常被称为CAP定理或PACELC定理。

##### **可线性化强于因果一致性**

那么因果序和可线性化之间是什么关系呢？答案是可线性化一定意味着因果关系 ： 任何可线性化的系统都将正确地保证因果关系。 特别是， 如果系统存在多个通信通道（见图9-5中的消息队列和文件存储服务），可线性化确保了因果关系会自动全部保留，而不需要额外的工作（比如在不同组件之间的传递时间戳）。

可线性化可以确保因果性这一结论，使线性化系统更加简单易懂而富有吸引力。但是，正如在“线性化的代价”将要阐述的，线性化会显著降低性能和可用性，尤其是在严重网络延迟的情况下（例如多数据中心）。 正因如此， 一些分布式数据系统已经放弃了线性化，以换来更好的性能，但也存在可能无法正确工作的风险。

好消息是线性化并非是保证因果关系的唯一途径 ，还有其他方法使得系统可以满足因果一致性而免于线性化所带来的性能问题。事实上，因果一致性可以认为是 ，不会由于网络延迟而显著影响性能，又能对网络故障提供容错的最强的一致性模型。

在许多情况下，许多看似需要线性化的系统实际上真正需要的是因果一致性，后者的实现可以高效很多。基于这样的观察 ，研究人员正在探索新的数据库来保证因果关系，其性能与可用性特征与最终一致性类似。

由于这些研究还处于早期阶段，大多数还没有投入到生产系统 ，也存在其他一些挑战需要克服 。但是，毫无疑问，这是未来非常有希望的方向 。

##### **捕获因果依赖关系**

我们此处不会深入探讨非线性化系统是如何保证因果一致性的细节，而只是简单地介绍一些关键思想。

为保持因果关系，需要知道哪个操作发生在前。这里只需偏序关系，或许并发操作会以任意顺序执行，但如果一个操作发生在另一个操作之前，那么每个副本都应该按照相同的顺序处理。因此，当某个副本在处理一个请求时，必须确保所有因果在前的请求都已完成处理；否则，后面的请求必须等待直到前序操作处理完毕。

为了确定请求的因果依赖关系，我们需要一些手段来描述系统中节点所知道的“知识”。如果节点在写入Y时已经看到X值，则X和Y可能是属于因果关系。这种分析使用了类似针对欺诈指控刑事调查中的推理方法： 某个CEO在做出决定事项Y时是否已经知道了消息X ?

确定请求的先后顺序与第五章“检测并发写”中所讨论的技巧类似。后者针对的是无主复制中的因果关系，该场景需要去检测对同一个主键的并发写请求 ，从而避免更新丢失。因果一致性则要更进一步，它需要跟踪整个数据库请求的因果关系，而不仅仅是针对某个主键。版本向量技术可以推广为一种通用的解决方案。

为了确定因果关系，数据库需要知道应用程序读取的是哪个版本的数据。这就是为什么在图5-13中先前读操作的版本号在提交时要传回到数据库。 SSI的冲突检测也是类似想法，如第7章“可串行化的快照隔离”所介绍的： 当事务提交时，数据库要检查事务曾经读取的数据版本现在是否仍是最新的。为此，数据库需要跟踪事务读取了哪些版本的数据。

#### **序列号排序**

虽然因果关系很重要，但实际上跟踪所有的因果关系不切实际。在许多应用程序中，客户端在写入之前会先读取大量数据，系统无法了解之后的写入究竟是依赖于全部读取内容，还是仅仅是其中一小部分。但很明显， 显式跟踪所有已读数据意味着巨大的运行开销。

这里还有一个更好的方法： 我们可以使用序列号或时间戳来排序事件。时间戳不一定来自墙上时钟（或者物理时钟，但正如第8章所讨论的，物理时钟存在很多问题）。它可以只是一个逻辑时钟，例如采用算法来产生一个数字序列用以识别操作，通常是递增的计数器。

这样的序列号或时间戳非常紧凑（只有几字节的大小），但它们保证了全序关系。也就是说，每一个操作都有唯一的顺序号，并且总是可以通过比较来确定哪个更大（即操作发生在后）。

特别是，我们可以按照与因果关系一致的顺序来创建序列号： 保证如果操作A发生在B之前，那么A一定在全序中出现在B之前 （即A的序列号更小） 。并行操作的序列可能是任意的。这样的全局排序可以捕获所有的因果信息，但也强加了比因果关系更为严格的顺序性。

在主从复制数据库中（参阅第5章 “主节点与从节点”）， 复制日志定义了与因果关系一致的写操作全序关系 。主节点可以简单地为每个操作递增某个计数器，从而为复制日志中的每个操作赋值一个单调递增的序列号。从节点按照复制日志出现的顺序来应用写操作，那结果一定满足因果一致性（虽然从节点的数据可能会滞后于主节点）。

##### **非因果序列发生器**

如果系统不存在这样唯一的主节点（例如可能是多主或者无主类型的数据库，或者数据库本身是分区的），如何产生序列号就不是那么简单了。实践中可以采用以下方法 ：

- 每个节点都独立产生自己的一组序列号。例如，如果有两个节点，则一个节点只生成奇数，而另一个节点只生成偶数。还可以在序列号中保留一些位用于嵌入所属节点的唯一标识符，确保不同的节点永远不会生成相同的序列号。
- 可以把墙上时间戳信息（物理时钟）附加到每个操作上。时间戳可能是不连续的，但是只要它们有足够高的分辨率，就可以用来区分操作。 “最后写获胜”的冲突解决方案也使用类似的方法（参阅第8章“时间戳与事件顺序”） 。
- 可以预先分配序列号的区间范围。例如，节点A负责区间 1～ 1000的序列号，节点B负责 1001 ～2000 。然后每个节点独立地从区间中分配序列号， 当序列号出现紧张时就分配更多的区间。

上述三种思路都可行，相比于把所有请求全部压给唯一的主节点具有更好的扩展性。它们为每个操作生成一个唯一的、近似增加的序列号。不过， 它们也都存在一个问题 ： 所产生的序列号与因果关系并不严格一致。

所有这些序列号发生器都无法保证正确捕获跨节点操作的顺序，因而存在因果关系方面的问题 ：

- 每个节点可能有不同的处理速度，如每秒请求数。因此，某个节点产生偶数而另一个产生奇数，偶数的计数器产生速度可能落后于奇数的计数器，反之亦然。这样就无法准确地知道哪个操作在先。
- 物理时钟的时间戳会受到时钟偏移的影响，也可能导致与实际因果关系不一致。例如图 8-3 ，后来发生的操作实际上被分配了一个较低的时间戳。
- 对于区间分配器， 一个操作可能被赋予从 1001 ～2000之间的某个序列号，而后发生的操作则路由到另一个节点，拿到了某个 1～ 1000之间的序列号，导致与因果序不一致。

##### **Lamport时间戳**

刚才所描述的三个序列号发生器可能与因果关系存在不一致，但还有一个简单的方法可以产生与因果关系一致的序列号。它被称为兰伯特时间戳（ Lamport timestamp) , 由 Leslie Lamport于1978年提出，该文献也是现代分布式系统领域被引用最多的经典论文之一 。

图 9-8 给出了Lamport时间戳的示例。首先每个节点都有一个唯一的标识符，且每个节点都有一个计数器来记录各自已处理的请求总数。 Lamport时间戳是一个值对（计数器，节点ID ）。两个节点可能会有相同的计数器值，但时间戳中还包含节点ID信息，因此可以确保每个时间戳都是唯一的。

​    ![0](https://note.youdao.com/yws/res/22651/WEBRESOURCE34680bed61df76a950a404e408d1581a)

Lamport时间戳与物理墙上时钟并不存在直接对应关系，但它可以保证全序： 给定两个Lamport时间戳，计数器较大那个时间戳大；如计数器值正好相同，则节点ID越大，时间戳越大。(GPT解释：这种时间戳机制很好地解决了分布式系统中的事件排序问题，但它不能解决并发事件的问题。也就是说，如果两个事件的Lamport时间戳相同，我们无法通过时间戳来判断它们的顺序。然而，由于每个事件都有一个唯一的节点ID，我们可以使用节点ID来确定它们的顺序。)

到目前为止，该思路与上一节所描述的奇数／偶数计数器并无本质不同。但是Lamport时间戳的核心亮点在于使它们与因果性保持一致，具体如下所示 ： 每个节点以及每个客户端都跟踪迄今为止所见到的最大计数器值，并在每个请求中附带该最大计数器值。当节点收到某个请求（或者回复）时，如果发现请求内嵌的最大计数器值大于节点自身的计数器值，则它立即把自己的计数器修改为该最大值。

如图 9-8 所示，客户端A从节点2收到计数器值 5 ，然后将最大值5发送到节点 1 。 此时，节点1的计数器仅为 1 ，但是它立即向前跳到 5 ，所以下一个操作将获得计数器值 6 。

只要把最大计数器值嵌入到每一个请求中， 该方案可以确保Lamport时间戳与因果关系一致，而请求的因果依赖性一定会保证后发生的请求得到更大的时间戳。

Lamport时间戳有时会与版本向量发生混淆（第 5章“检测并发写”中介绍了版本向量 ）。虽然存在一些相似之处，但它们的目的不同：版本向量用以区分两个操作是并发还是因果依赖，而Lamport时间戳则主要用于确保全序关系。即使Lamport时间戳与因果序一致，但根据其全序关系却无法区分两个操作属于并发关系，还是因果依赖关系 。 Lamport时间戳优于版本向量之处在于它更加紧凑和高效。

**GPT解释==**

Q：比较Lamport时间戳和版本向量

------

确实，Lamport时间戳和版本向量在许多情况下容易混淆，但它们的设计目的和使用场景是不同的。

**Lamport时间戳：**

Lamport时间戳的设计目的是为了在分布式系统中为所有事件创建一个全序关系。这个全序关系确保了如果事件A在事件B之前发生（按照因果关系），那么事件A的时间戳将小于事件B的时间戳。然而，这种时间戳不足以区分两个事件是否并发。换句话说，如果我们只有两个事件的Lamport时间戳，我们无法确定这些事件是并发发生的还是一个事件实际上导致了另一个事件。

**版本向量：**

版本向量是一种不同的机制，用于跟踪分布式系统中的并发更新。每个节点都有自己的版本号，当节点更新数据或接收到其他节点的更新时，版本号会相应地增加。版本向量使我们能够确定两个事件是因果关系还是并发关系。如果一个事件的版本向量在所有维度上都不小于另一个事件的版本向量，那么我们可以说第一个事件发生在第二个事件之后，或者两个事件有因果关系。如果版本向量无法确定事件的顺序，那么这些事件是并发发生的。

**比较Lamport时间戳和版本向量：**

- 全序 vs 因果关系：Lamport时间戳提供全序，但无法区分并发事件；版本向量则可以区分事件是因果关系还是并发关系，但不提供全序。
- 紧凑性和效率：Lamport时间戳通常比版本向量更紧凑和高效，因为它仅仅是一个(计数器, 节点ID)对。版本向量则需要为系统中的每个节点保存一个计数器，因此在节点数量很多时可能会变得庞大。
- 使用场景：Lamport时间戳适用于需要全序的场景，如排序事件或实现分布式锁。版本向量更适合于需要确定数据副本之间的并发更新和解决冲突的场景，如多版本并发控制（MVCC）。

在分布式系统的设计中，选择正确的工具来跟踪和管理事件顺序至关重要。Lamport时间戳和版本向量都是实现一致性的强大工具，但它们的选择取决于系统的具体需求和保证。

Q：Lamport时间戳为什么无法区分并发事件呢，能举例说明一下吗?

------

Lamport时间戳确实提供了一个全序关系，但这个全序关系只是基于逻辑时间的顺序，并不涉及事件之间的实际因果关系。Lamport时间戳通过单调增加的计数器和消息传递来确保，如果事件A因果地发生在事件B之前，那么事件A的时间戳一定小于事件B的时间戳。

然而，如果两个事件发生在不同的节点上，并且没有消息传递或直接的因果关系，那么它们的Lamport时间戳无法反映这两个事件是否并发。下面是一个例子来说明这一点：

假设我们有两个节点，节点1和节点2：

1. 节点1上发生了事件A，其Lamport时间戳更新为(1, id1)（其中id1是节点1的标识符）。
2. 同时，在节点2上发生了事件B，其Lamport时间戳更新为(1, id2)（其中id2是节点2的标识符）。

由于事件A和事件B在不同的节点上独立发生，并且它们之间没有消息传递，所以我们不能说这两个事件中哪一个发生在另一个之前。但是，如果我们只看Lamport时间戳，我们会发现它们都具有计数器值1，即使它们包含不同的节点ID。在这种情况下，Lamport时间戳无法给我们提供这两个事件是否并发的信息。

如果我们根据节点ID附加规则比较这两个时间戳，我们可能会得出一个在全序中的顺序，比如说，如果id1小于id2，那么事件A的时间戳(1, id1)会被认为是小于事件B的时间戳(1, id2)的，从而在全序中排在事件B之前。但实际上，事件A和事件B是并发发生的，因为它们之间没有因果关系。

所以，虽然Lamport时间戳可以为事件赋予全序，但这个全序并不反映事件是否并发。因果关系和并发性需要通过其他机制（如版本向量）来跟踪。

##### **时间戳排序依然不够**

虽然Lamport时间戳定义了与因果序一致的全序关系，但还不足以解决实际分布式系统中许多常见的问题。

例如， 一个账户系统需要确保用户名唯一标识用户。即两个用户如果同时尝试使用相同的用户名创建账户时，确保其中一个成功，另一个必须失败。

乍看之下，似乎全序关系（例如使用Lamport时间戳）应该可以解决问题 ： 如果有这样并发的操作，则选择时间戳较低的那个作为获胜者（先申请用户名的那个请求），而让时间戳大的请求失败。由于时间戳有序，所以这样的比较方法也应该是可行的。

但是，这种方法确定胜利者有这样一个前提条件：需要收集系统中所有的用户创建请求，然后才可以比较它们的时间戳。然而，当节点刚刚收到用户的创建请求时，它无法当时就做出决定该请求应该成功还是失败。此时，节点根本不知道是否有另一个节点在同时创建相同用户名（以及那个请求所附带的时间戳）。

而为了获得上述两点信息，系统就必须检查每个节点，询问它们在做什么。如果万一某个节点出现故障或者由于网络问题而无法连接，那么方法就无法正常运转。显然这不是我们所期望的容错系统。

这里问题的关键是，只有在收集了所有的请求信息之后，才能清楚这些请求之间的全序关系。 如果另一个节点执行了某些操作，但你无法知道那是什么，就无法构造出最终的请求序列。也许，来自该未知操作确实需要插入到全序集合中才能正确评估出下一步。

总而言之，为了实现像用户名唯一性约束这样的目标，仅仅对操作进行全序排列还是不够的，还需要知道这些操作是否发生、何时确定等。假如能够在创建用户名时，已经确定知道了没有其他节点正在执行相同用户名的创建， 你大可以直接安全返回创建成功。

要想知道什么时候全序关系已经确定就需要之后的“全序关系广播”。

#### **全序关系广播**

如果程序只运行在一个CPU核上，可以非常简单地定义出操作的全序关系，即在单核上执行的顺序。但是，在分布式系统中，让所有的节点就全序关系达成一致就面临巨大挑战。在前面一节中，我们讨论了按时间戳或序列号排序，发现它不如主从复制那么直接有效（如果使用时间戳排序来实现唯一性约束，会丧失容错性）。

如前所述，主从复制首先确定某一个节点作为主节点，然后在主节点上顺序执行操作。接下来的主要挑战在于，如何扩展系统的吞吐量使之突破单一主节点的限制，以及如何处理主节点失效时的故障切换（参阅第5章“处理节点失效”）。在分布式系统研究文献中，这些问题被称为全序关系广播或者原子广播的。

##### **GPT解释**

Q：什么叫全序关系广播

------

全序关系广播（Total Order Broadcast）是分布式系统中一个关键的通信协议，它确保所有节点以相同的全局顺序接收和处理消息。全序关系广播的主要特点是它提供了一种机制，让分布式系统中的所有节点对消息的处理顺序达成一致。

在一个全序关系广播协议中，任意两条消息的发送和接收都遵循以下两个基本属性：

1. 全局顺序：如果节点A在它的本地顺序中先接收到消息M1，后接收到消息M2，那么在系统中的任何其他节点B上，也保证在接收到M2之前，先接收到M1。
2. 可靠性：如果消息M被某个节点接收，则系统中的所有正常运行的节点最终都会接收该消息。

这两个特性确保了即使在面对网络延迟、节点故障和网络分区等问题时，消息的处理顺序依然是一致和确定的，从而保持了系统状态的一致性。全序关系广播是构建一致性算法（如共识算法）和复制系统的基石。常见的实现这一协议的算法包括Paxos、Raft和Viewstamped Replication等。

Q：如何理解这句话“全序关系广播是构建一致性算法（如共识算法）和复制系统的基石。常见的实现这一协议的算法包括Paxos、Raft和Viewstamped Replication等”

------

这里的表述可能会让人产生疑问，让我来澄清一下：

全序关系广播和共识算法之间的关系是相互的，并且在概念上是相互依赖的。

1. 全序关系广播：这是一个系统属性，指的是分布式系统中的所有操作都以全局一致的顺序执行。这是很多分布式系统需要达成的目标，因为它能保证不同节点间的一致性。
2. 共识算法：这是一类算法，它们的目标是在分布式系统中的多个节点间就某项内容（如操作顺序、系统的状态等）达成一致。共识算法是实现全序关系广播的技术手段之一，因为它们能够协调不同节点，以使它们对某个操作序列达成共识。

换句话说，**全序关系广播是一个目标或属性**，而**共识算法是达到这个目标的方法**。Paxos、Raft和Viewstamped Replication等共识算法都提供了达成全序关系广播的机制。通过这些算法，分布式系统能够确保所有节点以相同的顺序提交和执行操作，从而实现全序关系广播的属性。

因此，当我们说全序关系广播是构建一致性算法的基石时，我们指的是它是分布式一致性需要解决的一个基本问题。同时，当我们说共识算法实现全序关系广播时，我们是指这些算法提供了确保操作全局顺序的具体机制。两者是紧密相关的，但表示的是不同的概念层面。

Q：要实现全序关系广播一般的流程是什么

------

实现全序关系广播（Total Order Broadcast）一般需要遵循以下流程：

1. 客户端请求：客户端发送请求到分布式系统中的节点。这个请求可以是一个命令或者要求执行的操作。
2. 领导者选举：共识算法可能需要首先选出一个领导者（Leader）。领导者负责协调请求的处理过程。在某些算法中（如Raft），这个步骤是预先完成的，而在其他算法中（如Paxos），这个步骤可能是按需进行的。
3. 日志条目创建：领导者节点在内部日志中创建一个与请求相对应的新条目。这个日志条目还没有被提交，因此系统其他部分并不知道它。
4. 复制日志条目：领导者将日志条目发送给集群中的其他节点（追随者Follower），请求它们复制这个条目。
5. 追随者确认：追随者节点接收到新的日志条目后，将其写入本地日志，并向领导者发送回执确认。
6. 提交日志条目：一旦领导者从大多数节点收到确认，它将确定这个日志条目可以被提交。这通常涉及到更新领导者本地状态机，并向所有追随者发送提交消息。
7. 应用到状态机：所有的节点（包括领导者和追随者）在日志中提交日志条目后，将其应用到本地状态机。这确保了所有节点以相同的顺序执行相同的操作。
8. 响应客户端：一旦操作被应用到状态机，系统就可以生成一个响应并发送给客户端。这个响应可能包含操作的结果或者确认执行的信号。

通过上述流程，全序关系广播确保了分布式系统中的所有节点以完全相同的顺序执行相同的操作，从而在系统不同副本之间实现一致性。

##### **使用全序关系广播**

像ZooKeeper和etcd这样的共识服务实际上就实现了全序关系广播。这也暗示了全序关系广播与共识之间有着密切联系， 本章稍后会揭示这一点。

全序关系广播正是数据库复制所需要的：如果每条消息代表数据库写请求，并且每个副本都按相同的顺序处理这些写请求，那么所有副本可以保持一致（或许有些滞后）。 该原则也被称为状态机复制，我们将在第11章中详细介绍。

可以使用全序关系广播来实现可串行化事务。如第7章“实际串行执行”所述，如果每条消息表示一个确定性事务并且作为存储过程来执行，且每个节点都遵从相同的执行顺序，那么可以保证数据库各分区以及各副本之间的一致性 。

全序关系广播另一个要点是顺序在发送消息时已经确定，如果消息发送成功，节点不允许追溯地将某条消息插入到先前的某个位置上。这一点使得全序关系广播比基于时间戳排序要求更强。

理解全序关系广播的另一种方式是将其视为日志（如复制日志，事务日志或预写日志）。传递消息就像追加方式更新日志。由于所有节点必须以相同的顺序发送消息，因此所有节点都可以读取日志并看到相同的消息序列。

全序关系广播对于提供fencing令牌的锁服务也很有用（参阅第8章的“Fencing 令牌”）。每个获取锁的请求都作为消息附加到日志中，所有消息按照日志中的顺序依次编号。序列号还可以作为令牌，它符合单调递增要求。在ZooKeeper中， 该序列号被称为 zxid。

##### **采用全序关系广播实现线性化存储**

如图 9-4 所示，在一个可线性化的系统中有全序操作集合。这是否意味着可线性化与全序关系广播是完全相同呢？不完全是，但两者之间有着密切的联系。

全序关系广播是基于异步模型 ：保证消息以固定的顺序可靠地发送 ，但是不保证消息何时发送成功 （因此某个接收者可能明显落后于其他接收者 ） 。 而可线性化则强调就近性：读取时保证能够看到最新的写入值。

如果有了全序关系广播，就可以在其上构建线性化的存储系统。例如，确保用户名唯一标识一个用户。

设想一下，对于每一个可能的用户名，都可以有一个带有原子比较－设置操作的线性化寄存器。每个寄存器初始值为空（表示尚未使用）。当用户创建一个用户名时，对该用户名的寄存器执行比较设置操作： 仅当寄存器值为空时 ，将其设置为新的用户账号。 如果多个用户试图同时获取相同的用户名， 则只有一个原子比较－设置操作成功。

可以通过使用全序关系广播以追加日志的方式来实现线性化的原子比较－设置操作，步骤如下所示 ：

1. 在日志中追加一条消息，并指明想要的用户名。
2. 读取日志 ， 将其广播给所有节点，并等待回复。
3. 检查是否有任何消息声称该用户名已被占用。 如果第一条这样的回复来自于当前节点，那么就成功获得该用户名，可以提交该获取声明（也许附加另一条消息到日志）并返回给客户端 。 反之，如果声称占用的第一条回复消息来自其他节点，则中止操作。

由于日志条目以相同的顺序发送到所有节点，而如果存在多个并发写入， 则所有节点将首先决哪个请求在先。选择第一个写请求作为获胜者，并中止其他请求，以确保所有节点同意一个写请求最终要么提交成功要么中止。类似的方法还可以用来在日志之上实现可串行化的多对象事务。

虽然此过程可确保线性化写入，但它却无法保证线性化读取，即从异步日志更新的存储中读取数据时 ，可能是旧值。 具体来说，这里只提供了顺序一致性，有时也称为时间线一致性，它弱于线性化保证。为了同时满足线性化读取，有以下几个方案 ：

- 可以采用追加的方式把读请求排序、广播，然后各个节点获取该日志，当本节点收到消息时才执行真正的读操作。消息在日志中的位置已经决定了读取发生的时间点。 etcd的quorum读取和这个思路有相似之处。
- 如果可以以线性化的方式获取当前最新日志中消息的位置 ，即查询位置，等待直到该位置之前的所有条目都已经发送给你，接下来再执行读取。这与ZooKeeper的sync()操作思路相同。
- 可以从同步更新的副本上进行读取，这样确保总是读取最新值。这种技术可以用于链式复制，具体参阅第5章的“复制研究” 。

##### **采用线性化存储实现全序关系广播**

前面一节介绍了如何基于全序关系广播来构建线性化的原子比较 －设置操作。我们也可以反过来，假定已有了线性化的存储，在其上构建全序关系广播。

最简单的方法是假设有一个线性化的寄存器来存储一个计数，然后使其支持原子自增－读取操作或者原子比较－设置操作。

算法思路很简单 ： 对于每个要通过全序关系广播的消息，原子递增并读取该线性化的计数，然后将其作为序列号附加到消息中。接下来，将消息广播到所有节点（如果发生丢失， 则重新发送），而接受者也严格按照序列号来发送回复消息。

请注意，与Lamport时间戳不同 ，通过递增线性化寄存器获得的数字不会存在任何间隙。因此，如果节点完成了消息4的发送，且接收到了序列号6的消息，那么在它对消息6回复之前必须等待消息5。 Lamport时间戳则不是这样，而这也是区别全序关系广播与基于时间戳排序的关键。

使用原子自增操作来创建线性化整数有多难呢？答案还是那样，如果不存在失效，就非常容易，甚至可以把它保存在某个节点的内存变量中。难点在于处理节点的网络中断，以及节点失效时如何恢复该值。事实上，如果对线性化的序列号发生器深思熟虑之后所得到的最终结果，往往毫无意外地指向了共识算法。

这并非巧合，可以证明 ，线性化的原子比较－设置（或自增 ） 寄存器与全序关系广播二者都等价于共识问题。 也就是说，如果你能解决其中的一个问题，那么就可以把方案用于解决其他问题。这样的结论是多么的深刻和震撼！

好了，现在终于是时候正面处理共识问题了 ，这是本章剩余部分的重点。

### **分布式事务与共识**

共识问题是分布式计算中最重要也是最基本的问题之一。表面上看，目标只是让几个节点就某件事情达成一致。这似乎很简单，或者至少不应该太难。不幸的是，许多失败的系统正是由于低估了这个问题所导致的。

共识问题既然这么重要，本书已过大半，我们才正式揭开其面纱似乎有点姗姗来迟，这主要是因为共识主题非常之艰深，欣赏其精妙之处需要很多准备知识。即使在学术界，对共识的深刻认识也只是最近几十年才逐渐形成的，中间还纠缠着很多的误解。在探讨了复制（第5章），事务（第7章），系统模型（第8章），线性化和全序关系广播（本章）等问题之后，现在终于完成必要的准备，可以开始直面共识问题了 。

有很多重要的场景都需要集群节点达成某种一致，例如 ：

主节点选举

对于主从复制的数据库，所有节点需要就谁来充当主节点达成一致。如果由于网络故障原因出现节点之间无法通信，就很容易出现争议。 此时 ，共识对于避免错误的故障切换非常重要，后者会导致两个节点都自认为是主节点即脑裂（参阅第5章“处理节点失效”）。如果集群中存在两个这样的主节点，每个都在接受写请求，最终会导致数据产生分歧、不一致甚至数据丢失。

原子事务提交

对于支持跨节点或跨分区事务的数据库，会面临这样的问题 ： 某个事务可能在一些节点上执行成功，但在其他节点却不幸发生了失败。为了维护事务的原子性（即ACID，参阅第7章“原子性”），所有节点必须对事务的结果达成一致：要么全部成功提交（假定没有出错），要么中止／回滚（如果出现了错误）。这个共识的例子被称为原子提交问题。

本节我们将首先详细研究原子提交问题。具体来讲，我们将集中于两阶段提交(2PC)算法，这是解决原子提交最常见的方法，在各种数据库、消息系统和应用服务器中都有实现。事实证明， 2PC是一种共识算法，虽然谈不上多么优秀。

2PC学习之后，我们将继续探索更好的共识算法实现，比如ZooKeeper(Zab)和etcd(Raft)所使用的算法。

#### **原子提交与两阶段提交**

第7章我们了解到事务原子性的目的是，当一个包含多笔写操作的事务在执行过程出现任何意外，原子性可以为上层应用提供非常简单的语义： 事务的结果要么是成功提交（所有事务的写入都是持久的），要么是中止（此时所有事务的写入都被回滚，即撤销或者丢弃）。

原子性可以防止失败的事务破坏系统，避免形成部分成功夹杂着部分失败。这对于多对象事务（参阅第7章“单对象与多对象事务操作”）和维护二级索引格外重要。每个二级索引都有与主数据不同的数据结构，因此 ，如果修改了某些数据， 则相应的二级索引也需要随之更新。原子性可以确保二级索引与主数据总是保持一致（如果发生了不一致，那么索引的作用将会大打折扣）。

##### **从单节点到分布式的原子提交**

对于在单个数据库节点上执行的事务，原子性通常由存储引擎来负责。当客户端请求数据库节点提交事务时，数据库首先使事务的写入持久化（通常保存在预写日志中，请参阅第3章“可靠的B-tree”），然后把提交记录追加写入到磁盘的日志文件中 。 如果数据库在该过程中间发生了崩溃，那么当节点重启后， 事务可以从日志中恢复： 如果在崩溃之前提交记录已成功写入磁盘，则认为事务已安全提交； 否则，回滚该事务的所有写入。

因此，在单节点上，事务提交非常依赖于数据持久写入磁盘的顺序关系：先写入数据，然后再提交记录。 事务提交（或中止）的关键点在于磁盘完成日志记录的时刻：在完成日志记录写之前如果发生了崩溃，则事务需要中止；如果在日志写入完成之后，即使发生崩溃，事务也被安全提交。这就是在单一设备上实现原子提交的核心思路。

但是，如果一个事务涉及多个节点呢？例如，一个分区数据库中多对象事务，或者是基于词条分区的二级索引（其中索引条目可能位于与主数据不同的节点上， 请参阅第6章“分区与二级索引” ）。虽然大多数NoSQL分布式数据都不支持这样的分布式事务，但有很多集群关系型数据库则支持（参阅本章后面“实践中的分布式事务”）。

向所有节点简单地发送一个提交请求，然后各个节点独立执行事务提交是绝对不够的。这样做很容易发生部分节点提交成功，而其他一些节点发生失败，从而违反了原子性保证 ：

- 某些节点可能会检测到违反约束或有冲突，因而决定中止，而其他节点则可能成功提交。
- 某些提交请求可能在网络中丢失，最终由于超时而中止，而其他提交请求则顺利通过。
- 某些节点可能在日志记录写入之前发生崩溃，然后在恢复时回滚，而其他节点则成功提交。

如果一部分节点提交了事务，而其他节点却放弃了事务，节点之间就会变得不一致（见图 7-3）。而且某个节点一旦提交了事务，即使事后发现其他节点发生中止，它也无法再撤销已提交的事务。正因如此，如果有部分节点提交了事务，则所有节点也必须跟着提交事务。

事务提交不可撤销，不能事后再改变主意（在提交之后再追溯去中止）。这些规则背后的深层原因是， 一旦数据提交，就被其他事务可见，继而其他客户端会基于此做出相应的决策。这个原则构成了读－提交隔离级别的基础（参阅第7章“读提交”）。如果允许事务在提交后还能中止，会违背之后所有读－提交的事务，进而被迫产生级联式的追溯和撤销。

当然已提交事务的效果可以被之后一笔新的事务来抵消掉，即补偿性事务。不过，从数据库的角度来看，前后两个事务完全互相独立。 类似这种跨事务的正确性需要由应用层来负责。

##### **两阶段提交**

两阶段提交 (two-phase commit, 2PC) 是一种在多节点之间实现事务原子提交的算法，用来确保所有节点要么全部提交，要么全部中止。它是分布式数据库中的经典算法之一。2PC在某些数据库内部使用，或者以XA事务形式 (例如Java TransactionAPI)或SOAP Web服务WS-AtomicTransaction的形式提供给应用程序。

2PC的基本流程如图9-9所示。不同于单节点上的请求提交，2PC中的提交/中止过程分为两个阶段(因此得名2PC)。

​    ![0](https://note.youdao.com/yws/res/22989/WEBRESOURCEfbf224ca0c063e5b404947bec3bd2779)

2PC引入了单节点事务所没有的一个新组件: 协调者 (也称为事务管理器)。这是分布式事务中的关键角色。在一个单节点事务中，事务的管理通常是由数据库内部的事务管理器负责的，而在分布式事务中，需要跨多个节点协调事务，这就需要一个额外的组件来完成这项工作。

通常，2PC事务从应用程序在多个数据库节点上执行数据读/写开始。我们将这些数据库节点称为事务中的参与者。当应用程序准备提交事务时，协调者开始阶段1: 发送一个准备请求到所有节点，询问他们是否可以提交。协调者然后跟踪参与者的回应:

- 如果所有参与者回答“是”，表示他们已准备好提交，那么协调者接下来在阶段2会发出提交请求，提交开始实际执行。
- 如果有任何参与者回复 “否”，则协调者在阶段2中向所有节点发送放弃请求。

这个过程有点像西方传统的婚姻仪式 ： 主持人会询问新郎和新娘是否愿意与对方结为夫妇，通常双方都会回答“我愿意”，在确认之后和所有与会者共同见证下，方可宣布完成了婚姻承诺。而万一新郎或者新娘没有肯定回复，理论上仪式应该中止。

**GPT解释==**

Q：协调者的作用

------

协调者的角色和职责：

1. 发起事务：协调者开始一个新的事务，并通知所有参与节点（参与者 Participant）准备执行事务操作。
2. 收集投票：在第一阶段，协调者向所有参与者发送“准备”请求，并等待它们的响应。参与者执行事务指令，写入日志，然后投票是否“准备好”提交事务。
3. 决定事务命运：在第二阶段，协调者根据参与者的投票决定事务是提交还是中止。如果所有参与者都报告准备好，协调者将决定提交事务；如果任一参与者无法准备好，协调者将决定中止事务。
4. 发送最终指令：协调者向所有参与者发送最终决定（提交或中止）。
5. 处理失败和恢复：协调者在整个过程中也负责处理参与者失败的情况，并在参与者恢复时协助它们完成事务的提交或中止。

二阶段提交的两个阶段：

- 第一阶段（准备阶段）：协调者询问参与者是否可以安全地提交事务，并等待所有参与者的答复。每个参与者都会将事务操作记录到日志中，以便在系统崩溃后能够恢复状态。
- 第二阶段（提交/中止阶段）：如果所有参与者都同意提交事务，协调者发送提交请求；如果有任何参与者拒绝提交，或者协调者在超时后没有接收到所有响应，协调者发送中止请求。

二阶段提交协议通过引入协调者组件来确保分布式系统中事务的一致性和原子性，不管事务是否跨多个数据库、应用或资源。然而，2PC协议也带来了性能和可用性的挑战，比如协调者或参与者的单点故障可能导致事务长时间锁定资源，影响系统的整体性能。因此，设计和实现2PC时需要仔细考虑这些因素。

##### **系统的承诺**

只从上面简单的描述可能还是不清楚为什么两阶段提交可以确保跨节点的原子性，而单一提交却做不到。试想，即使对于2PC ，准备和提交请求也一样可能发生丢失，那么2PC究竟为何不同？

为了理解其工作原理 ，我们来更详细地分解这个过程：

1. 当应用程序启动一个分布式事务时 ，它首先向协调者请求事务 ID 。该ID全局唯一。
2. 应用程序在每个参与节点上执行单节点事务，并将全局唯一事务 ID附加到事务上。此时，读写都是在单节点内完成。如果在这个阶段出现问题（例如节点崩溃或请求超时），则协调者和其他参与者都可以安全中止。
3. 当应用程序准备提交时 ，协调者向所有参与者发送准备请求 ，并附带全局事务ID 。如果准备请求有任何一个发生失败或者超时，则协调者会通知所有参与者放弃事务。
4. 参与者在收到准备请求之后，确保在任何情况下都可以提交事务，包括安全地将事务数据写入磁盘（不能以任何借口稍后拒绝提交，包括系统崩溃，电源故障或磁盘空间不足等），并检查是否存在冲突或约束违规。一旦向协调者回答“是”，节点就承诺会提交事务。换句话说，尽管还没有真正提交，但参与者已表态此后不会行使放弃事务的权利。
5. 当协调者收到所有准备请求的答复时，就是否提交（或放弃） 事务要做出明确的决定（即只有所有参与者都投赞成票时才会提交）。协调者把最后的决定写入到磁盘的事务日志中，防止稍后系统崩溃，并可以恢复之前的决定。这个时刻称为提交点。
6. 协调者的决定写入磁盘之后，接下来向所有参与者发送提交（或放弃）请求。 如果此请求出现失败或超时，则协调者必须一直重试， 直到成功为止。此时，所有节点不允许有任何反悔：开弓没有回头箭， 一旦做了决定，就必须贯彻执行，即使需要很多次重试。而如果有参与者在此期间出现故障，在其恢复之后，也必须继续执行。这是因为之前参与者都投票选择了“是” ， 对于做出的承诺同样没有反悔的余地。

由此可见，该协议有两个关键的“不归路”：首先，当参与者投票“是”时，它做出了肯定提交的承诺（尽管还取决于其他的参与者的投票，协调者才能做出最后决定）。其次，协调者做出了提交（或者放弃）的决定，这个决定也是不可撤销。正是这两个承诺确保了2PC的原子性（而单节点原子提交其实是将两个事件合二为一 ，写入事务日志即提交） 。

##### **协调者发生故障**

如果参与者或者网络在2PC期间发生失败，例如在第一阶段，任何一个准备请求发生了失败或者超时 ，那么协调者就会决定中止交易； 或者在第二阶段发生提交（或中止）请求失败，则协调者将无限期重试。但是，如果协调者本身发生了故障，接下来会发生什么现在还不太清楚。

如果协调者在发送准备请求之前就已失败，则参与者可以安全地中止交易。但是， 一旦参与者收到了准备请求并做了投票“是”，则参与者不能单方面放弃，它必须等待协调者的决定。如果在决定到达之前，出现协调者崩溃或网络故障，则参与者只能无奈等待。此时参与者处在一种不确定的状态。

情况如图 9-10 所示。在该例子中，协调者实际上做出了提交决定，数据库2已经收到了提交请求。但是，协调者在将提交请求发送到数据库1之前发生了崩溃，因此数据库1不知道该提交还是中止。超时机制也无法解决问题：如果超时之后数据库1决定单方面中止，最终将与完成提交的数据库2产生不一致。同理，参与者也不能单方面决定提交，因为可能有些参与者投了否决票导致协调者最终的决定是放弃。

没有协调者的消息，参与者无法知道下一步的行动（是提交还是放弃）。理论上，参与者之间可以互相通信，通过了解每个参与者的投票情况并最终达成一致，不过这已经不是2PC协议的范畴了。

​    ![0](https://note.youdao.com/yws/res/23010/WEBRESOURCEae412ce075b2f88a1cc9f1958af1903c)

2PC能够顺利完成的唯一方法是等待协调者恢复。这就是为什么协调者必须在向参与者发送提交（或中止）请求之前要将决定写入磁盘的事务日志： 等协调者恢复之后 ，通过读取事务日志来确定所有未决的事务状态。 如果在协调者日志中没有完成提交记录就会中止。 此时 ， 2PC的提交点现在归结为协调者在常规单节点上的原子提交。

##### **三阶段提交**

两阶段提交也被称为阻塞式原子提交协议，因为2PC可能在等待协调者恢复时卡住。理论上，可以使其改进为非阻塞式从而避免这种情况。但是，实践中要想做到这一点并不容易。

作为2PC的替代方案，目前也有三阶段提交算法 。然而， 3PC假定一个有界的网络延迟和节点在规定时间内响应。考虑到目前大多数具有无限网络延迟和进程暂停的实际情况（见第8章），它无法保证原子性 。

通常，非阻塞原子提交依赖于一个完美的故障检测器，即有一个非常可靠的机制可以判断出节点是否已经崩溃。在无限延迟的网络环境中，超时机制并不是可靠的故障检测器 ，因为即使节点正常，请求也可能由于网络问题而最终超时。正是由于这样的原因，尽管大家已经意识到上述协调者潜在的问题，但还在普遍使用2PC 。

#### **实践中的分布式事务**

分布式事务，尤其是那些通过两阶段提交所实现的事务，声誉混杂。 一方面，它们被看作是提供了一个其他方案难以企及的重要的安全保证 ；但另一方面， 他们由于操作上的缺陷、性能问题、承诺不可靠等问题而遭受诟病。 目前，许多云服务提供商由于运维方面的问题而决定不支持分布式事务。

分布式事务的某些实现存在严重的性能问题。例如，有报告显示MySQL的分布式事务比单节点事务慢10倍以上，所以不建议使用也就不足为奇了。两阶段提交性能下降的主要原因是为了防崩溃恢复而做的磁盘I/O (fsync) 以及额外的网络往返开销。

但是，我们不应该就这么直接地抛弃分布式事务，而应该更加审慎的对待，从中获取一些重要的经验教训。首先，我们还是要明确“分布式事务”的确切含义。目前由两种截然不同的分布式事务概念 ：

数据库内部的分布式事务

某些分布式数据库（例如那些标配支持复制和分区的数据库）支持跨数据库节点的内部事务。例如，VoltDB和MySQL Cluster的NDB存储引擎就支持这样的内部分布式事务。此时，所有参与节点都运行着相同的数据库软件。

异构分布式事务

在异构分布式事务中，存在两种或两种以上不同的参与者实现技术。例如来自不同供应商的数据库，甚至是非数据库系统（如消息中间件）。即使是完全不同的系统，跨系统的分布式事务业必须确保原子提交。

数据库内部事务由于不必考虑与其他系统的兼容，因此可以使用任何形式的内部协议并采取有针对性的优化。因此，数据库内部的分布式事务往往可行且工作不错，但异构环境的事务则充满了挑战。

##### **Exactly-once消息处理**

这段感觉没有什么意思

##### **XA交易**

X/Open XA (eXtended Architecture, XA ）是异构环境下实施两阶段提交的一个工业标准，于1991年推出并得到广泛推广 。目前，许多传统关系数据库（包括PostgreSQL、MySQL、DB2、SQL Server和Oracle ）和消息队列（包括ActiveMQ 、HornetQ 、 MSMQ和IBM MQ ）都支持XA 。XA并不是一个网络协议，而是一个与事务协调者进行通信的C API。

省略后面书籍的说明，直接看下面GPT的解释吧

**GPT解释==**

Q：介绍一下XA

------

X/Open XA 是一组定义了如何在异构系统中实现两阶段提交（2PC）的标准。它允许多个资源管理器（例如关系数据库、消息队列等）在全局事务管理器（事务协调者）的控制下协同工作。

**XA的工作原理：**

1. 全局事务管理器：这是负责协调整个分布式事务的组件。它通常是一个事务处理监控器或应用服务器。
2. 资源管理器：这些是管理诸如数据库或消息队列等资源的系统。它们与全局事务管理器通信以参与分布式事务。
3. XA接口：这是定义了一系列函数的API，资源管理器使用这些函数来参与全局事务管理器控制的事务。

**XA接口的关键函数：**

- xa_start：标记事务的开始。
- xa_end：标记事务的结束。
- xa_prepare：准备提交事务的阶段，资源管理器在此阶段表示它已准备好提交。
- xa_commit：实际提交事务的阶段。
- xa_rollback：如果事务无法提交，则回滚事务。

这个接口允许资源管理器正确地参与到两阶段提交的各个阶段中，确保全局事务的一致性。

**XA标准的优点：**

- 异构系统的事务一致性：XA允许不同类型的系统参与到相同的事务中，提供跨多个资源的事务一致性。
- 广泛支持：许多流行的数据库和消息队列系统支持XA标准，这使得它成为业界广泛使用的解决方案。
- 标准化：作为一个行业标准，它提供了一致的方法来实现分布式事务。

**XA标准的挑战：**

- 性能影响：两阶段提交协议可能会导致性能下降，因为它需要额外的通信和磁盘IO操作。
- 复杂性：实现和维护XA事务需要额外的逻辑和错误处理。
- 锁定资源：在事务的持续时间内，资源可能被锁定，这可能影响系统的并发性。

尽管有挑战，XA标准仍然是许多企业在需要确保跨多种存储和处理系统的事务一致性时的首选解决方案。它的广泛支持和行业认可使得它成为对异构系统进行事务管理的可靠方式。然而，随着微服务和云原生架构的兴起，许多组织开始探索基于最终一致性的替代分布式事务模型，如Saga模式，这种模型通常在分布式系统中更具伸缩性和鲁棒性。

##### **停顿时仍持有锁**

为什么我们非常关注陷入停顿的参与者节点（即不确定该提交还是中止）呢？难道系统不能选择忽略（并最终清理）这些节点，这样系统不就可以继续工作么？

问题的关键在于锁。正如第7章“读－提交”所讨论的，数据库事务通常持有待修改行的行级独占锁，用以防止脏写。此外，如果要使用可串行化的隔离，则两阶段锁的数据库还会对事务曾经读取的行持有读－共享锁（参阅第7章“两阶段加锁”）。

在事务提交（或中止）之前，数据库都不会释放这些锁（图 9-9 中的阴影区域所示）。因此，在两阶段提交时， 事务在整个停顿期间一直持有锁。换句话说，如果协调者崩溃并且需要20分钟才能重启恢复，那么这些对象将被锁定20分钟；如果协调者的日志由于某种原因而彻底丢失，这些数据对象将永久处于加锁状态，至少管理员采用手动方式解决之前只能如此。

数据处于加锁时，其他事务就无能执行修改。取决于数据库的具体实现，其他事务甚至无法读取这些行。因此，其他的事务事实上无能有效执行。这可能会导致很多上层应用基本处于不可用状态，所以必须解决处于停顿状态的那些事务。

##### **从协调者故障中恢复**

理论上，如果协调者崩溃之后重新启动， 它应该可以从日志中恢复那些停顿的事务。然而，在实践中，孤立的不确定事务确实会发生。无论何种原因，例如由于软件bug导致交易日志丢失或者损坏，最终协调者还是出现了恢复失败。那些悬而未决的事务无法自动解决，而是永远留在那里，而且还持有锁并阻止其他事务。

即使重启那些处于停顿状态的数据库节点也无法解决这个问题，这是由于2PC的正确实现要求即使发生了重启，也要继续保持重启之前事务的加锁（否则就会违背原子性保证）。所以，这的确非常棘手。

唯一的出路只能是让管理员手动决定究竟是执行提交还是回滚。管理员必须仔细检查每个有问题的参与者，确定是否有节点已经事实完成了提交（或中止），然后要将相同的结果一一应用于所有的参与者上。这种方案可能需要大量的手工操作 ，而且很可能处在关键生产环境的中断间隙，背负着巨大的压力和时间限制（要不然，为什么协调者容易出现这种问题）。

许多XA的实现都支持某种紧急避险措施称之为启发式决策：这样参与者节点可以在紧急情况下单方面做出决定，放弃或者继续那些停顿的事务，而不需要等到协调者发出指令。需要说明的是，这里的启发式其实是可能破坏原子性的委婉说法，它的确违背了两阶段提交所做出的承诺。因此，这种启发式决策只是为了应急，不能作为常规手段来使用。

##### **分布式事务的限制**

XA事务解决了多个参与者之间如何达成一致这样一个非常现实而重要的问题，但正如上面所看到的，它也引入了不少操作方面的限制。特别是，核心的事务协调者本身就是一种数据库 （存储事务的投票结果 ）， 因此需要和其他重要的数据库一样格外小心:

- 如果协调者不支持数据复制，而是在单节点上运行，那么它就是整个系统的单点故障（因为它的故障导致了很多应用阻塞在停顿事务所持有的锁上）。而现实情况是，有许多协调者的实现默认情况下并非高可用，或者只支持最基本的复制。
- 许多服务器端应用程序都倾向于无状态模式（因为更受HTTP的青睐），而所有的持久状态都保存在数据库中，这样应用服务器可以轻松地添加或删除实例。但是，当协调者就是应用服务器的一部分时，部署方式就发生了根本的变化。突然间，协调者的日志成为可靠系统的重要组成部分，它要求与数据库本身一样重要（需要协调者日志恢复那些有疑问的事务）。这样的应用服务器已经不再是无状态。
- 由于XA需要与各种数据系统保持兼容 ，它最终其实是多系统可兼容的最低标准。例如，它无法深入检测不同系统之间的死锁条件（因为这就将需要另一个标准化协议，使得多个系统交换事务所等待的锁信息），而且不适用干SSI（参阅第7章“可串行化的快照隔离”），后者要求一个复杂的协议来识别不同系统间的写冲突。
- 对于数据库内部的分布式事务（而不是XA ），限制则少很多，例如SSI的分布式版本是可行的 。然而， 2PC要成功提交事务还是存在潜在的限制，它要求必须所有参与者都投票赞成，如果有任何部分发生故障，整个事务只能失败。所以分布式事务有扩大事务失败的风险，这与我们构建容错系统的目标有些背道而驰。

这是否意味着我们应该放弃保持多个系统一致的希望呢？不完全是， 还有其他的方法可以实现这一目标且无需担心异构分布式事务的这些负面影响， 具体将在第11章和第12章呈现。现在，我们应该可以总结一下共识问题。

#### **支持容错的共识**

通俗理解，共识是让几个节点就某项提议达成一致。例如，多个人同时尝试预订飞机的最后一个座位或剧院中的同一座位，或者尝试使用相同的用户名注册账户，此时可以用共识算法来决定这些不相容的操作之中谁是获胜者。

共识问题通常形式化描述如下： 一个或多个节点可以提议某些值，由共识算法来决定最终值。 对于预约座位的例子，当多个顾客同时试图购买最后一个座位时，处理顾客请求的每个节点可以提议它所服务的顾客ID，最后的决定则是关于由哪个顾客获得座位。

在这个描述中，共识算法必须满足以下性质:

协商一致性（Uniform agreement)

所有的节点都接受相同的决议。

诚实性（Integrity)

所有节点不能反悔， 即对一项提议不能有两次决定。

合法性（Validity)

如果决定了值v ， 则v一定是由某个节点所提议的。

可终止性（Termination)

节点如果不崩溃则最终一定可以达成决议。

协商一致性和诚实性属性定义了共识的核心思想：决定一致的结果， 一旦决定，就不能改变 。有效性(合法性)属性主要是为了排除一些无意义的方案 ： 例如， 无论什么建议，都可以有一个总是为空（ NULL ）的决定，虽然可以满足一致性和诚实性，但没有任何实际效果。

如果不关心容错，那么满足前三个属性很容易：可以强行指定某个节点为“独裁者”，由它做出所有的决定。但是，如果该节点失败，系统就无法继续做出任何决定。其实这就是在两阶段提交时所看到的： 如果协调者失败了，那些处于不确定状态的参与者就无从知道下一步该做什么。

可终止性则引入了容错的思想。它重点强调一个共识算法不能原地空转，永远不做事情，换句话说，它必须取得实质性进展。即使某些节点出现了故障，其他节点也必须最终做出决定。可终止性属于一种活性，而另外三种则属于安全性方面的属性（参阅第8章“安全性与活性”）。

上述共识的系统模型假定当某个节点发生崩溃后，节点就彻底消失，永远不再回来。可以这样设想，这不是由于软件错误，而是遭遇了地震，整个数据中心包括所有节点被山体滑坡所摧毁，所以必须假设节点已经深埋于30英尺下的瓦砾之中，不可能重新上线。在这样的系统模型下，所有采取等待节点恢复的算法都无法满足终止性，特别是2PC不符合可终止性要求。

当然，如果所有的节点都崩溃了，那么无论何种算法都不可能继续做出决定。算法所能够容忍的失败次数和规模都有一定的限制。事实上，可以证明任何共识算法都需要至少大部分节点正确运行才能确保终止性。而这个多数就可以安全地构成quorum（参阅第5章“读写 quorum" ）。

因此，可终止性的前提是，发生崩溃或者不可用的节点数必须小于半数节点。即使是多数节点出现了故障或者存在严重的网络问题，现在有很多实现的共识系统也可以满足安全属性： 协商一致性，诚实性和合法性。 所以大规模的失效情况可能会导致系统无法处理请求，但不会破坏系统做出无效的决定。

大多数共识算法都假定系统不存在拜占庭式错误 。 对于 “拜占庭式错误” （参阅第8章），即节点没有遵循协议（例如故意发送相互矛盾的消息），从而破坏协议的安全属性。研究表明，只要发生拜占庭故障的节点数小于三分之一，也可以达成共识。不过篇幅所限，我们无法就此展开细节讨论。

##### **共识算法与全序广播**

最著名的容错式共识算法包括VSR, Paxos, Raft和Zab。这些算法存在诸多相似之处，但又不完全相同。篇幅所限，本书无法详细介绍这些算法，除非你决定要自己实现一套这样的共识系统(这可能是非常不明智的做法，极具失败的可能)，否则只需了解它们共同的设计思想就足够了。

这些算法大部分其实并不是直接使用上述的形式化模型（提议并决定某个值，同时满足上面4个属性）。

全序关系广播的要点是，消息按照相同的顺序发送到所有节点。 如果仔细想想，这其实相当于进行了多轮的共识过程： 在每一轮，节点提出他们接下来想要发送的消息，然后决定下一个消息的全局顺序。

所以，全序关系广播相当于持续的多轮共识（每一轮共识的决定对应于一条消息）

- 由于协商一致性，所有节点决定以相同的顺序发送相同的悄息。
- 由于诚实性，消息不能重复。
- 由于合法性，消息不会被破坏， 也不是凭空捏造的。
- 由于可终止性，消息不会丢失。

VSR 、 Raft和Zab都采取了全序关系广播，这比重复性的一轮共识只解决一个提议更加高效。而Paxos 则有对应的优化版本称之为Multi -Paxos 。

**GPT解释**

Q：

------

这些算法通常不是一次性决定一个单一的值，而是持续地就一系列的值达成共识，从而实现全序关系广播（全局顺序的消息传递）。实际上，这就像是在进行多轮共识过程：

- 在每一轮中，节点提议它们想要发送的消息。
- 然后，通过共识算法决定下一个消息在全序中的位置。
- 这样，所有节点都能以相同的顺序处理消息，从而保证了状态的一致性。

全序关系广播对于很多分布式系统（如数据库、分布式日志服务、状态机复制等）来说非常重要，因为它确保了所有操作的顺序性和一致性。在系统设计中，通常建议使用现成的、经过良好测试的共识库或服务，如 Etcd（利用Raft算法）、Consul（利用Raft算法）或 Apache ZooKeeper（使用Zab算法），而不是自己从头实现共识算法。这是因为实现一个正确无误、性能良好且容错性高的共识系统非常复杂，需要克服诸多挑战，并且需要经过严格的测试和验证。

##### **主从复制与共识**

第5章讨论了主从复制 （参阅第5章“主节点与从节点”），所有的写入操作都由主节点负责，并以相同的顺序发送到从节点来保持副本更新。这不就是基本的全序关系广播么？那在主从复制时我们怎么没有考虑共识问题呢？

答案取决于如何选择主节点。如果主节点是由运营人员手动选择和配置的，那基本上就是一个独裁性质的 “一致性算法” ： 只允许一个节点接受写入（并决定复制日志中的写入顺序），如果该节点发生故障，系统将无法写入，直到操作人员再手动配置新的节点成为主节点。这样的方案也能在实践中很好地发挥作用，但它需要人为干预才能取得进展，不满足共识的可终止性。

一些数据库支持自动选举主节点和故障切换，通过选举把某个从节点者提升为新的主节点（参阅第5章“处理节点失效”）。这样更接近容错式全序关系广播，从而达成共识。

但是，还有一个问题，我们之前曾讨论过脑裂 ： 所有的节点都需要同意主节点，否则两个主节点会导致数据库出现不一致。因此 ，我们需要共识算法选出一位主节点。但是，如果这里描述的共识算法实际上是全序关系广播，且全序关系广播很像主从复制，但主从复制现在又需要选举主节点。

看起来要选举一个新的主节点，我们首先需要有一个主节点。要解决共识，必须先处理共识。怎么摆脱这样一个奇怪的循环？

GPT解释

Q：

------

您提出了一个有趣的问题，涉及到主从复制和共识算法在分布式系统中的交互和相互依赖。确实，主从复制可以看作是一种简化的全序关系广播，因为主节点负责决定操作的全局顺序并将其广播给从节点。这里的共识问题主要集中在如何选择主节点。

在手动选择主节点的情况下，共识算法的确不是必需的，因为人为地确定了只有一个节点可以接受写入。这种情况下，共识的终止性取决于人工干预，而不是算法本身。

当我们引入自动主节点选举时，情况变得更加复杂。在这个过程中，节点必须就谁应该成为新的主节点达成共识。如果没有共识算法，可能会出现脑裂（split-brain）现象，即多个节点都认为自己是主节点，导致数据不一致。

为了解决这个问题，我们使用共识算法（如Paxos、Raft等），让节点之间就一个新的主节点达成一致。然而，如您所指出的，这似乎形成了一个循环：要选举一个新的主节点（共识），我们似乎需要一个主节点来处理共识。

这个问题的解决方案在于共识算法的工作机制：

1. 分阶段操作：共识算法（如Paxos或Raft）通常是分阶段的，并不需要一个永久的主节点来协调所有操作。在Paxos中，任何节点都可以提出提案，并且只要大多数节点接受该提案，提案就会被选为新的值。在Raft中，节点通过选举产生一个临时的领导者，该领导者在任期内协调共识过程。
2. 独立于主从复制：共识算法可以独立于主从复制工作。它们的目的是在集群中的所有节点间达成一致的决策，而不是管理数据的复制。一旦一个新的主节点被共识选举出来，主从复制协议就会开始工作，新的主节点将负责调度数据的复制。
3. 解耦共识和复制：在很多现代分布式数据存储系统中，共识和复制是两个解耦的组件。共识组件负责选举和领导者更替，而复制组件负责数据的一致性复制。

总之，尽管共识和主从复制似乎存在循环依赖，但实际上它们是可以解耦的。共识算法确保了即使在没有永久主节点的情况下也能够在分布式环境中做出一致的决策，而主从复制则确保了一旦主节点被选举出来之后，数据的一致性可以在整个集群中得到保持。

##### **Epoch和Quorum**

目前所讨论的所有共识协议在其内部都使用了某种形式的主节点，虽然主节点并不是固定的。相反，他们都采用了一种弱化的保证:  协议定义了一个世代编号 (epoch number，对应于Paxos中的ballot number，VSP中view number，以及Raft中的term number) ，并保证在每个世代里，主节点是唯一确定的。

如果发现当前的主节点失效，节点就开始一轮投票选举新的主节点 。 选举会赋予一个单调递增的epoch号。如果出现了两个不同的主节点对应于不同 epoch号码（例如，上一个epoch号码的主节点其实并没有真正挂掉)，则具有更高epoch号码的主节点将获胜。

在主节点做出任何决定之前，它必须首先检查是否存在比它更高的epoch号码，否则就会产生冲突的决定。主节点如何知道它是否已被其他节点所取代了呢？还记得上一章“真理由多数决定”么？节点不能依靠自己所掌握的信息来决策，例如自认为是主节点并不代表其他节点都接受了它的“自认为”。

相反，它必须从quorum节点中收集投票（参阅第5章“读写quorum" ）。主节点如果想要做出某个决定，须将提议发送给其他所有节点，等待quorum节点的响应。quorum通常（但不总是）由多数节点组成。并且，只有当没有发现更高epoch主节点存在时，节点才会对当前的提议（带有epoch号码）进行投票。

因此，这里面实际存在两轮不同的投票：首先是投票决定谁是主节点，然后是对主节点的提议进行投票。其中的关键一点是，参与两轮的quorum必须有重叠：如果某个提议获得通过，那么其中参与投票的节点中必须至少有一个也参加了最近一次的主节点选举。换言之，如果在针对提议的投票中没有出现更高epoch号码，那么可以得出这样的结论: 因为没有发生更高epoch的主节点选举，当前的主节点地位没有改变所以可以安全地就提议进行投票。

投票过程看起来很像两阶段提交（ 2PC ）。最大的区别是， 2PC的协调者并不是依靠选举产生；另外容错共识算法只需要收到多数节点的投票结果即可通过决议，而2PC则要求每个参与者都必须做出“是”才能最终通过。 此外，共识算法还定义了恢复过程，出现故障之后，通过该过程节点可以选举出新的主节点然后进入一致的状态，确保总是能够满足安全属性。所有这些差异之处都是确保共识算法正确性和容错性的关键。

##### **共识的局限性**

共识算法对于分布式系统来说绝对是一个巨大的突破，它为一切不确定的系统带来了明确的安全属性（一致性，完整性和有效性）， 此外它还可以支持容错（只要大多数节点还在工作和服务可达）。共识可以提供全序关系广播，以容错的方式实现线性化的原子操作（参阅本章前面“采用全序关系广播实现线性化存储”）。

不过， 也不是所有系统都采用了共识，因为好处的背后都是有代价的。这包括：

在达成一致性决议之前，节点投票的过程是一个同步复制过程。如第5章“同步与异步复制”所述，数据库通常配置为异步复制，存在某些已提交的数据在故障切换时丢失的风险，即使这样，很多系统还是采用异步复制（而非同步复制），原因正是为了更好的性能。

共识体系需要严格的多数节点才能运行。这意味着需要至少三个节点才能容忍一个节点发生故障（剩下的三分之二形成多数），或者需要最少五个节点来容忍两个节点故障（其余五分之三形成多数）。如果由于网络故障切断了节点之间的连接，则只有多数节点所在的分区可以继续工作 ， 剩下的少数节点分区则处于事实上的停顿状态（参阅本章前面“线性化的代价”）。	

多数共识算法是假定一组固定参与投票的节点集，这意味着不能动态、添加或删除节点 。动态成员资格的扩展特性可以在集群中的按需调整节点数，但相比于静态的成员组成，其理解程度和接受程度要低很多。

共识系统通常依靠超时机制来检测节点失效。在网络延迟高度不确定的环境中，特别是那些跨区域分布的系统，经常由于网络延迟的原因，导致节点错误地认为主节点发生了故障。虽然这种误判并不会损害安全属性，但频繁的主节点选举显著降低了性能，系统最终会花费更多的时间和资源在选举主节点上而不是原本的服务任务。

此外，共识算法往往对网络问题特别敏感。 例如， Raft 已被发现存在不合理的边界条件处理：如果整个网络中存在某一条网络连接持续不可靠， Raft 会进入一种奇怪的状态 ：它不断在两个节点之间反复切换主节点，当前主节点不断被赶下台，这最终导致系统根本无法安心提供服务。其他共识算法也有类似的问题，所以面对不可靠网络， 如何设计更具鲁棒性的共识算法仍然是一个开放性的研究问题 。

#### **成员与协调服务**

ZooKeeper或etcd这样的项目通常称为“分布式键值存储”或“协调与配置服务“。从它们对外提供服务的API来看则与数据库非常相像: 读取、写入对应主键的值，或者遍历主键。如果他们只是个普通数据库的话，为什么要花大力气实现一个共识算法呢? 它们与其他数据库有何不同之处?

为帮助理解，我们还是先简单探讨一下通常如何使用ZooKeeper这样的服务。应用程序开发者其实很少直接使用ZooKeeper，主要因为它并非通用的数据库。绝大多数情况是通过其他很多项目来间接地依赖于Zookeeper，例如HBase，Hadoop YARN，OpenStack Nova和Kafka等都依赖于在后头运行的ZooKeeper服务。那么这些项目为什么需要它呢?

ZooKeeper和etcd主要针对保存少量、可完全载入内存的数据 (虽然它们最终仍要写入磁盘以支持持久性)而设计，所以不要用它们保存大量的数据。它们通常采用容错的全序广播算法在所有节点上复制这些数据从而实现高可靠。正如之前所讨论的，全序广播主要用来实现数据库复制：每条消息代表的是数据库写请求，然后按照相同的顺序在多个节点上应用写操作，从而达到多副本之间的一致性。

ZooKeeper的实现其实模仿了Google的Chubby分布式锁服务但它不仅实现了全序广播 (因此实现了共识)，还提供了其他很多有趣的特性。所有这些特性在构建分布式系统时格外重要:

线性化的原子操作

使用原子比较-设置操作，可以实现加锁服务。例如如果多个节点同时尝试执行相同的操作，则确保其中只有一个会成功。共识协议保证了操作满足原子性和线性化，即使某些节点发生故障或网络随时被中断。分布式锁通常实现为一个带有到期时间的租约，这样万一某些客户端发生故障，可以最终释放锁(参阅第8章“进程暂停”)。

操作全序

如第8章“主节点与锁”所述，当资源被锁或者租约保护时，需要fencing令牌来防止某些客户端由于发生进程暂停而引起锁冲突。fencing令牌确保每次加锁时数字总是单调增加。 ZooKeeper在实现该功能时，采用了对所有操作执行全局排序，然后为每个操作都赋予一个单调递增的事务ID (zxd) 和版本号(cversion) 

故障检测

客户端与ZooKeeper节点维护一个长期会话，客户端会周期性地与ZooKeeper服务节点互相交换心跳信息，以检查对方是否存活。即使连接出现闪断，或者某个ZooKeeper节点发生失效，会话仍处于活动状态。但是，如果长时间心跳停止且超过了会话超时设置，ZooKeeper会声明会话失败。此时，所有该会话持有的锁资源可以配置为自动全部释放(ZooKeeper称之为ephemeral nodes即临时节点)。

更改通知

客户端不仅可以读取其他客户端所创建的锁和键值，还可以监视它们的变化。因此，客户端可以知道其他客户端何时加入了集群(基于它写入ZooKeeper的值)以及客户端是否发生了故障 (会话超时导致节点消失)。通过订阅通知机制，客户端不需要频繁地轮询服务即可知道感兴趣对象的变化情况。

在上述特征中，其实只有线性化的原子操作才依赖于共识。然而ZooKeeper集成了所有这些功能，在分布式协调服务中发挥了关键作用。

##### **节点任务分配**

ZooKeeper和Chubby系统非常适合的一个场景是，如果系统有多个流程或服务的实例，并且需要其中的一个实例充当主节点；而如果主节点失效，由其他某个节点来接管。显然，这非常吻合主从复制数据库，此外，它对于作业调度系统 (或类似的有状态服务)也非常有用。

还有另一个场景，对于一些分区资源 (可以是数据库，消息流，文件存储，分布式actor system等)，需要决定将哪个分区分配给哪个节点。当有新节点加入集群时需要将某些现有分区从当前节点迁移到新节点，从而实现负载动态平衡(参阅第5章”分区再平衡”)。而当节点移除或失败时，其他节点还需要接管失败节点。

上述场景中的任务，可以借助ZooKeeper中的原子操作，ephemeral nodes和通知机制来实现。如果实现无误，它可以非常方便地使应用程序达到自动故障中恢复，减少人工干预。虽然目前出现了如Apache Curator等 (基于ZooKeeper客户端API) 提供了更高级别的封装接口，但总体上讲真正做起来并非易事。即使这样，它仍然比从头开始实现一套共识算法好很多，全新开发共识系统非常有挑战性，目前成功记录寥寥可数。

应用程序最初可能只运行在单节点，之后可能最终扩展到数千节点。试图在如此庞大的集群上进行多数者投票会非常低效。ZooKeeper通常是在固定数量的节点 (通常三到五个) 上运行投票，可以非常高效地支持大量的客户端。因此，ZooKeeper其实提供了一种将跨节点协调服务 (包括共识，操作排序和故障检测) 专业外包的方式。

通常情况下，ZooKeeper所管理的数据变化非常缓慢，类似“分区7的主节点在10.1.1.23”这样的信息，其变化频率往往在分钟甚至是小时级别。它不适合保存那些应用实时运行的状态数据，后者可能每秒产生数千甚至百万次更改。如果这样，应该考虑使用其他工具(如Apache BookKeeper)。

##### **服务发现**

此外，ZooKeeper、etcd和Consul还经常用于服务发现。例如需要某项服务时，应该连接到哪个IP地址等。在典型的云环境中，虚拟机可能会起起停停，这种动态变化的节点无法提前知道服务节点的IP地址，因此，可以这样配置服务，每当节点启动时将其网络端口信息向ZooKeeper等服务注册，然后其他人只需向ZooKeeper的注册表中询问即可。

但是，关于服务发现是否需要共识还缺乏统一认识。通过服务名称来获取IP地址传统的查询方式是基于DNS，它使用多层缓存来实现高性能与高可用性。从DNS读取肯定不满足线性化，而现实情况是，如果DNS返回的结果是过期的旧值，通常也不会产生什么大问题。总体讲，DNS对于网络产生中断时服务可用性和鲁棒性更为重要一些

即使服务发现不需要共识，但主节点选举则肯定需要。因此，如果共识系统已经明确知道哪一个是主节点，那它可以利用这些信息来帮助次级服务来发现各自的主节点。现在一些共识系统支持只读的缓存副本。这些副本异步地接收其他共识算法所达成的决议日志，但自身并不怎么参与投票，而主要是提供不需要支持线性化的读取服务。

##### **成员服务**

ZooKeeper等还可以看作是成员服务范畴的一部分。关于成员服务的研究历史可以追溯到20世纪80年代，它对于构建高可靠的系统 (例如空中交管) 非常重要。

成员服务用来确定当前哪些节点处于活动状态并属于集群的有效成员。正如在第8章中所介绍的，由于无限的网络延迟，无法可靠地检测一个节点究竟是否发生了故障，但是，可以将故障检测与共识绑定在一起，让所有节点就节点的存活达成一致意见。

这里依然存在发生误判的可能性，即节点其实处于活动状态却被错误地宣判为故障。即便这样，系统就成员资格问题的决定是全体一致的，这是最重要的。例如，选举主节点的方式可能是简单地投票选择编号最小的节点，一旦节点对于当前包含哪些成员出现了不同意见，那么共识过程就无法继续。

### **小结**

本章从多个不同的角度审视了一致性与共识问题。深入研究了线性化 (一种流行的一致性模型)其目标是使多副本对外看起来好像是单一副本，然后所有操作以原子方式运行，就像一个单线程程序操作变量一样。线性化的概念简单，容易理解，看起来很有吸引力，但它的主要问题在于性能，特别是在网络延迟较大的环境中。

我们接下来探讨了因果关系，因果关系对事件进行了某种排序 (根据事件发生的原因结果依赖关系)。线性化是将所有操作都放在唯一的、全局有序时间线上，而因果性则不同，它为我们提供了一个弱一致性模型：允许存在某些并发事件，所以版本历史是一个包含多个分支与合并的时间线。因果一致性避免了线性化昂贵的协调开销，且对网络延迟的敏感性要低很多。然而，即使意识到因果顺序 (例如采用Lamport时间戳)，我们发现有时无法在实践中采用这种方式，在“时间戳排序还不够”一节有这样的例子：确保用户名唯一并拒绝对同一用户名的并发注册请求。如果某个节点要同意请求，则必须以某种方式查询其他节点是否存在竞争请求。这个例子最终引导我们去探究系统的共识问题。

共识意味着就某一项提议，所有节点做出一致的决定，而且决定不可撤销。通过逐一分析，事实证明，多个广泛的问题最终都可以归结为共识，并且彼此等价（这就意味着，如果找到其中一个解决方案，就可以比较容易地将其转换为其他问题的解决方案）。这些等价的问题包括:

可线性化的比较-设置寄存器

寄存器需要根据当前值是否等于输入的参数，来自动决定接下来是否应该设置新值。

原子事务提交

数据库需要决定是否提交或中止分布式事务

全序广播

消息系统要决定以何种顺序发送消息

锁与租约

当多个客户端争抢锁或租约时，要决定其中哪一个成功

成员/协调服务

对于失败检测器(例如超时机制)，系统要决定节点的存活状态(例如基于会话超时)

唯一性约束

当多个事务在相同的主键上试图并发创建冲突资源时，约束条件要决定哪一个被允许，哪些违反约束因而必须失败。

如果系统只存在一个节点，或者愿意把所有决策功能都委托给某一个节点，那么事情就变得很简单。这和主从复制数据库的情形是一样的，即由主节点负责所有的决策事宜，正因如此，这样的数据库可以提供线性化操作、唯一性约束、完全有序的复制日志等。

然而，如果唯一的主节点发生故障，或者出现网络中断而导致主节点不可达，这样的系统就会陷入停顿状态。有以下三种基本思路来处理这种情况:

1. 系统服务停止，并等待主节点恢复。许多XA / JTA事务协调者采用了该方式。本质上，这种方法并没有完全解决共识问题，因为它不满足终止性条件，试想如果主节点没法恢复，则系统就会永远处于停顿状态。
2. 人为介入来选择新的主节点，并重新配置系统使之生效。许多关系数据库都采用这种方法。本质上它引入了一种“上帝旨意”的共识，即在计算机系统之外由人类来决定最终命运。故障切换的速度完全取决于人类的操作，通常比计算机慢。
3. 采用算法来自动选择新的主节点。这需要一个共识算法，我们建议采用那些经过验证的共识系统来确保正确处理各种网络异常。

虽然主从数据库提供了线性化操作，且在写操作粒度级别上并不依赖于共识算法，但它仍然需要共识来维护主节点角色和处理主节点变更情况。因此，某种意义上说，唯一的主节点只是其中的一步，系统在其他环节依然需要共识 (虽然不那么的频繁)。好在容错算法与共识的系统可以共存，我们在本章做了简要地介绍。

ZooKeeper等工具以一种类似外包方式为应用提供了重要的共识服务、故障检测和成员服务等。虽然用起来依然有挑战，但远比自己开发共识算法要好得多(正确处理好第8章的所有问题绝非易事)。如果面临的问题最终可以归结为共识，并且还有容错需求，那么这里给的建议是采用如ZooKeeper等验证过的系统。

尽管如此，并不是每个系统都需要共识。例如无主复制和多主复制复制系统通常并不支持全局共识。正因如此，这些系统可能会发生冲突(参阅第5章“处理写冲突”)，但或许也可以接受或者寻找其他方案，例如没有线性化保证时，就需要努力处理好数据多个冲突分支以及版本合并等。

本章引用了大量分布式系统理论方面的研究。虽然理论性文章和证明有时理解起来有些困难，有时甚至包含了一些不太合理的假设条件，但它们对于指导实际工作还是极具价值：例如帮助推理系统的边界在哪里，帮助发现一些违反直觉的分布式系统潜在的缺陷。如果有时间，建议仔细阅读这些参考资料。

至此我们终于完成了本书第二部分，其中包括复制 (第5章) ，分区(第6章)，事务(第7章)，分布式系统失效模型 (第8章) 以及最后的一致性与共识 (第9章)。相信我们已经奠定了坚实的理论基础，接下来第三部分我们将面向实际环境，讨论如何基于异构模块来构建强大的应用系统。





# **第四部分 自己扩展**

## **列式存储**

参考资料：https://zhuanlan.zhihu.com/p/35622907

**列式存储（Column-oriented Storage）**并不是一项新技术，最早可以追溯到 1983 年的论文 Cantor。然而，受限于早期的硬件条件和使用场景，主流的事务型数据库（OLTP）大多采用行式存储，直到近几年分析型数据库（OLAP）的兴起，列式存储这一概念又变得流行。

总的来说，列式存储的优势一方面体现在存储上能节约空间、减少 IO，另一方面依靠列式数据结构做了计算上的优化。本文中着重介绍列式存储的数据组织方式，包括数据的布局、编码、压缩等。在下一篇文章中将介绍计算层以及 DBMS 整体架构设计。

### **什么是列式存储**

传统 OLTP 数据库通常采用行式存储。以下图为例，所有的列依次排列构成一行，以行为单位存储，再配合以 B+ 树或 SS-Table 作为索引，就能快速通过主键找到相应的行数据。

​    ![0](https://note.youdao.com/yws/res/23825/WEBRESOURCE1032d840723de2cc7e8cbb1a8a5d7a62)

行式存储对于 OLTP 场景是很自然的：大多数操作都以实体（entity）为单位，即大多为增删改查一整行记录，显然把一行数据存在物理上相邻的位置是个很好的选择。

然而，对于 OLAP 场景，一个典型的查询需要遍历整个表，进行分组、排序、聚合等操作，这样一来按行存储的优势就不复存在了。更糟糕的是，分析型 SQL 常常不会用到所有的列，而仅仅对其中某些感兴趣的列做运算，那一行中那些无关的列也不得不参与扫描。

列式存储就是为这样的需求设计的。如下图所示，同一列的数据被一个接一个紧挨着存放在一起，表的每列构成一个长数组。

​    ![0](https://note.youdao.com/yws/res/23829/WEBRESOURCE50208f35be4bca43ac2b7621fc8a7209)

显然，列式存储对于 OLTP 不友好，一行数据的写入需要同时修改多个列。但对 OLAP 场景有着很大的优势：

- 当查询语句只涉及部分列时，只需要扫描相关的列
- 每一列的数据都是相同类型的，彼此间相关性更大，对列数据压缩的效率较高

### **BigTable（HBase）是列式存储吗？**

两者关系： Bigtable（由 Google 开发的一个分布式存储系统，Bigtable 的设计细节首次在 2006 年的一篇研究论文中被公开，并且它对后续的 NoSQL 数据库设计产生了很大影响。） 和 HBase （HBase 是一个开源的非关系型分布式数据库（NoSQL），它是 Apache 软件基金会的一个项目，设计上受到了 Google Bigtable 的启发。HBase 是 Hadoop 生态系统的一部分，它在 Hadoop 分布式文件系统（HDFS）之上提供了 Bigtable 类似的能力。）是不同的产品（一个是商业服务，另一个是开源项目），但 HBase 模仿了 Bigtable 的设计；Bigtable 是 Google 的专有技术，而 HBase 是受 Bigtable 影响的开源实现，是对 Bigtable 概念的一种开源应用。

很多文章将 BigTable 归为列式存储。但严格地说，BigTable 并非列式存储，虽然论文中提到借鉴了 C-Store 等列式存储的某些设计，但 BigTable 本身按 Key-Value Pair 存储数据，和列式存储并无关系。

有一点迷惑的是 BigTable 的列簇（column family）概念，列簇可以被指定给某个 locality group，决定了该列簇数据的物理位置，从而可以让同一主键的各个列簇分别存放在最优的物理节点上。由于 column family 内的数据通常具有相似性，对它做压缩要比对整个表压缩效果更好。

另外，值得强调的一点是：列式数据库可以是关系型、也可以是 NoSQL，这和是否是列式并无关系。本文中讨论的 C-Store 就采用了关系模型。

​    ![0](https://note.youdao.com/yws/res/23843/WEBRESOURCEdb57f6c07cce834396f26171d82a12d5)

让GPT帮我们解释一下上面的内容吧

------

确实，Bigtable 中的列簇（column family）概念对于理解其数据模型是非常关键的。列簇是 Bigtable 存储结构的核心组成部分，它影响数据的存储方式和访问性能。下面我会详细解释列簇和 locality group 的概念，以及它们如何影响数据的物理存储。

**列簇（Column Family）：**

在 Bigtable 中，所有数据都组织在表格中，而表格由行和列组成。列被进一步组织为列簇，这意味着每个列簇包含一组列。列簇内的列通常具有相关的数据类型或访问模式。例如，一个人的个人信息可以是一个列簇，而他的交易记录可以是另一个列簇。

**Locality Group：**

Bigtable 允许将列簇分配给所谓的 locality group。Locality group 是物理存储的概念，它决定了列簇中的数据如何在磁盘上存储。通过将列簇分配给不同的 locality group，可以优化数据的访问模式，因为相关的数据可以被存储在一起，提高数据读取的局部性。例如，频繁访问的列簇可以放在快速存储介质上，而不经常访问的数据可以放在慢速存储上。

**压缩：**

由于列簇内的数据通常具有相似性，对列簇进行压缩通常比对整个表进行压缩效果更好。这是因为相似的数据更容易压缩，而且列簇内的数据模式和访问模式的一致性使得压缩算法能够更高效地工作。

**列式存储与关系模型：**

您提到的另一个重要点是列式存储（column-oriented storage）可以用于关系型数据库和 NoSQL 数据库。列式存储的关键优势是它能够高效地执行针对特定列的查询，因为它只需要读取相关的列，而不是整行数据。这在分析和报表生成等操作中特别有用。C-Store 是一个采用关系模型的列式数据库的例子，它证明了列式存储不仅限于 NoSQL 数据库。

总的来说，Bigtable 的列簇和 locality group 功能提供了一种灵活的方法来优化数据的物理存储和访问。而列式存储的概念可以跨越不同类型的数据库系统，无论它们是基于关系模型还是非关系模型（NoSQL）。

#### **C-Store简介**

大多数 DBMS 都是为写优化，而 C-Store 是第一个为读优化的 OLTP 数据库系统，虽然从今天的视角看它应当算作 HTAP 。C-Store 可能是第一个现代的列式存储数据库实现，其的设计启发了无数后来的商业或开源数据库，就比如 Vertica。

C-Store 是关系型数据库，它的逻辑表和其他数据库中的并没有什么不同。但是在 C-Store 内部，逻辑表被纵向拆分成 projections，每个 projection 可以包含一个或多个列，甚至可以包含来自其他逻辑表的列。当然，每个列至少会存在于一个 projections 上。

​    ![0](https://note.youdao.com/yws/res/23862/WEBRESOURCEa43daad4936ba1530ebda39411372827)

Projection 内是以列式存储的：里面的每个列分别用一个数据结构存放。为了避免列太长引起问题，也支持每个 projection 以 sort key 的值做横向切分。

## **NoSQL**

NoSQL（通常解释为"Not Only SQL"）是一类数据库管理系统，它们与传统的关系型数据库（如MySQL、PostgreSQL等）不同，不一定遵循严格的关系模型。NoSQL数据库设计用于处理大规模数据分布式存储和操作的需求，特别是在需要高性能、可伸缩性、灵活的数据模型和简单设计时。

基于 BASE 理论支撑的 NoSQL 运动坚持创造各种可用性优先、数据一致性其次的方案，而传统数据库则坚守 ACID 特性（原子性、一致性、隔离性、持久性），优先数据一致性，在必要的时候，可以放弃系统可用性。当时 BASE 理论还没有被广泛接受，人们还是不愿意放弃 ACID 的优点。

当 CAP 理论提出后，我们明白了在分布式系统中，只能在强一致性和 100% 的可用性之间二选一，不能两个都要。从此 BASE 理论也逐渐被人们所接受，在大规模存储的场景中广泛应用，并且开创了从 2000 年到 2010 年， NoSQL 运动的黄金十年。这十年里，工业界产生了大量优秀的 NoSQL 系统，比如 BigTable 、 HBase 、 MongoDB 、 Cassandra ，解决了人们当时遇到的大规模数据存储的问题。

CAP 理论的出现是有历史使命的，让人们能够在分布式系统中，放弃以关系数据库为代表的 ACID 强一致性系统，接受以 NoSQL 为代表的 BASE 理论，并且暂时解决了人们在 2000 年前后对于分布式系统中，数据一致性和可用性之间的争论，让人们能够更加务实地解决当时由于互联网爆发式发展，产生的海量用户和数据的分布式计算与存储的问题。

NoSQL数据库主要有以下几种类型：

\1. 键值存储（Key-Value Stores）

键值存储是最简单的NoSQL数据库类型，以键值对的形式存储数据。它们提供快速查询和简单的数据模型，使其非常适合用于存储会话信息、用户配置、缓存等。代表性的键值存储数据库包括Redis和Amazon DynamoDB。

\2. 列存储（Column-Family Stores）

列存储数据库将数据以列族的形式存储在行中，这使得对大量数据的聚合操作变得非常高效。它们适合处理大数据量的分析工作负载，例如时间序列数据、大型数据仓库等。Apache Cassandra和HBase是这类数据库的例子。

\3. 文档型数据库（Document Stores）

文档型数据库以文档（通常是JSON、XML或BSON格式）的形式存储数据。每个文档都是一个独立的数据单元，它们可以嵌套复杂的数据结构。文档数据库非常适合内容管理系统、电子商务应用等。MongoDB和Couchbase是流行的文档型数据库。

\4. 图数据库（Graph Stores）

图数据库专门用于处理图结构数据，如社交网络、推荐系统和网络拓扑等。它们通过节点、边和属性来存储和查询关系密集的数据。Neo4j和Amazon Neptune是图数据库的例子。

NoSQL数据库的特点：

- 灵活性：NoSQL数据库通常不需要预先定义模式（Schema），这使得在快速迭代和开发时可以更灵活地处理数据结构的变化。
- 水平可伸缩性：许多NoSQL数据库被设计为易于水平扩展，通过在多个服务器或节点上分布数据来处理更大的数据集和更高的吞吐量。
- 高性能：对于特定类型的查询和操作，NoSQL数据库通常提供更高的性能，尤其是在数据分布式存储和高并发访问的场景中。
- 高可用性和容错性：NoSQL数据库设计为支持复制、分区和分布式存储，以提供高可用性和容错性。

使用场景：

NoSQL数据库适用于很多不同的场景，尤其是当应用程序需要处理大量数据、快速开发、灵活的数据模型或者分布式架构时。它们在大数据、实时Web应用、云计算和移动应用中尤为流行。

总结：

NoSQL数据库是一组多样化的技术，旨在解决传统关系型数据库在某些情况下可能遇到的问题，如可伸缩性、性能和模式的灵活性。它们不是为了替代传统的SQL数据库，而是作为在处理某些类型的数据和应用程序时的补充或替代方案。根据应用程序的特定需求和数据工作负载选择合适的数据库类型是至关重要的。

## **NewSQL**

NewSQL 是一种数据库技术，旨在结合传统关系型数据库系统的良好特性（如SQL兼容性、ACID事务和关系数据模型）与NoSQL系统的可伸缩性和高性能。NewSQL数据库试图在不牺牲事务一致性和数据完整性的前提下，解决关系型数据库在大型分布式系统中扩展性的限制。

**核心特性**

1. ACID事务：NewSQL数据库支持原子性、一致性、隔离性、持久性（ACID）事务，确保了数据的可靠性和一致性，特别是在并发操作和分布式系统中。
2. 可扩展性：通过分布式架构，NewSQL数据库可以水平扩展到多个服务器或节点，以处理大量数据和高并发事务。
3. SQL兼容性：尽管具有分布式特性，NewSQL数据库通常兼容SQL标准，这意味着它们可以无缝地与支持SQL的应用程序集成。
4. 高性能：NewSQL数据库旨在提供低延迟和高吞吐量的在线事务处理（OLTP），同时也支持复杂查询和在线分析处理（OLAP）。

**实现方式**

NewSQL数据库的实现方式不尽相同，但它们通常涉及以下几个关键技术：

1. 分布式架构：能够在多个实例或节点之间分发数据和负载，从而提高系统的并发能力和容错性。
2. 分区（Sharding）：将数据水平切分成多个分区，并将它们分布在不同的节点上，以优化查询性能和数据管理。
3. 复制（Replication）：为了提高数据的可用性和耐久性，数据可以在不同节点之间复制。
4. 两阶段提交（2PC）或共识协议：为保证分布式事务的一致性，NewSQL数据库可能会实现两阶段提交或其他共识协议，如Paxos或Raft。
5. 存储引擎优化：高效的存储引擎可以提供快速的数据访问和修改，特别是对于索引和查询优化。

**代表性NewSQL数据库**

- Google Spanner：是Google开发的全球分布式数据库，支持SQL查询语言，并提供了外部一致性和全球事务。
- CockroachDB：是一个分布式SQL数据库，支持ACID事务，并且自动处理数据的分割和复制。
- TiDB：是一个开源的分布式SQL数据库，支持水平扩展，兼容MySQL协议。
- VoltDB：是一个面向快速数据处理的内存数据库系统，支持SQL和ACID事务。
- NuoDB：称为"新一代SQL数据库"，提供了一个分布式对象架构，旨在适应云应用程序的需求。

**使用场景**

NewSQL数据库通常在需要强事务保证和SQL接口的同时要求高性能和良好扩展性的场景中使用。它们适合于金融服务、电子商务、实时分析和任何需要高效事务处理的大型分布式应用程序。

**总结**

NewSQL数据库提供了一种折衷的解决方案，结合了关系型数据库的可靠事务和数据完整性，以及NoSQL数据库的可伸缩性和高性能。对许多企业来说，NewSQL是在大规模操作和复杂查询需求上的现代化选择，它们支持传统SQL的优势而不牺牲关系型数据库的关键特性。