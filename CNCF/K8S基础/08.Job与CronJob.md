接下来给大家介绍另外一类资源对象： Job ，在日常的工作中经常都会遇到一些需要进行数据处理和分析的需求，当然也会有按时间来进行调度的工作，在 Kubernetes 集群中提供了 Job 和 CronJob 两种资源对象来应对这种需求。

# Job

用 Job 这个资源对象来创建一个如下所示的任务，该任务负责计算 π 小数点后 2000 位，并将结果打印出来，此计算大约需要 10 秒钟完成。对应的资源清单如下所示：

```yaml
# job-pi.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    spec:
      containers:
        - name: pi
          image: perl:5.34.0
          imagePullPolicy: IfNotPresent
          command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
  backoffLimit: 4
```

可以看到 Job 中也是一个 Pod 模板，和之前的 Deployment、StatefulSet 之类的是一致的，只是 Pod 中的容器要求是一个任务，而不是一个常驻的进程了，因为需要退出；另外值得注意的是 Job 的 `RestartPolicy` 仅支持 `Never` 和 `OnFailure` 两种，不支持 `Always`。

直接创建这个 Job 对象：

```shell
[root@master yamlDir]# kubectl apply -f job-pi.yaml
job.batch/pi created
[root@master yamlDir]# kubectl get job
NAME   COMPLETIONS   DURATION   AGE
pi     0/1           5s         5s
[root@master controller]# kubectl get pods
NAME                                     READY   STATUS              RESTARTS        AGE
pi-lbjxd                                 0/1     ContainerCreating   0               23s
```

Job 对象创建成功后，可以查看下对象的详细描述信息：

```shell
[root@master yamlDir]# kubectl describe job pi
Name:             pi
Namespace:        default
# 注意这个选择器
Selector:         controller-uid=38738e0d-bb61-4cd1-b7cc-44f60f31d858
Labels:           controller-uid=38738e0d-bb61-4cd1-b7cc-44f60f31d858
                  job-name=pi
Annotations:      batch.kubernetes.io/job-tracking:
Parallelism:      1
Completions:      1
Completion Mode:  NonIndexed
Start Time:       Sat, 24 Feb 2024 17:50:55 -0500
Completed At:     Sat, 24 Feb 2024 17:52:18 -0500
Duration:         83s
Pods Statuses:    0 Active (0 Ready) / 1 Succeeded / 0 Failed
Pod Template:
  Labels:  controller-uid=38738e0d-bb61-4cd1-b7cc-44f60f31d858
           job-name=pi
  Containers:
   pi:
    Image:      perl:5.34.0
    Port:       <none>
    Host Port:  <none>
    Command:
      perl
      -Mbignum=bpi
      -wle
      print bpi(2000)
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  94s   job-controller  Created pod: pi-j6zg5
  Normal  Completed         11s   job-controller  Job completed
```

可以看到，Job 对象在创建后，它的 Pod 模板，被自动加上了一个 `controller-uid=< 一个随机字符串 >` 这样的 Label 标签，而这个 Job 对象本身，则被自动加上了这个 Label 对应的 `Selector`，从而保证了 Job 与它所管理的 Pod 之间的匹配关系。而 Job 控制器之所以要使用这种携带了 UID 的 Label，就是为了避免不同 Job 对象所管理的 Pod 发生重合。

可以看到隔一会儿后 Pod 变成了 `Completed` 状态，这是因为容器的任务执行完成正常退出了，可以查看对应的日志：

```shell
[root@master yamlDir]# kubectl get pods
NAME       READY   STATUS      RESTARTS   AGE
pi-j6zg5   0/1     Completed   0          7m17s

[root@master yamlDir]# kubectl logs pi-j6zg5
3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421......
[root@master controller]# kubectl get job
#                    job持续的时间
NAME   COMPLETIONS   DURATION   AGE
pi     1/1           9s         15m
```

上面这里的 Job 任务对应的 Pod 在运行结束后，会变成 `Completed` 状态，但是如果执行任务的 Pod 因为某种原因一直没有结束怎么办呢？同样可以在 Job 对象中通过设置字段 `spec.activeDeadlineSeconds` 来限制任务运行的最长时间，比如：

```yaml
spec:
 activeDeadlineSeconds: 100
```

在 Kubernetes Job 的配置中，`spec.activeDeadlineSeconds` 字段允许设置一个时间限制，表示该 Job 可以运行的最长时间（以秒为单位）。如果设置了这个字段，Job 运行的时间超过了这个秒数，系统就会尝试终止这个 Job。这个时间限制包括了 Job 的启动时间、运行时间以及任何重试的时间。那么当 Job 运行超过了 100s 后，这个 Job 的所有 Pod 都会被终止，并且Job的终止原因会变成 `DeadlineExceeded`。

如果任务执行失败了，会怎么处理呢，这个和定义的 `restartPolicy` 有关系，比如定义如下所示的 Job 任务，定义 `restartPolicy: Never` 的重启策略：

```yaml
# job-failed-demo.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-failed-demo
spec:
  template:
    spec:
      containers:
      - name: test-job
        image: busybox
        imagePullPolicy: IfNotPresent
        command: ["echo123", "test failed job!"]
      restartPolicy: Never
```

直接创建上面的资源对象：

```shell
➜  ~ kubectl apply -f job-failed-demo.yaml
job.batch/job-failed-demo created
[root@master ~]# kubectl get pod -w
# 可以看到 RESTARTS 都是0
NAME                                     READY   STATUS              RESTARTS       AGE
job-failed-demo-tsdvs                    0/1     Pending             0              0s
job-failed-demo-tsdvs                    0/1     ContainerCreating   0              0s
job-failed-demo-tsdvs                    0/1     StartError          0              1s
job-failed-demo-86gcx                    0/1     Pending             0              0s
job-failed-demo-86gcx                    0/1     ContainerCreating   0              0s
job-failed-demo-86gcx                    0/1     StartError          0              1s
job-failed-demo-gwmtt                    0/1     Pending             0              0s
job-failed-demo-gwmtt                    0/1     ContainerCreating   0              0s
job-failed-demo-gwmtt                    0/1     StartError          0              1s
job-failed-demo-8hlpv                    0/1     Pending             0              0s
job-failed-demo-8hlpv                    0/1     ContainerCreating   0              0s
job-failed-demo-8hlpv                    0/1     StartError          0              3s
job-failed-demo-gn884                    0/1     Pending             0              0s
job-failed-demo-gn884                    0/1     ContainerCreating   0              0s
job-failed-demo-gn884                    0/1     StartError          0              3s
job-failed-demo-2lmsx                    0/1     Pending             0              0s
job-failed-demo-2lmsx                    0/1     ContainerCreating   0              0s
job-failed-demo-2lmsx                    0/1     StartError          0              3s
job-failed-demo-94p9j                    0/1     Pending             0              0s
job-failed-demo-94p9j                    0/1     ContainerCreating   0              0s
job-failed-demo-94p9j                    0/1     StartError          0              3s
# 共7次失败
[root@master controller]# kubectl describe job job-failed-demo
Name:             job-failed-demo
Namespace:        default
Selector:         controller-uid=5eac4705-0216-45c4-b57a-f66df82b104b
Labels:           controller-uid=5eac4705-0216-45c4-b57a-f66df82b104b
                  job-name=job-failed-demo
Annotations:      batch.kubernetes.io/job-tracking:
Parallelism:      1
Completions:      1
Completion Mode:  NonIndexed
Start Time:       Mon, 21 Oct 2024 23:09:24 -0400
Pods Statuses:    0 Active (0 Ready) / 0 Succeeded / 7 Failed # 可以看到7次失败
Pod Template:
  Labels:  controller-uid=5eac4705-0216-45c4-b57a-f66df82b104b
           job-name=job-failed-demo
  Containers:
   test-job:
    Image:      busybox
    Port:       <none>
    Host Port:  <none>
    Command:
      echo123
      test failed job!
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Events:
  Type     Reason                Age    From            Message
  ----     ------                ----   ----            -------
  # job-controller 重启了6个pod，第一个不算
  Normal   SuccessfulCreate      2m11s  job-controller  Created pod: job-failed-demo-tsdvs
  Normal   SuccessfulCreate      2m8s   job-controller  Created pod: job-failed-demo-86gcx
  Normal   SuccessfulCreate      2m5s   job-controller  Created pod: job-failed-demo-gwmtt
  Normal   SuccessfulCreate      2m2s   job-controller  Created pod: job-failed-demo-8hlpv
  Normal   SuccessfulCreate      119s   job-controller  Created pod: job-failed-demo-gn884
  Normal   SuccessfulCreate      116s   job-controller  Created pod: job-failed-demo-2lmsx
  Normal   SuccessfulCreate      113s   job-controller  Created pod: job-failed-demo-94p9j
  # 重启次数达到限制
  Warning  BackoffLimitExceeded  110s   job-controller  Job has reached the specified backoff limit
```

可以看到当设置成 `Never` 重启策略的时候，Job 任务执行失败后会不断创建新的 Pod，但是不会一直创建下去，会根据 `spec.backoffLimit` 参数进行限制，默认为 `6`，通过该字段可以定义重建 Pod 的次数。

但是如果设置的 `restartPolicy: OnFailure` 重启策略，则当 Job 任务执行失败后不会创建新的 Pod 出来，只会不断重启 Pod，比如将上面的 Job 任务 `restartPolicy` 更改为 `OnFailure` 后查看 Pod：

```shell
[root@master ~]# kubectl get pod -w -owide
NAME                                     READY   STATUS              RESTARTS       AGE    IP             NODE     NOMINATED NODE   READINESS GATES
job-failed-demo-j65zq                    0/1     Pending             0              0s     <none>         <none>   <none>           <none>
job-failed-demo-j65zq                    0/1     ContainerCreating   0              0s     <none>         node1    <none>           <none>
job-failed-demo-j65zq                    0/1     RunContainerError   0 (1s ago)     2s     10.244.1.6     node1    <none>           <none>
job-failed-demo-j65zq                    0/1     RunContainerError   1 (1s ago)     3s     10.244.1.6     node1    <none>           <none>
job-failed-demo-j65zq                    0/1     CrashLoopBackOff    1 (2s ago)     4s     10.244.1.6     node1    <none>           <none>
job-failed-demo-j65zq                    0/1     RunContainerError   2 (0s ago)     16s    10.244.1.6     node1    <none>           <none>
job-failed-demo-j65zq                    0/1     CrashLoopBackOff    2 (15s ago)    31s    10.244.1.6     node1    <none>           <none>
job-failed-demo-j65zq                    0/1     RunContainerError   3 (0s ago)     44s    10.244.1.6     node1    <none>           <none>
[root@master controller]# kubectl describe pod job-failed-demo-j65zq
Name:             job-failed-demo-j65zq
Namespace:        default
Priority:         0
Service Account:  default
Node:             node1/192.168.220.147
Start Time:       Mon, 21 Oct 2024 23:22:21 -0400
Labels:           controller-uid=4676fa3b-a60e-4cba-a4d8-f0640cf8bf49
                  job-name=job-failed-demo
Annotations:      <none>
Status:           Running
IP:               10.244.1.6
IPs:
  IP:           10.244.1.6
# 被谁控制
Controlled By:  Job/job-failed-demo
Containers:
  test-job:
    Container ID:  containerd://42842151aeef9147b546320e034d1355d1f038f0b999efc7ee950734cc948843
    Image:         busybox
    Image ID:      sha256:beae173ccac6ad749f76713cf4440fe3d21d1043fe616dfbe30775815d1d0f6a
    Port:          <none>
    Host Port:     <none>
    Command:
      echo123
      test failed job!
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated # 上次状态
      Reason:       StartError # 具体原因
      Message:      failed to create containerd task: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: exec: "echo123": executable file not found in $PATH: unknown
      Exit Code:    128
      Started:      Wed, 31 Dec 1969 19:00:00 -0500
      Finished:     Mon, 21 Oct 2024 23:25:21 -0400
    Ready:          False
    Restart Count:  5 # 重启次数
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-447s6 (ro)
```

除此之外，还可以通过设置 `spec.parallelism` 参数来进行并行控制，该参数定义了一个 Job 在任意时间最多可以有多少个 Pod 同时运行。并行性请求（`.spec.parallelism`）可以设置为任何非负整数，如果未设置，则默认为 1，如果设置为 0，则 Job 相当于启动之后便被暂停，直到此值被增加。

`spec.completions` 参数可以定义 Job 至少要完成的 Pod 数目。如下所示创建一个新的 Job 任务，设置允许并行数为 2，至少要完成的 Pod 数为 8：

```yaml
# job-para-demo.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-para-test
spec:
  parallelism: 2
  completions: 8
  template:
    spec:
      containers:
        - name: test-job
          image: busybox
          imagePullPolicy: IfNotPresent
          command: ["echo", "test paralle job!"]
      restartPolicy: Never
```

创建完成后查看任务状态：

```shell
[root@master controller]# kubectl get job
NAME              COMPLETIONS   DURATION   AGE
job-para-test     8/8           17s        40s

[root@master ~]# kubectl get pod -w -owide
NAME                                     READY   STATUS              RESTARTS         AGE    IP             NODE     NOMINATED NODE   READINESS GATES
job-para-test-c87rq                      0/1     Pending             0                0s     <none>         node1    <none>           <none>
job-para-test-fk2mt                      0/1     Pending             0                0s     <none>         node1    <none>           <none>
job-para-test-c87rq                      0/1     ContainerCreating   0                0s     <none>         node1    <none>           <none>
job-para-test-fk2mt                      0/1     ContainerCreating   0                0s     <none>         node1    <none>           <none>
job-para-test-c87rq                      0/1     Completed           0                4s     10.244.1.7     node1    <none>           <none>
job-para-test-fk2mt                      0/1     Completed           0                4s     10.244.1.8     node1    <none>           <none>
job-para-test-w7h4q                      0/1     Pending             0                0s     <none>         node1    <none>           <none>
job-para-test-pbrs8                      0/1     Pending             0                0s     <none>         <none>   <none>           <none>
job-para-test-w7h4q                      0/1     ContainerCreating   0                0s     <none>         node1    <none>           <none>
job-para-test-c87rq                      0/1     Completed           0                5s     10.244.1.7     node1    <none>           <none>
job-para-test-fk2mt                      0/1     Completed           0                5s     10.244.1.8     node1    <none>           <none>
job-para-test-pbrs8                      0/1     ContainerCreating   0                0s     <none>         node1    <none>           <none>
job-para-test-w7h4q                      0/1     Completed           0                3s     10.244.1.9     node1    <none>           <none>
job-para-test-pbrs8                      0/1     Completed           0                3s     10.244.1.10    node1    <none>           <none>
job-para-test-fhvzv                      0/1     Pending             0                0s     <none>         <none>   <none>           <none>
job-para-test-4cgp6                      0/1     Pending             0                0s     <none>         <none>   <none>           <none>
job-para-test-w7h4q                      0/1     Completed           0                4s     10.244.1.9     node1    <none>           <none>
job-para-test-pbrs8                      0/1     Completed           0                4s     10.244.1.10    node1    <none>           <none>
job-para-test-fhvzv                      0/1     ContainerCreating   0                0s     <none>         node1    <none>           <none>
job-para-test-4cgp6                      0/1     ContainerCreating   0                0s     <none>         node1    <none>           <none>
job-para-test-4cgp6                      0/1     Completed           0                3s     10.244.1.12    node1    <none>           <none>
job-para-test-fhvzv                      0/1     Completed           0                3s     10.244.1.11    node1    <none>           <none>
job-para-test-9blws                      0/1     Pending             0                0s     <none>         <none>   <none>           <none>
job-para-test-wzcsp                      0/1     Pending             0                0s     <none>         node1    <none>           <none>
job-para-test-9blws                      0/1     ContainerCreating   0                0s     <none>         node1    <none>           <none>
job-para-test-wzcsp                      0/1     ContainerCreating   0                0s     <none>         node1    <none>           <none>
job-para-test-wzcsp                      0/1     Completed           0                4s     10.244.1.14    node1    <none>           <none>
job-para-test-9blws                      0/1     Completed           0                4s     10.244.1.13    node1    <none>           <none>
```

可以看到一次可以有 2 个 Pod 同时运行，需要 8 个 Pod 执行成功，如果不是 8 个成功，那么会根据 `restartPolicy` 的策略进行处理，可以认为是一种检查机制。

此外带有确定完成计数的 Job，即 `.spec.completions` 不为 `nil` 的 Job（设置为 `nil` 表示只要有一个 Pod 成功即可）， 都可以在其 `.spec.completionMode` 中设置完成模式：

- `NonIndexed`（默认值）：当成功完成的 Pod 个数达到 `.spec.completions` 所设值时认为 Job 已经完成。换言之，每个 Job 完成事件都是独立无关且同质的。要注意的是，当 `.spec.completions` 取值为 `nil` 时，Job 被默认处理为 `NonIndexed` 模式。
- `Indexed`：当设置为 `Indexed` 时，Job 中的每个 Pod 都会获得一个从 0 到 (`.spec.completions - 1`) 的连续索引，这个索引会以注解的形式（`batch.kubernetes.io/job-completion-index`）呈现在 Pod 上。Job 在每个索引都有至少一个成功完成的 Pod 时被认为是完成的。此模式下，必须指定 `.spec.completions`，且 `.spec.parallelism` 必须小于或等于 `10^5`。此外，在这种模式下，Pod 的名字会采用 `$(job-name)-$(index)-$(random-string)` 格式，Pod 的主机名会采用 `$(job-name)-$(index)` 格式。索引可以通过四种方式获取：
  - Pod 注解 `batch.kubernetes.io/job-completion-index`。
  - Pod 标签 `batch.kubernetes.io/job-completion-index`（适用于 v1.28 及更高版本）。 请注意，必须启用 `PodIndexLabel` 特性门控才能使用此标签，默认被启用。
  - 作为 Pod 主机名的一部分，遵循模式 `$(job-name)-$(index)`。 当你同时使用带索引的 Job（Indexed Job）与 [服务（Service）](https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/)， Job 中的 Pod 可以通过 DNS 使用确切的主机名互相寻址。 有关如何配置的更多信息，请参阅[带 Pod 间通信的 Job](https://kubernetes.io/zh-cn/docs/tasks/job/job-with-pod-to-pod-communication/)。
  - 对于容器化的任务，在环境变量 `JOB_COMPLETION_INDEX` 中。

当每个索引都有对应一个成功完成的 Pod 时，Job 被认为是已完成的。

## 索引完成模式

下面将运行一个使用多个并行工作进程的 Kubernetes Job。 Pod 具有控制平面自动设置的索引编号（index number）， 这些编号使得每个 Pod 能识别出要处理整个任务的哪个部分。

Pod 索引在注解 `batch.kubernetes.io/job-completion-index` 中呈现，具体表示为一个十进制值字符串。为了让容器化的任务进程获得此索引，可以使用 Downward API 机制来获取注解的值，而且控制平面会自动设置环境变量`JOB_COMPLETION_INDEX` 来暴露索引。

这里创建一个如下所示的 Job 资源清单文件：

```yaml
# job-indexed.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: indexed-job
spec:
  completions: 5
  parallelism: 3
  completionMode: Indexed
  template:
    spec:
      restartPolicy: Never
      initContainers:
        - name: "input"
          image: "bash"
          imagePullPolicy: IfNotPresent
          command:
            - "bash"
            - "-c"
            - |
              items=(foo bar baz qux xyz)
              echo ${items[$JOB_COMPLETION_INDEX]} > /input/data.txt
          volumeMounts:
            - mountPath: /input
              name: input
      containers:
        - name: "worker"
          image: "busybox"
          imagePullPolicy: IfNotPresent
          command:
            - "rev"
            - "/input/data.txt"
          volumeMounts:
            - mountPath: /input
              name: input
      volumes:
        - name: input
          emptyDir: {}
```

在该资源清单中设置了 `completionMode: Indexed`，表示这是一个 `Indexed` 完成模式的 Job 任务。这里还使用了 Job 控制器为 Pod 的所有容器设置的内置 `JOB_COMPLETION_INDEX` 环境变量。 Init 容器将索引映射到一个静态值，并将其写入一个文件，该文件通过 `emptyDir` 卷与运行 `worker` 的容器共享。

> rev（reverse）命令用于将文件中的每行内容以字符为单位反序输出，即第一个字符最后输出，最后一个字符最先输出，以此类推。

直接创建该资源对象即可：

```shell
[root@master yamlDir]# kubectl apply -f job-indexed.yaml
job.batch/indexed-job created

[root@master ~]# kubectl get pod -w -owide
NAME                                     READY   STATUS              RESTARTS      AGE    IP             NODE     NOMINATED NODE   READINESS GATES
indexed-job-0-p97vx                      0/1     Pending             0             0s     <none>         <none>   <none>           <none>
indexed-job-2-qjjwf                      0/1     Pending             0             0s     <none>         <none>   <none>           <none>
indexed-job-1-wmt47                      0/1     Pending             0             0s     <none>         <none>   <none>           <none>
indexed-job-0-p97vx                      0/1     Init:0/1            0             0s     <none>         node1    <none>           <none>
indexed-job-2-qjjwf                      0/1     Init:0/1            0             0s     <none>         node1    <none>           <none>
indexed-job-1-wmt47                      0/1     Init:0/1            0             0s     <none>         node1    <none>           <none>
indexed-job-1-wmt47                      0/1     PodInitializing     0             61s    10.244.1.17    node1    <none>           <none>
indexed-job-1-wmt47                      0/1     Completed           0             62s    10.244.1.17    node1    <none>           <none>
indexed-job-3-bcsrv                      0/1     Pending             0             0s     <none>         <none>   <none>           <none>
indexed-job-1-wmt47                      0/1     Completed           0             65s    10.244.1.17    node1    <none>           <none>
indexed-job-3-bcsrv                      0/1     Init:0/1            0             0s     <none>         node1    <none>           <none>
indexed-job-3-bcsrv                      0/1     PodInitializing     0             2s     10.244.1.18    node1    <none>           <none>
indexed-job-3-bcsrv                      0/1     Completed           0             5s     10.244.1.18    node1    <none>           <none>
indexed-job-4-54bjb                      0/1     Pending             0             0s     <none>         <none>   <none>           <none>
indexed-job-4-54bjb                      0/1     Init:0/1            0             0s     <none>         node1    <none>           <none>
indexed-job-3-bcsrv                      0/1     Completed           0             6s     10.244.1.18    node1    <none>           <none>
indexed-job-4-54bjb                      0/1     PodInitializing     0             2s     10.244.1.19    node1    <none>           <none>
indexed-job-2-qjjwf                      0/1     PodInitializing     0             75s    10.244.1.15    node1    <none>           <none>
indexed-job-4-54bjb                      0/1     Completed           0             6s     10.244.1.19    node1    <none>           <none>
indexed-job-2-qjjwf                      0/1     Completed           0             79s    10.244.1.15    node1    <none>           <none>
indexed-job-0-p97vx                      0/1     Init:0/1            0             80s    10.244.1.16    node1    <none>           <none>
indexed-job-0-p97vx                      0/1     PodInitializing     0             81s    10.244.1.16    node1    <none>           <none>
indexed-job-0-p97vx                      0/1     Completed           0             85s    10.244.1.16    node1    <none>           <none>
```

创建此 Job 时，控制平面会创建一系列 Pod。 `.spec.parallelism` 的值决定了一次可以运行多少个 Pod， 而 `.spec.completions` 决定了 Job 总共创建了多少个 Pod。因为 `.spec.parallelism` 小于 `.spec.completions`， 所以控制平面在启动更多 Pod 之前，将等待第一批的某些 Pod 完成。

创建 Job 后，稍等片刻，就能检查进度：

```shell
[root@master controller]# kubectl describe job indexed-job
Name:               indexed-job
Namespace:          default
Selector:           controller-uid=dd3f3091-3001-4e88-9d2a-1c6e0623043a
Labels:             controller-uid=dd3f3091-3001-4e88-9d2a-1c6e0623043a
                    job-name=indexed-job
Annotations:        batch.kubernetes.io/job-tracking:
Parallelism:        3
Completions:        5
Completion Mode:    Indexed
Start Time:         Tue, 22 Oct 2024 05:50:14 -0400
Completed At:       Tue, 22 Oct 2024 05:51:39 -0400
Duration:           85s
Pods Statuses:      0 Active (0 Ready) / 5 Succeeded / 0 Failed
Completed Indexes:  0-4
Pod Template:
  Labels:  controller-uid=dd3f3091-3001-4e88-9d2a-1c6e0623043a
           job-name=indexed-job
  Init Containers:
   input:
  ......
  Containers:
   worker:
  ......
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  13m   job-controller  Created pod: indexed-job-0-p97vx
  Normal  SuccessfulCreate  13m   job-controller  Created pod: indexed-job-1-wmt47
  Normal  SuccessfulCreate  13m   job-controller  Created pod: indexed-job-2-qjjwf
  Normal  SuccessfulCreate  11m   job-controller  Created pod: indexed-job-3-bcsrv
  Normal  SuccessfulCreate  11m   job-controller  Created pod: indexed-job-4-54bjb
  Normal  Completed         11m   job-controller  Job completed
```

这里使用每个索引的自定义值运行 Job，可以检查其中 Pod 的输出：

```shell
[root@master yamlDir]# kubectl logs indexed-job-0-p8np2
Defaulted container "worker" out of: worker, input (init)
oof
[root@master yamlDir]# kubectl logs indexed-job-1-zvpsm
Defaulted container "worker" out of: worker, input (init)
rab
```

在初始化容器中执行了如下所示的命令：

```shell
items=(foo bar baz qux xyz)
echo ${items[$JOB_COMPLETION_INDEX]} > /input/data.txt
```

当 `JOB_COMPLETION_INDEX=3` 的时候表示将 `items[3]` 的 qux 值写入到了 `/input/data.txt` 文件中，然后通过 `volume` 共享，在主容器中通过 `rev` 命令将其反转，所以输出结果就是 `xuq` 。

上面这个示例中每个 Pod 只做一小部分工作（反转一个字符串），在实际工作中肯定比这复杂，比如可能会创建一个基于场景数据制作 60 秒视频任务的 Job，此视频渲染 Job 中的每个工作项都将渲染该视频的特定帧，索引完成模式意味着 Job 中的每个 Pod 都知道通过从视频开始计算帧数，来确定渲染和发布哪一帧，这样就可以大大提高工作任务的效率。

## Pod间通信的Job

> 参考资料：https://kubernetes.io/zh-cn/docs/tasks/job/job-with-pod-to-pod-communication/

要在某 Job 中启用使用 Pod 主机名的 Pod 间通信，你必须执行以下操作：

1. 对于 Job 所创建的那些 Pod， 使用一个有效的标签选择算符创建[无头服务](https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/#headless-services)。 该无头服务必须位于与该 Job 相同的名字空间内。 实现这一目的的一种简单的方式是使用 `job-name: <任务名称>` 作为选择算符， 因为 `job-name` 标签将由 Kubernetes 自动添加。 此配置将触发 DNS 系统为运行 Job 的 Pod 创建其主机名的记录。

2. 通过将以下值包括到你的 Job 模板规约中，针对该 Job 的 Pod，将无头服务配置为其子域服务：

   ```yaml
   subdomain: <无头服务的名称>
   ```

以下是启用通过 Pod 主机名来完成 Pod 间通信的 Job 示例。 只有在使用主机名成功 ping 通所有 Pod 之后，此 Job 才会结束。

在以下示例中的每个 Pod 中执行的 Bash 脚本中，如果需要从名字空间外到达 Pod， Pod 主机名也可以带有该名字空间作为前缀。

```yaml
apiVersion: v1
kind: Service
metadata:
  name: headless-svc
spec:
  clusterIP: None # clusterIP 必须为 None 以创建无头服务
  selector:
    job-name: example-job # 必须与 Job 名称匹配
---
apiVersion: batch/v1
kind: Job
metadata:
  name: example-job
spec:
  completions: 3
  parallelism: 3
  completionMode: Indexed
  template:
    spec:
      subdomain: headless-svc # 必须与 Service 名称匹配
      restartPolicy: Never
      containers:
      - name: example-workload
        image: bash:latest
        command:
        - bash
        - -c
        - |
          for i in 0 1 2
          do
            gotStatus="-1"
            wantStatus="0"             
            while [ $gotStatus -ne $wantStatus ]
            do                                       
              ping -c 1 example-job-${i}.headless-svc > /dev/null 2>&1
              gotStatus=$?                
              if [ $gotStatus -ne $wantStatus ]; then
                echo "Failed to ping pod example-job-${i}.headless-svc, retrying in 1 second..."
                sleep 1
              fi
            done                                                         
            echo "Successfully pinged pod: example-job-${i}.headless-svc"
          done          
```

下面是对这个容器启动命令的详细解释：

```yaml
command:
- bash
- -c
- |
  for i in 0 1 2
  do
    gotStatus="-1"
    wantStatus="0"             
    while [ $gotStatus -ne $wantStatus ]
    do                                       
      ping -c 1 example-job-${i}.headless-svc > /dev/null 2>&1
      gotStatus=$?                
      if [ $gotStatus -ne $wantStatus ]; then
        echo "Failed to ping pod example-job-${i}.headless-svc, retrying in 1 second..."
        sleep 1
      fi
    done                                                         
    echo "Successfully pinged pod: example-job-${i}.headless-svc"
  done
```

1. 外层命令
   - `bash -c`：使用 Bash shell 执行后面的命令字符串。`-c` 选项告诉 Bash 解释并执行后面的字符串。

2. for 循环
   - `for i in 0 1 2`：循环变量 `i` 依次取值 `0`、`1`、`2`。

3. 初始化变量
   - `gotStatus="-1"`：初始化 `gotStatus` 变量为 `-1`，表示初始状态为失败。
   - `wantStatus="0"`：初始化 `wantStatus` 变量为 `0`，表示期望的状态为成功。

4. while 循环
   - `while [ $gotStatus -ne $wantStatus ]`：当 `gotStatus` 不等于 `wantStatus` 时，继续循环。
     - `ping -c 1 example-job-${i}.headless-svc > /dev/null 2>&1`：向 `example-job-${i}.headless-svc` 发送一个 ICMP 请求（即 ping 一次），并将输出重定向到 `/dev/null`，错误输出也重定向到 `/dev/null`。
     - `gotStatus=$?`：获取上一条命令的退出状态码，并赋值给 `gotStatus`。
     - `if [ $gotStatus -ne $wantStatus ]; then`：如果 `gotStatus` 不等于 `wantStatus`，表示 ping 失败。
       - `echo "Failed to ping pod example-job-${i}.headless-svc, retrying in 1 second..."`：打印失败信息。
       - `sleep 1`：等待 1 秒钟后重试。
     - `fi`：结束 if 语句。

5. 成功处理
   - `echo "Successfully pinged pod: example-job-${i}.headless-svc"`：当 `gotStatus` 等于 `wantStatus` 时，表示 ping 成功，打印成功信息。

6. 结束 for 循环
   - `done`：结束 for 循环。

这个容器启动命令的主要功能是：

1. 循环三次：分别对 `example-job-0.headless-svc`、`example-job-1.headless-svc` 和 `example-job-2.headless-svc` 进行 ping 测试。
2. 持续 ping 直到成功：对于每个 Pod，使用 `ping` 命令进行测试，直到成功为止。如果 ping 失败，会每隔 1 秒钟重试一次。
3. 打印结果：每次成功 ping 到一个 Pod 后，打印成功信息。

这个命令通常用于验证一组 Pod 是否已经准备好并可以互相通信。通过这种方式，可以确保在分布式任务中，各个 Pod 之间的网络连接是正常的。

应用上述示例之后，使用 `<Pod 主机名>.<无头服务名>` 通过网络到达彼此。 你应看到类似以下的输出：

```shell
[root@master 01-controller]# kubectl logs example-job-0-lm7hz
Failed to ping pod example-job-0.headless-svc, retrying in 1 second...
Failed to ping pod example-job-0.headless-svc, retrying in 1 second...
Failed to ping pod example-job-0.headless-svc, retrying in 1 second...
......
Failed to ping pod example-job-0.headless-svc, retrying in 1 second...
Successfully pinged pod: example-job-0.headless-svc
Successfully pinged pod: example-job-1.headless-svc
Failed to ping pod example-job-2.headless-svc, retrying in 1 second...
Failed to ping pod example-job-2.headless-svc, retrying in 1 second...
......
Failed to ping pod example-job-2.headless-svc, retrying in 1 second...
Failed to ping pod example-job-2.headless-svc, retrying in 1 second...
Successfully pinged pod: example-job-2.headless-svc
[root@master 01-controller]#
```

> 谨记此例中使用的 `<Pod 主机名>.<无头服务名称>` 名称格式不适用于设置为 `None` 或 `Default` 的 DNS 策略。 你可以在[此处](https://kubernetes.io/zh-cn/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy)了解有关 Pod DNS 策略的更多信息。

# CronJob

CronJob 其实就是在 Job 的基础上加上了时间调度，我们可以在给定的时间点运行一个任务，也可以周期性地在给定时间点运行。这个实际上和我们 Linux 中的 crontab 就非常类似了。

crontab 的格式为：分 时 日 月 星期 要运行的命令 。

```shell
# ┌───────────── 分钟 (0 - 59)
# │ ┌───────────── 小时 (0 - 23)
# │ │ ┌───────────── 月的某天 (1 - 31)
# │ │ │ ┌───────────── 月份 (1 - 12)
# │ │ │ │ ┌───────────── 周的某天 (0 - 6)（周日到周一；在某些系统上，7 也是星期日）
# │ │ │ │ │             或者是 sun，mon，tue，web，thu，fri，sat
# │ │ │ │ │
# │ │ │ │ │
# * * * * *
```

- 第 1 列分钟 0 ～ 59
- 第 2 列小时 0 ～ 23
- 第 3 列日 1 ～ 31
- 第 4 列月 1 ～ 12
- 第 5 列星期 0 ～ 7（0 和 7 表示星期天）
- 第 6 列要运行的命令

所有 CronJob 的 schedule 时间都是基于 kube-controller-manager 的时区，如果你的控制平面在 Pod 中运行了 kube-controller-manager， 那么为该容器所设置的时区将会决定 CronJob 的控制器所使用的时区。官方并不支持设置如 CRON_TZ 或者 TZ 等变量，这两个变量是用于解析和计算下一个 Job 创建时间所使用的内部库中一个实现细节，不建议在生产集群中使用它。

但是如果在 kube-controller-manager 中启用了 CronJobTimeZone 这个 Feature Gates，那么我们就可以为 CronJob 指定一个时区（如果你没有启用该特性门控，或者你使用的是不支持试验性时区功能的 Kubernetes 版本，集群中所有 CronJob 的时区都是未指定的）。启用该特性后，你可以将 spec.timeZone 设置为有效时区名称。

现在，我们用 CronJob 来管理我们上面的 Job 任务，定义如下所示的资源清单：

```yaml
# cronjob-demo.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cronjob-demo
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
            - name: hello
              image: busybox
              args:
                - "bin/sh"
                - "-c"
                - "for i in 9 8 7 6 5 4 3 2 1; do echo $i; done"
```

这里的 Kind 变成了 CronJob 了，要注意的是 .spec.schedule 字段是必须填写的，用来指定任务运行的周期，格式就和 crontab 一样，另外一个字段是 .spec.jobTemplate, 用来指定需要运行的任务，格式当然和 Job 是一致的。

还有一些值得我们关注的字段 .spec.successfulJobsHistoryLimit(默认为 3) 和 .spec.failedJobsHistoryLimit(默认为 1)，表示历史限制，是可选的字段，指定可以保留多少完成和失败的 Job。然而，当运行一个 CronJob 时，Job 可以很快就堆积很多，所以一般推荐设置这两个字段的值，如果设置限制的值为 0，那么相关类型的 Job 完成后将不会被保留。

我们直接新建上面的资源对象：

```
➜  ~ kubectl apply -f cronjob-demo.yaml
cronjob "cronjob-demo" created
```

然后可以查看对应的 Cronjob 资源对象：

```
[root@master yamlDir]# kubectl get cronjob -owide
NAME           SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE     CONTAINERS   IMAGES    SELECTOR
cronjob-demo   */1 * * * *   False     0        60s             2m15s   hello        busybox   <none>
```

稍微等一会儿查看可以发现多了几个 Job 资源对象，这个就是因为上面我们设置的 CronJob 资源对象，每 1 分钟执行一个新的 Job：

```shell
[root@master yamlDir]# kubectl get job -owide
NAME                    COMPLETIONS   DURATION   AGE     CONTAINERS   IMAGES    SELECTOR
cronjob-demo-28480384   1/1           20s        2m39s   hello        busybox   controller-uid=d5065b99-9896-476a-a219-d9600eed0d80
cronjob-demo-28480385   1/1           19s        99s     hello        busybox   controller-uid=e01b4708-5f31-4368-a514-31854f164cf8
cronjob-demo-28480386   1/1           19s        39s     hello        busybox   controller-uid=aa297cbc-f77f-4f2d-bc8e-6d83536243ba

[root@master yamlDir]# kubectl get pod
NAME                          READY   STATUS      RESTARTS   AGE
cronjob-demo-28480384-gcrgh   0/1     Completed   0          2m46s
cronjob-demo-28480385-48m62   0/1     Completed   0          106s
cronjob-demo-28480386-v5q2w   0/1     Completed   0          46s
[root@master yamlDir]#
```

这个就是 CronJob 的基本用法，一旦不再需要 CronJob，我们可以使用 kubectl 命令删除它：

```shell
➜  ~ kubectl delete cronjob cronjob-demo
cronjob "cronjob-demo" deleted
```

不过需要注意的是这将会终止正在创建的 Job，但是运行中的 Job 将不会被终止，不会删除它们的 Job 或 Pod。

> 思考：那如果我们想要在每个节点上去执行一个 Job 或者 Cronjob 又该怎么来实现呢？