接下来给大家介绍另外一类资源对象： Job ，我们在日常的工作中经常都会遇到一些需要进行批量数据处理和分析的需求，当然也会有按时间来进行调度的工作，在我们的 Kubernetes 集群中为我们提供了 Job 和 CronJob 两种资源对象来应对我们的这种需求。

Job 负责处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束。而 CronJob 则就是在 Job上加上了时间调度。



# Job

我们用 Job 这个资源对象来创建一个如下所示的任务，该任务负责计算 π 到小数点后 2000 位，并将结果打印出来，此计算大约需要 10 秒钟完成。对应的资源清单如下所示：

```yaml
# job-pi.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    spec:
      containers:
        - name: pi
          image: perl:5.34.0
          command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
  backoffLimit: 4
```

我们可以看到 Job 中也是一个 Pod 模板，和之前的 Deployment、StatefulSet 之类的是一致的，只是 Pod 中的容器要求是一个任务，而不是一个常驻的进程了，因为需要退出，另外值得注意的是 Job 的 RestartPolicy 仅支持 Never 和 OnFailure 两种，不支持 Always，我们知道 Job 就相当于来执行一个批处理任务，执行完就结束了，如果支持 Always 的话是不是就陷入了死循环了？

直接创建这个 Job 对象：

```
[root@master yamlDir]# kubectl apply -f job-pi.yaml
job.batch/pi created
[root@master yamlDir]# kubectl get job
NAME   COMPLETIONS   DURATION   AGE
pi     0/1           5s         5s
[root@master yamlDir]# kubectl get pods
NAME             READY   STATUS              RESTARTS      AGE
pi-j6zg5         0/1     ContainerCreating   0             22s
```

Job 对象创建成功后，我们可以查看下对象的详细描述信息：

```shell
[root@master yamlDir]# kubectl describe job pi
Name:             pi
Namespace:        default
Selector:         controller-uid=38738e0d-bb61-4cd1-b7cc-44f60f31d858
Labels:           controller-uid=38738e0d-bb61-4cd1-b7cc-44f60f31d858
                  job-name=pi
Annotations:      batch.kubernetes.io/job-tracking:
Parallelism:      1
Completions:      1
Completion Mode:  NonIndexed
Start Time:       Sat, 24 Feb 2024 17:50:55 -0500
Completed At:     Sat, 24 Feb 2024 17:52:18 -0500
Duration:         83s
Pods Statuses:    0 Active (0 Ready) / 1 Succeeded / 0 Failed
Pod Template:
  Labels:  controller-uid=38738e0d-bb61-4cd1-b7cc-44f60f31d858
           job-name=pi
  Containers:
   pi:
    Image:      perl:5.34.0
    Port:       <none>
    Host Port:  <none>
    Command:
      perl
      -Mbignum=bpi
      -wle
      print bpi(2000)
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  94s   job-controller  Created pod: pi-j6zg5
  Normal  Completed         11s   job-controller  Job completed
```

可以看到，Job 对象在创建后，它的 Pod 模板，被自动加上了一个 controller-uid=< 一个随机字符串 > 这样的 Label 标签，而这个 Job 对象本身，则被自动加上了这个 Label 对应的 Selector，从而保证了 Job 与它所管理的 Pod 之间的匹配关系。而 Job 控制器之所以要使用这种携带了 UID 的 Label，就是为了避免不同 Job 对象所管理的 Pod 发生重合。

我们可以看到隔一会儿后 Pod 变成了 Completed 状态，这是因为容器的任务执行完成正常退出了，我们可以查看对应的日志：

```shell
[root@master yamlDir]# kubectl get pods
NAME       READY   STATUS      RESTARTS   AGE
pi-j6zg5   0/1     Completed   0          7m17s

[root@master yamlDir]# kubectl logs pi-j6zg5
3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421
[root@master yamlDir]#
```

上面我们这里的 Job 任务对应的 Pod 在运行结束后，会变成 Completed 状态，但是如果执行任务的 Pod 因为某种原因一直没有结束怎么办呢？同样我们可以在 Job 对象中通过设置字段 spec.activeDeadlineSeconds 来限制任务运行的最长时间，比如：

```
spec:
 activeDeadlineSeconds: 100
```

在 Kubernetes Job 的配置中，spec.activeDeadlineSeconds 字段允许你设置一个时间限制，表示该 Job 可以运行的最长时间（以秒为单位）。如果设置了这个字段，Job 运行的时间超过了这个秒数，系统就会尝试终止这个 Job。这个时间限制包括了 Job 的启动时间、运行时间以及任何重试的时间。那么当我们 Job 运行超过了 100s 后，这个 Job 的所有 Pod 都会被终止，并且Job的终止原因会变成 DeadlineExceeded。

如果的任务执行失败了，会怎么处理呢，这个和定义的 restartPolicy 有关系，比如定义如下所示的 Job 任务，定义 restartPolicy: Never 的重启策略：

```yaml
# job-failed-demo.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-failed-demo
spec:
  template:
    spec:
      containers:
      - name: test-job
        image: busybox
        command: ["echo123", "test failed job!"]
      restartPolicy: Never
```

直接创建上面的资源对象：

```shell
➜  ~ kubectl apply -f job-failed-demo.yaml
job.batch/job-failed-demo created
[root@master yamlDir]# kubectl get pod
NAME                    READY   STATUS       RESTARTS   AGE
job-failed-demo-ftxpc   0/1     StartError   0          2m23s
job-failed-demo-jkmjn   0/1     StartError   0          2m19s
job-failed-demo-jvnwc   0/1     StartError   0          98s
job-failed-demo-lbntw   0/1     StartError   0          101s
job-failed-demo-ln9kk   0/1     StartError   0          2m
job-failed-demo-zkhwt   0/1     StartError   0          2m42s
job-failed-demo-ztknq   0/1     StartError   0          94s
```

可以看到当我们设置成 Never 重启策略的时候，Job 任务执行失败后会不断创建新的 Pod，但是不会一直创建下去，会根据 spec.backoffLimit 参数进行限制，默认为 6，通过该字段可以定义重建 Pod 的次数。

但是如果我们设置的 restartPolicy: OnFailure 重启策略，则当 Job 任务执行失败后不会创建新的 Pod 出来，只会不断重启 Pod，比如将上面的 Job 任务 restartPolicy 更改为 OnFailure 后查看 Pod：

```shell
☸ ➜ kubectl get pods
NAME                  READY   STATUS              RESTARTS      AGE
job-failed-demo-6l8vn 0/1     CrashLoopBackOff    3 (22s ago)   77s
```

除此之外，我们还可以通过设置 spec.parallelism 参数来进行并行控制，该参数定义了一个 Job 在任意时间最多可以有多少个 Pod 同时运行。并行性请求（.spec.parallelism）可以设置为任何非负整数，如果未设置，则默认为 1，如果设置为 0，则 Job 相当于启动之后便被暂停，直到此值被增加。

spec.completions 参数可以定义 Job 至少要完成的 Pod 数目。如下所示创建一个新的 Job 任务，设置允许并行数为 2，至少要完成的 Pod 数为 8：

```yaml
# job-para-demo.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-para-test
spec:
  parallelism: 2
  completions: 8
  template:
    spec:
      containers:
        - name: test-job
          image: busybox
          command: ["echo", "test paralle job!"]
      restartPolicy: Never
```

创建完成后查看任务状态：

```shell
➜  ~ kubectl get pod
NAME                     READY   STATUS              RESTARTS   AGE
job-para-test--1-rwxm8   0/1     ContainerCreating   0          6s
job-para-test--1-vgtxf   0/1     ContainerCreating   0          2s
➜  ~ kubectl get job
NAME            COMPLETIONS   DURATION   AGE
job-para-test   0/8           29s        29s
➜  ~ kubectl get job
NAME            COMPLETIONS   DURATION   AGE
job-para-test   8/8           111s       2m34s
➜  ~ kubectl get pod
NAME                     READY   STATUS      RESTARTS   AGE
job-para-test--1-7nk2x   0/1     Completed   0          76s
job-para-test--1-dcdvp   0/1     Completed   0          2m2s
job-para-test--1-k9sgw   0/1     Completed   0          2m36s
job-para-test--1-rwkkb   0/1     Completed   0          2m17s
job-para-test--1-rwxm8   0/1     Completed   0          2m36s
job-para-test--1-tqlzd   0/1     Completed   0          106s
job-para-test--1-vgtxf   0/1     Completed   0          2m32s
job-para-test--1-vxj6b   0/1     Completed   0          91s
```

可以看到一次可以有 2 个 Pod 同时运行，需要 8 个 Pod 执行成功，如果不是 8 个成功，那么会根据 restartPolicy 的策略进行处理，可以认为是一种检查机制。

此外带有确定完成计数的 Job，即 .spec.completions 不为 null 的 Job， 都可以在其 .spec.completionMode 中设置完成模式：

- NonIndexed（默认值）：当成功完成的 Pod 个数达到 .spec.completions 所设值时认为 Job 已经完成。换言之，每个 Job 完成事件都是独立无关且同质的。要注意的是，当 .spec.completions 取值为 null 时，Job 被默认处理为 NonIndexed 模式。
- Indexed：当设置为 Indexed 时，Job 中的每个 Pod 都会获得一个从 0 到 (.spec.completions - 1) 的连续索引，这个索引会以注解的形式（batch.kubernetes.io/job-completion-index）呈现在 Pod 上。Job 在每个索引都有至少一个成功完成的 Pod 时被认为是完成的。此模式下，必须指定 .spec.completions，且 .spec.parallelism 必须小于或等于 10^5。此外，在这种模式下，Pod 的名字会采用 $(job-name)-$(index)-$(random-string) 的格式，Pod 的主机名会采用 $(job-name)-$(index) 的格式。索引可以通过三种方式获取：

当每个索引都对应一个成功完成的 Pod 时，Job 被认为是已完成的。

## 索引完成模式

下面我们将运行一个使用多个并行工作进程的 Kubernetes Job，每个 worker 都是在自己的 Pod 中运行的容器。 Pod 具有控制平面自动设置的索引编号（index number）， 这些编号使得每个 Pod 能识别出要处理整个任务的哪个部分。

Pod 索引在注解 batch.kubernetes.io/job-completion-index 中呈现，具体表示为一个十进制值字符串。为了让容器化的任务进程获得此索引，我们可以使用 downward API 机制来获取注解的值。而且控制平面会自动设置 Downward API 在 JOB_COMPLETION_INDEX 环境变量中暴露索引。

我们这里创建一个如下所示的 Job 资源清单文件：

```yaml
# job-indexed.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: indexed-job
spec:
  completions: 5
  parallelism: 3
  completionMode: Indexed
  template:
    spec:
      restartPolicy: Never
      initContainers:
        - name: "input"
          image: "bash"
          command:
            - "bash"
            - "-c"
            - |
              items=(foo bar baz qux xyz)
              echo ${items[$JOB_COMPLETION_INDEX]} > /input/data.txt
          volumeMounts:
            - mountPath: /input
              name: input
      containers:
        - name: "worker"
          image: "busybox"
          command:
            - "rev"
            - "/input/data.txt"
          volumeMounts:
            - mountPath: /input
              name: input
      volumes:
        - name: input
          emptyDir: {}
```

在该资源清单中我们设置了 completionMode: Indexed，表示这是一个 Indexed 完成模式的 Job 任务。这里我们还使用了 Job 控制器为Pod的所有容器设置的内置 JOB_COMPLETION_INDEX 环境变量。 Init 容器将索引映射到一个静态值，并将其写入一个文件，该文件通过 emptyDir 卷 与运行 worker 的容器共享。

> rev（reverse）命令用于将文件中的每行内容以字符为单位反序输出，即第一个字符最后输出，最后一个字符最先输出，以此类推。

直接创建该资源对象即可：

```shell
[root@master yamlDir]# kubectl apply -f job-indexed.yaml
job.batch/indexed-job created

[root@master yamlDir]# kubectl get job
NAME          COMPLETIONS   DURATION   AGE
indexed-job   0/5           23s        23s
```

当你创建此 Job 时，控制平面会创建一系列 Pod。 .spec.parallelism 的值决定了一次可以运行多少个 Pod， 而 .spec.completions 决定了 Job 总共创建了多少个 Pod。

因为 .spec.parallelism 小于 .spec.completions， 所以控制平面在启动更多 Pod 之前，将等待第一批的某些 Pod 完成。

```shell
[root@master yamlDir]# kubectl get pod
NAME                  READY   STATUS      RESTARTS   AGE
indexed-job-0-p8np2   0/1     Completed   0          119s
indexed-job-1-zvpsm   0/1     Completed   0          119s
indexed-job-2-qxgpb   0/1     Completed   0          119s
indexed-job-3-2g9lt   0/1     Completed   0          80s
indexed-job-4-md75q   0/1     Completed   0          80s
```

创建 Job 后，稍等片刻，就能检查进度：

```shell
[root@master yamlDir]# kubectl describe jobs/indexed-job
Name:               indexed-job
Namespace:          default
Selector:           controller-uid=ed75f163-9fa0-4010-8979-d4aad2576876
Labels:             controller-uid=ed75f163-9fa0-4010-8979-d4aad2576876
                    job-name=indexed-job
Annotations:        batch.kubernetes.io/job-tracking:
Parallelism:        3
Completions:        5
Completion Mode:    Indexed
Start Time:         Sat, 24 Feb 2024 19:19:38 -0500
Completed At:       Sat, 24 Feb 2024 19:21:06 -0500
Duration:           88s
Pods Statuses:      0 Active (0 Ready) / 5 Succeeded / 0 Failed
Completed Indexes:  0-4
Pod Template:
  Labels:  controller-uid=ed75f163-9fa0-4010-8979-d4aad2576876
           job-name=indexed-job
  Init Containers:
...
...
Events:
  Type    Reason            Age    From            Message
  ----    ------            ----   ----            -------
  Normal  SuccessfulCreate  2m30s  job-controller  Created pod: indexed-job-0-p8np2
  Normal  SuccessfulCreate  2m30s  job-controller  Created pod: indexed-job-2-qxgpb
  Normal  SuccessfulCreate  2m30s  job-controller  Created pod: indexed-job-1-zvpsm
  Normal  SuccessfulCreate  111s   job-controller  Created pod: indexed-job-3-2g9lt
  Normal  SuccessfulCreate  111s   job-controller  Created pod: indexed-job-4-md75q
  Normal  Completed         62s    job-controller  Job completed
[root@master yamlDir]#
```

这里我们使用的每个索引的自定义值运行 Job，我们可以检查其中一个 Pod 的输出：

```shell
[root@master yamlDir]# kubectl logs indexed-job-0-p8np2
Defaulted container "worker" out of: worker, input (init)
oof
[root@master yamlDir]# kubectl logs indexed-job-1-zvpsm
Defaulted container "worker" out of: worker, input (init)
rab
```

我们在初始化容器中执行了如下所示的命令：

```shell
items=(foo bar baz qux xyz)
echo ${items[$JOB_COMPLETION_INDEX]} > /input/data.txt
```

当 JOB_COMPLETION_INDEX=3 的时候表示我们将 items[3] 的 qux 值写入到了 /input/data.txt 文件中，然后通过 volume 共享，在主容器中我们通过 rev 命令将其反转，所以输出结果就是 xuq 了。

上面我们这个示例中每个 Pod 只做一小部分工作（反转一个字符串）。 在实际工作中肯定比这复杂，比如你可能会创建一个基于场景数据制作 60 秒视频任务的 Job，此视频渲染 Job 中的每个工作项都将渲染该视频剪辑的特定帧，索引完成模式意味着 Job 中的每个 Pod 都知道通过从剪辑开始计算帧数，来确定渲染和发布哪一帧，这样就可以大大提高工作任务的效率。

# CronJob

CronJob 其实就是在 Job 的基础上加上了时间调度，我们可以在给定的时间点运行一个任务，也可以周期性地在给定时间点运行。这个实际上和我们 Linux 中的 crontab 就非常类似了。

crontab 的格式为：分 时 日 月 星期 要运行的命令 。

```shell
# ┌───────────── 分钟 (0 - 59)
# │ ┌───────────── 小时 (0 - 23)
# │ │ ┌───────────── 月的某天 (1 - 31)
# │ │ │ ┌───────────── 月份 (1 - 12)
# │ │ │ │ ┌───────────── 周的某天 (0 - 6)（周日到周一；在某些系统上，7 也是星期日）
# │ │ │ │ │             或者是 sun，mon，tue，web，thu，fri，sat
# │ │ │ │ │
# │ │ │ │ │
# * * * * *
```

- 第 1 列分钟 0 ～ 59
- 第 2 列小时 0 ～ 23
- 第 3 列日 1 ～ 31
- 第 4 列月 1 ～ 12
- 第 5 列星期 0 ～ 7（0 和 7 表示星期天）
- 第 6 列要运行的命令

所有 CronJob 的 schedule 时间都是基于 kube-controller-manager 的时区，如果你的控制平面在 Pod 中运行了 kube-controller-manager， 那么为该容器所设置的时区将会决定 CronJob 的控制器所使用的时区。官方并不支持设置如 CRON_TZ 或者 TZ 等变量，这两个变量是用于解析和计算下一个 Job 创建时间所使用的内部库中一个实现细节，不建议在生产集群中使用它。

但是如果在 kube-controller-manager 中启用了 CronJobTimeZone 这个 Feature Gates，那么我们就可以为 CronJob 指定一个时区（如果你没有启用该特性门控，或者你使用的是不支持试验性时区功能的 Kubernetes 版本，集群中所有 CronJob 的时区都是未指定的）。启用该特性后，你可以将 spec.timeZone 设置为有效时区名称。

现在，我们用 CronJob 来管理我们上面的 Job 任务，定义如下所示的资源清单：

```yaml
# cronjob-demo.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cronjob-demo
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
            - name: hello
              image: busybox
              args:
                - "bin/sh"
                - "-c"
                - "for i in 9 8 7 6 5 4 3 2 1; do echo $i; done"
```

这里的 Kind 变成了 CronJob 了，要注意的是 .spec.schedule 字段是必须填写的，用来指定任务运行的周期，格式就和 crontab 一样，另外一个字段是 .spec.jobTemplate, 用来指定需要运行的任务，格式当然和 Job 是一致的。

还有一些值得我们关注的字段 .spec.successfulJobsHistoryLimit(默认为 3) 和 .spec.failedJobsHistoryLimit(默认为 1)，表示历史限制，是可选的字段，指定可以保留多少完成和失败的 Job。然而，当运行一个 CronJob 时，Job 可以很快就堆积很多，所以一般推荐设置这两个字段的值，如果设置限制的值为 0，那么相关类型的 Job 完成后将不会被保留。

我们直接新建上面的资源对象：

```
➜  ~ kubectl apply -f cronjob-demo.yaml
cronjob "cronjob-demo" created
```

然后可以查看对应的 Cronjob 资源对象：

```
[root@master yamlDir]# kubectl get cronjob -owide
NAME           SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE     CONTAINERS   IMAGES    SELECTOR
cronjob-demo   */1 * * * *   False     0        60s             2m15s   hello        busybox   <none>
```

稍微等一会儿查看可以发现多了几个 Job 资源对象，这个就是因为上面我们设置的 CronJob 资源对象，每 1 分钟执行一个新的 Job：

```shell
[root@master yamlDir]# kubectl get job -owide
NAME                    COMPLETIONS   DURATION   AGE     CONTAINERS   IMAGES    SELECTOR
cronjob-demo-28480384   1/1           20s        2m39s   hello        busybox   controller-uid=d5065b99-9896-476a-a219-d9600eed0d80
cronjob-demo-28480385   1/1           19s        99s     hello        busybox   controller-uid=e01b4708-5f31-4368-a514-31854f164cf8
cronjob-demo-28480386   1/1           19s        39s     hello        busybox   controller-uid=aa297cbc-f77f-4f2d-bc8e-6d83536243ba

[root@master yamlDir]# kubectl get pod
NAME                          READY   STATUS      RESTARTS   AGE
cronjob-demo-28480384-gcrgh   0/1     Completed   0          2m46s
cronjob-demo-28480385-48m62   0/1     Completed   0          106s
cronjob-demo-28480386-v5q2w   0/1     Completed   0          46s
[root@master yamlDir]#
```

这个就是 CronJob 的基本用法，一旦不再需要 CronJob，我们可以使用 kubectl 命令删除它：

```shell
➜  ~ kubectl delete cronjob cronjob-demo
cronjob "cronjob-demo" deleted
```

不过需要注意的是这将会终止正在创建的 Job，但是运行中的 Job 将不会被终止，不会删除它们的 Job 或 Pod。

> 思考：那如果我们想要在每个节点上去执行一个 Job 或者 Cronjob 又该怎么来实现呢？